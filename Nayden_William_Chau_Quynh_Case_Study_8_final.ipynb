{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study Eight: XGBoost, Random Forest and SVM Predictors \n",
    "by Billy Nayden and Quynh Chau March 1, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 INTRODUCTION\n",
    "\n",
    "The purpose of this case study is to implement XGBoost, Random Forest and SVM classification algorithms and evaluate performance based on log loss where applicable (SVM is the exception).  In addition, a rough scaling of SVM using a range of data sample sizes will be approximated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 METHODS\n",
    "\n",
    "\n",
    "### RANDOM FOREST (RF)\n",
    "\n",
    "A RandomForest algorithm using the label encoded categorical variables along with our continuous variables as the input. Our baseline log loss was `7.61` and our baseline accuracy was `78%` using the default hyperparameters for RandomForest.\n",
    "\n",
    "We were not able to produce tuning with the full complement of all features in the data set within a reasonable run time, so we decided to reduce the number of features. We found that 37 features accounted for >99% of all variance in our initial model, so we used those 37 features for parameter tuning. This process was accomplished via `sklearn`'s `SelectFromModel` function.\n",
    "\n",
    "The hyperparameters we tuned can be described as follows:\n",
    "\n",
    ">`bootstrap` is a statistical resampling technique involving random sampling. Can be true or false.\n",
    "\n",
    ">`max_depth` is the maximum number of levels in each decision tree.\n",
    "\n",
    ">`max_features` is the maximum number of features Random Forest is allowed to try in individual tree.\n",
    "\n",
    ">`min_samples_leaf` is the minimum number of leaf nodes you can have.\n",
    "\n",
    ">`min_samples_split` is the minimum number of samples placed in a node before the node is aplit.\n",
    "\n",
    ">`n_estimators` is the number of trees you want to build before taking the maximum voting or averages of predictions. Higher number of trees give you better performance but makes your code slower.\n",
    "\n",
    "\n",
    "### SUPPORT VECTOR MACHINE (SVC)\n",
    "\n",
    "##### Categorical Variables Preprocessing\n",
    "\n",
    "There were 19 categorical features in the dataset that was converted to numerical values for data modeling.  Since we had features with a multitude of categories (features with high cardinality), we would expand the feature space dramatically using one hot encoding with binary values 0 or 1.  Alternatively, for each variable, we examined the frequency of values, kept the values that made up rough 87%-90% of occurrences and combined the rest of the values into a single variable.  In some instances, though the value of occurence per single instance was low, when these low frequency occuring values were combined, their total frequency made up the bulk of the occurence.  This process was used in order to minimize the feature space since support vector machine implementations could take a long time given the size of the dataset.  Categorical features were converted to numerics using label encoder.\n",
    "\n",
    "##### Train/Test Split, Cross Validation and Parameter Tuning\n",
    "\n",
    "Using a 70:30 Train/test split of the data containing numerical features and the label encoding of categorical features, SVC() was implemented with RandomizedSearchCV with 3-fold cross validation for tuning of paramters C, gamma, and kernel = 'linear'.  C is a regularization parameter that prevents overfitting and has value range {0.1,10,100,1000} where the strength of the regularization is inversely proportional to C.  Gamma has a value range {1,0.1,0.01,0.001,0.0001.0.00001} where the higher the gamma value, the higher the priority is to classify all training examples correctly vs. keeping the decision surface simple and smooth.  Kernel types included 'linear' or 'rbf'.  The combination of C and gamma is important to the performance of the SVC() algorithm and finding the optimal values of C-gamma pairing for each kernel type was done using RandomizedSearchhCV.\n",
    "\n",
    "SVC() algorithm is time consuming and implementation time took several hours without yielding results.\n",
    "\n",
    "##### Sample Sampling for SVM\n",
    "\n",
    "Random samplings of the dataset with sample sizes of 1000,2000,5000 and 10000 were used to test implementation times for  Support Vector Machine classification, SVC(), with 70:30 train/test split and RandommisedSearchCV() with the parameter tuning for a range of 'C'(from 1 to 1000) and 'gamma' (from 0.0001 to 1).  For each sample sizes, the algorithm was implemented with 3-fold cross validation, and 30 iterations.  Performance was evaluated using classification report for F1-score and accuracy as well as confusion matrix. Lastly, verbose = 1 was chosen for progression tracking.\n",
    "\n",
    "\n",
    "### XGBOOST (XGB)\n",
    "\n",
    "The XGBoost model using the label encoded categorical variables along with  continuous variables as the input. Our baseline log loss was `0.55` and our baseline accuracy was `76%` using the default hyperparameters for XGBoost.\n",
    "\n",
    "The hyperparameters we tuned using grid search can be defined as follows:\n",
    "\n",
    "> `colsample_bytree` is the subsample ratio of columns when constructing each tree. Subsampling occurs once for every tree constructed.\n",
    "\n",
    "> `eta` Step size shrinkage used in update to prevents overfitting. After each boosting step, we can directly get the weights of new features, and eta shrinks the feature weights to make the boosting process more conservative.\n",
    "\n",
    "> `eval_metric` is the way we will evaluate our best set of parameters, in this case `logloss`\n",
    "\n",
    "> `max_depth` is the maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "\n",
    "> `min_child_weight` is the minimum sum of instance weight needed in a child. A larger weight will result in a more conservative algorithm.\n",
    "\n",
    "> `objective` is the type of algorithm\n",
    "\n",
    "> `subsample` is the subsample ratio of the training instances. A value of 0.5 means half the data would be randomly sampled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 RESULTS\n",
    "\n",
    "\n",
    "### SAMPLE SUPPORT VECTOR MACHINE CLASSIFIER\n",
    "\n",
    "The results for sampling of SVC() implementation using randomizedsearch CV parameter tuning for 30 iterations showed that given the same set of parameters, processing time was faster for smaller sample sizes with non-differentiating performance results.  \n",
    "\n",
    "|Sample size|Average Time (sec)|Accuracy|\n",
    "|-----------|------------------|--------|\n",
    " 10000|0.026|77%|    \n",
    " 2000|0.093|76%|\n",
    " 5000|0.563|76%|\n",
    "10000|3.190|75%|\n",
    "50000|544|76%|\n",
    "\n",
    "However, it was noted that the confusion matrices for these samplings only identified true negatives and false positives. Even using a random sample size of 50,000 rows did not make a difference in accuracy.\n",
    "\n",
    "Results for support vector machine classifier using the same parameters with randomized search CV 3-fold were not available at this time due to it running overnight and is still going after two days.  \n",
    "\n",
    "\n",
    "### XGBOOST CLASSIFIER\n",
    "\n",
    "|Hyperparameter|Value|\n",
    "| --- | --- |\n",
    "|'colsample_bytree'|1.0|\n",
    " |'eta'|0.01|\n",
    " |'eval_metric'|'logloss'|\n",
    " |'max_depth'|9|\n",
    "| 'min_child_weight'|5|\n",
    " |'objective'|'binary:logistic'|\n",
    " |'subsample'|1.0|\n",
    " \n",
    "While the `eta` value of `0.005` was slightly lower log loss, it took twice as long to run as `eta` of `.01` so we opted to sacrifice that small log loss for a faster run time.\n",
    "\n",
    "Our tuned model reduced log loss to `0.47` while increasing accuracy to `77%`.\n",
    "\n",
    "### RANDOM FOREST CLASSIFIER\n",
    "\n",
    "RandomForest grid search and a random search to tune hyperparameters, and got the following as our results:\n",
    "\n",
    "|Hyperparameter|Value|\n",
    "| --- | --- |\n",
    "|'bootstrap'|True|\n",
    " |'max_depth'|80|\n",
    " |'max_features'|3|\n",
    " |'min_samples_leaf'|4|\n",
    " |'min_samples_split'|10|\n",
    " |'n_estimators'|1000|\n",
    " \n",
    "Our tuned model reduced log loss to `7.35` while increasing accuracy to `79%`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Conclusion\n",
    "\n",
    "XGBoost Classifier is the best algorithm to use for this dataset based on log loss of 0.47 and accuracy of 77%.  Comparatively, Random Forest Classifier yielded a log loss of 7.35 with 79% accuracy.  In addition, XGBoost took about 2 hours to run in contrast to over 5 hours for Random Forest.  \n",
    "\n",
    "Support vector machine (SVM) was the worst performer as measured by implementation time, due to the sample size.  Based on a random sampling of sample size, accuracies ranged from 75%-77%, but runtime very time consuming.  In addition, the confusion matrix revealed that SVM only yielded false positives and true negatives, therefore, evaluating model performance based on accuracies alone can be misleading.  Moreover, random sampling for the SVM samples may have caused imbalanced subsets of the data, which may impact the results as shown by the confusion matrices.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C://Users//WilliamNayden//Documents//MSDS//case_8.csv\", index_col=0)\n",
    "target = df['target']\n",
    "df.drop(['target'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['v3', 'v22', 'v24', 'v30', 'v31', 'v47', 'v52', 'v56', 'v66', 'v71',\n",
      "       'v74', 'v75', 'v79', 'v91', 'v107', 'v110', 'v112', 'v113', 'v125'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 114321 entries, 3 to 228713\n",
      "Columns: 131 entries, v1 to v131\n",
      "dtypes: float64(108), int32(19), int64(4)\n",
      "memory usage: 106.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "objList = df.select_dtypes(include = \"object\").columns\n",
    "print (objList)\n",
    "\n",
    "#Label Encoding for object to numeric conversion\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for feat in objList:\n",
    "    df[feat] = le.fit_transform(df[feat].astype(str))\n",
    "\n",
    "print (df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              v1        v2  v3        v4         v5        v6        v7  \\\n",
      "ID                                                                        \n",
      "3       1.335739  8.727474   2  3.921026   7.915266  2.599278  3.176895   \n",
      "4       1.630686  7.464411   2  4.145098   9.191265  2.436402  2.483921   \n",
      "5       0.943877  5.310079   2  4.410969   5.326159  3.979592  3.928571   \n",
      "6       0.797415  8.304757   2  4.225930  11.627438  2.097700  1.987549   \n",
      "8       1.630686  7.464411   2  4.145098   8.742359  2.436402  2.483921   \n",
      "...          ...       ...  ..       ...        ...       ...       ...   \n",
      "228708  1.630686  7.464411   2  4.145098   8.742359  2.436402  2.483921   \n",
      "228710  1.630686  7.464411   2  4.145098   8.742359  2.436402  2.483921   \n",
      "228711  1.630686  7.464411   2  4.145098  10.069277  2.436402  2.483921   \n",
      "228712  1.630686  7.464411   2  4.145098  10.106144  2.436402  2.483921   \n",
      "228713  1.619763  7.932978   2  4.640085   8.473141  2.351470  2.826766   \n",
      "\n",
      "              v8         v9       v10  ...      v122      v123      v124  \\\n",
      "ID                                     ...                                 \n",
      "3       0.012941   9.999999  0.503281  ...  8.000000  1.989780  0.035754   \n",
      "4       2.301630   9.031859  1.312910  ...  6.822439  3.549938  0.598896   \n",
      "5       0.019645  12.666667  0.765864  ...  9.333333  2.477596  0.013452   \n",
      "6       0.171947   8.965516  6.542669  ...  7.018256  1.812795  0.002267   \n",
      "8       1.496569   9.031859  1.050328  ...  6.822439  3.549938  0.919812   \n",
      "...          ...        ...       ...  ...       ...       ...       ...   \n",
      "228708  1.496569   9.031859  1.444201  ...  6.822439  3.549938  0.919812   \n",
      "228710  1.496569   9.031859  6.236324  ...  6.822439  3.549938  0.919812   \n",
      "228711  0.323324   9.031859  2.078775  ...  6.822439  3.549938  0.156764   \n",
      "228712  0.309226   9.031859  1.291029  ...  6.822439  3.549938  0.490658   \n",
      "228713  3.479754   9.629630  0.853391  ...  7.936508  2.944285  3.135205   \n",
      "\n",
      "        v125      v126      v127      v128  v129      v130      v131  \n",
      "ID                                                                    \n",
      "3         21  1.804126  3.113719  2.024285     0  0.636365  2.857144  \n",
      "4          6  1.672658  3.239542  1.957825     0  1.925763  1.739389  \n",
      "5          5  1.773709  3.922193  1.120468     2  0.883118  1.176472  \n",
      "6         64  1.415230  2.954381  1.990847     1  1.677108  1.034483  \n",
      "8         89  1.672658  3.239542  2.030373     0  1.925763  1.739389  \n",
      "...      ...       ...       ...       ...   ...       ...       ...  \n",
      "228708    12  1.672658  3.239542  2.030373     0  1.925763  1.739389  \n",
      "228710    68  1.672658  3.239542  2.030373     1  1.925763  1.739389  \n",
      "228711    80  1.672658  3.239542  2.417606     2  1.925763  1.739389  \n",
      "228712    50  1.672658  3.239542  3.526650     0  1.925763  1.739389  \n",
      "228713    85  1.943149  4.385553  1.604493     0  1.787610  1.386138  \n",
      "\n",
      "[114321 rows x 131 columns]\n"
     ]
    }
   ],
   "source": [
    "train = df\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 114321 entries and 131 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset has {} entries and {} features\".format(*train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(X_train.values, y_train.values)\n",
    "xgtest = xgb.DMatrix(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy is 0.76\n",
      "Baseline Log Loss is 0.55\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# \"Learn\" the mean from the training data\n",
    "mean_train = np.mean(y_train)\n",
    "# Get predictions on the test set\n",
    "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
    "\n",
    "# Compute Log Loss and Accuracy\n",
    "log_baseline = log_loss(y_test, baseline_predictions)\n",
    "acc_baseline = accuracy_score(y_test, np.ones(baseline_predictions.shape))\n",
    "\n",
    "print(\"Baseline Accuracy is {:.2f}\".format(acc_baseline))\n",
    "print(\"Baseline Log Loss is {:.2f}\".format(log_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:squarederror',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eval_metric'] = \"logloss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-logloss:0.59585\n",
      "[1]\tTest-logloss:0.54349\n",
      "[2]\tTest-logloss:0.51408\n",
      "[3]\tTest-logloss:0.49622\n",
      "[4]\tTest-logloss:0.48699\n",
      "[5]\tTest-logloss:0.48083\n",
      "[6]\tTest-logloss:0.47772\n",
      "[7]\tTest-logloss:0.47577\n",
      "[8]\tTest-logloss:0.47423\n",
      "[9]\tTest-logloss:0.47283\n",
      "[10]\tTest-logloss:0.47257\n",
      "[11]\tTest-logloss:0.47378\n",
      "[12]\tTest-logloss:0.47440\n",
      "[13]\tTest-logloss:0.47358\n",
      "[14]\tTest-logloss:0.47444\n",
      "[15]\tTest-logloss:0.47440\n",
      "[16]\tTest-logloss:0.47383\n",
      "[17]\tTest-logloss:0.47389\n",
      "[18]\tTest-logloss:0.47399\n",
      "[19]\tTest-logloss:0.47445\n",
      "[20]\tTest-logloss:0.47463\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Log Loss: 0.47 with 11 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Log Loss: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.594222</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.219355</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.596227</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.224218</td>\n",
       "      <td>0.002851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.540254</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.217635</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.543916</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.222469</td>\n",
       "      <td>0.002365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.509214</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.217090</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.514469</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.221777</td>\n",
       "      <td>0.003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.490312</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.216398</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.221385</td>\n",
       "      <td>0.002789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.478276</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.215363</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.487557</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.221529</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.470668</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.214616</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.482328</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.221673</td>\n",
       "      <td>0.002325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.465326</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.213781</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.479303</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.221712</td>\n",
       "      <td>0.002283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.461288</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.212416</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.477426</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.221359</td>\n",
       "      <td>0.002064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-logloss-mean  train-logloss-std  train-error-mean  train-error-std  \\\n",
       "0            0.594222           0.000169          0.219355         0.000534   \n",
       "1            0.540254           0.000323          0.217635         0.000961   \n",
       "2            0.509214           0.000319          0.217090         0.000899   \n",
       "3            0.490312           0.000534          0.216398         0.000668   \n",
       "4            0.478276           0.000566          0.215363         0.000992   \n",
       "5            0.470668           0.000516          0.214616         0.000748   \n",
       "6            0.465326           0.000499          0.213781         0.000831   \n",
       "7            0.461288           0.000448          0.212416         0.001194   \n",
       "\n",
       "   test-logloss-mean  test-logloss-std  test-error-mean  test-error-std  \n",
       "0           0.596227          0.000418         0.224218        0.002851  \n",
       "1           0.543916          0.000762         0.222469        0.002365  \n",
       "2           0.514469          0.001079         0.221777        0.003009  \n",
       "3           0.497500          0.001061         0.221385        0.002789  \n",
       "4           0.487557          0.001440         0.221529        0.002131  \n",
       "5           0.482328          0.001366         0.221673        0.002325  \n",
       "6           0.479303          0.001508         0.221712        0.002283  \n",
       "7           0.477426          0.001778         0.221359        0.002064  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'logloss','error'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47742579999999996"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best Accuracy: {}', (1-cv_results['test-error-mean'].min()))\n",
    "print('Best Log Loss: {}'cv_results['test-logloss-mean'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\\Log Loss 0.48336480000000004 for 6 rounds\n",
      "\\Accuracy 0.7757031999999999 for 6 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\\Log Loss 0.4841996 for 6 rounds\n",
      "\\Accuracy 0.7746982 for 6 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\\Log Loss 0.48552100000000004 for 6 rounds\n",
      "\\Accuracy 0.775168 for 6 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\\Log Loss 0.48895039999999995 for 6 rounds\n",
      "\\Accuracy 0.7722826 for 6 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\\Log Loss 0.4901923999999999 for 5 rounds\n",
      "\\Accuracy 0.7731184 for 5 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\\Log Loss 0.48927000000000004 for 5 rounds\n",
      "\\Accuracy 0.7733534 for 5 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\\Log Loss 0.49479239999999997 for 5 rounds\n",
      "\\Accuracy 0.7702854 for 5 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\\Log Loss 0.493811 for 5 rounds\n",
      "\\Accuracy 0.7701938 for 5 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\\Log Loss 0.49371279999999995 for 5 rounds\n",
      "\\Accuracy 0.7714994 for 5 rounds\n",
      "Best params: 9, 5, Log Loss: 0.48336480000000004, Accuracy: 0.7714994\n"
     ]
    }
   ],
   "source": [
    "# Define initial best params and Log Loss\n",
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'logloss', 'error'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best Log Loss\n",
    "    mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "    mean_error = cv_results['test-error-mean'].min()\n",
    "    boost_rounds = cv_results['test-logloss-mean'].argmin()\n",
    "    print(\"\\Log Loss {} for {} rounds\".format(mean_logloss, boost_rounds))\n",
    "    print(\"\\Accuracy {} for {} rounds\".format((1-mean_error), boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, Log Loss: {}, Accuracy: {}\".format(best_params[0], best_params[1], min_logloss, (1-mean_error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 9\n",
    "params['min_child_weight'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tLog Loss 0.48336480000000004 for 6 rounds\n",
      "\tAccuracy 0.7757031999999999 for 6 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tLog Loss 0.48473760000000005 for 7 rounds\n",
      "\tAccuracy 0.7745544 for 7 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tLog Loss 0.48653880000000005 for 7 rounds\n",
      "\tAccuracy 0.774228 for 7 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tLog Loss 0.48524400000000006 for 6 rounds\n",
      "\tAccuracy 0.7760036 for 6 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tLog Loss 0.486137 for 6 rounds\n",
      "\tAccuracy 0.7745936 for 6 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tLog Loss 0.48725879999999994 for 6 rounds\n",
      "\tAccuracy 0.7741366000000001 for 6 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tLog Loss 0.4877432 for 6 rounds\n",
      "\tAccuracy 0.774437 for 6 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tLog Loss 0.4893510000000001 for 5 rounds\n",
      "\tAccuracy 0.7747499999999999 for 5 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tLog Loss 0.49988839999999996 for 3 rounds\n",
      "\tAccuracy 0.7740844 for 3 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tLog Loss 0.48957839999999997 for 6 rounds\n",
      "\tAccuracy 0.773471 for 6 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tLog Loss 0.4885256 for 6 rounds\n",
      "\tAccuracy 0.7740586 for 6 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tLog Loss 0.488768 for 6 rounds\n",
      "\tAccuracy 0.774894 for 6 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tLog Loss 0.48931700000000006 for 5 rounds\n",
      "\tAccuracy 0.7731706 for 5 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tLog Loss 0.49524840000000003 for 4 rounds\n",
      "\tAccuracy 0.7731444 for 4 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tLog Loss 0.49497160000000007 for 4 rounds\n",
      "\tAccuracy 0.7732228 for 4 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tLog Loss 0.49046939999999994 for 6 rounds\n",
      "\tAccuracy 0.773549 for 6 rounds\n",
      "Best params: 1.0, 1.0, Log Loss: 0.48336480000000004, Accuracy: 0.773549\n"
     ]
    }
   ],
   "source": [
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'logloss', 'error'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "    mean_error = cv_results['test-error-mean'].min()\n",
    "    boost_rounds = cv_results['test-logloss-mean'].argmin()\n",
    "    print(\"\\tLog Loss {} for {} rounds\".format(mean_logloss, boost_rounds))\n",
    "    print(\"\\tAccuracy {} for {} rounds\".format((1-mean_error), boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, Log Loss: {}, Accuracy: {}\".format(best_params[0], best_params[1], min_logloss, (1-mean_error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = 1.0\n",
    "params['colsample_bytree'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "CV with eta=0.3\n",
      "Wall time: 34.7 s\n",
      "\tLog Loss 0.48336480000000004 for 6 rounds\n",
      "\n",
      "\tAccuracy 0.7757031999999999 for 6 rounds\n",
      "CV with eta=0.2\n",
      "Wall time: 1min 7s\n",
      "\tLog Loss 0.4802938 for 11 rounds\n",
      "\n",
      "\tAccuracy 0.777009 for 11 rounds\n",
      "CV with eta=0.1\n",
      "Wall time: 2min 11s\n",
      "\tLog Loss 0.4761602 for 32 rounds\n",
      "\n",
      "\tAccuracy 0.7786150000000001 for 32 rounds\n",
      "CV with eta=0.05\n",
      "Wall time: 2min 27s\n",
      "\tLog Loss 0.4761278000000001 for 51 rounds\n",
      "\n",
      "\tAccuracy 0.7786801999999999 for 51 rounds\n",
      "CV with eta=0.01\n",
      "Wall time: 3min 43s\n",
      "\tLog Loss 0.5274683999999998 for 85 rounds\n",
      "\n",
      "\tAccuracy 0.7775574 for 85 rounds\n",
      "CV with eta=0.005\n",
      "Wall time: 3min 38s\n",
      "\tLog Loss 0.582802 for 83 rounds\n",
      "\n",
      "\tAccuracy 0.7761342 for 83 rounds\n",
      "Best params: 0.05, Log Loss: 0.4761278000000001, Accuracy: 0.7761342\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "# This can take some timeâ€¦\n",
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    \n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    \n",
    "    # Run and time CV\n",
    "    %time cv_results = xgb.cv(params,dtrain,num_boost_round=num_boost_round,seed=42,nfold=5,metrics=['logloss', 'error'],early_stopping_rounds=10)\n",
    "    \n",
    "    # Update best score\n",
    "    mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "    mean_error = cv_results['test-error-mean'].min()\n",
    "    boost_rounds = cv_results['test-logloss-mean'].argmin()\n",
    "    print(\"\\tLog Loss {} for {} rounds\\n\".format(mean_logloss, boost_rounds))\n",
    "    print(\"\\tAccuracy {} for {} rounds\".format((1-mean_error), boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, Log Loss: {}, Accuracy: {}\".format(best_params, min_logloss, (1-mean_error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Significantly reduces runtime\n",
    "params['eta'] = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1.0,\n",
       " 'eta': 0.01,\n",
       " 'eval_metric': 'logloss',\n",
       " 'max_depth': 9,\n",
       " 'min_child_weight': 5,\n",
       " 'objective': 'reg:linear',\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params\n",
    "{'colsample_bytree': 1.0,\n",
    " 'eta': 0.01,\n",
    " 'eval_metric': 'logloss',\n",
    " 'max_depth': 9,\n",
    " 'min_child_weight': 5,\n",
    " 'objective': 'reg:linear',\n",
    " 'subsample': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-logloss:0.68934\n",
      "[1]\tTest-logloss:0.68560\n",
      "[2]\tTest-logloss:0.68194\n",
      "[3]\tTest-logloss:0.67836\n",
      "[4]\tTest-logloss:0.67484\n",
      "[5]\tTest-logloss:0.67139\n",
      "[6]\tTest-logloss:0.66799\n",
      "[7]\tTest-logloss:0.66467\n",
      "[8]\tTest-logloss:0.66141\n",
      "[9]\tTest-logloss:0.65821\n",
      "[10]\tTest-logloss:0.65507\n",
      "[11]\tTest-logloss:0.65200\n",
      "[12]\tTest-logloss:0.64899\n",
      "[13]\tTest-logloss:0.64603\n",
      "[14]\tTest-logloss:0.64313\n",
      "[15]\tTest-logloss:0.64030\n",
      "[16]\tTest-logloss:0.63749\n",
      "[17]\tTest-logloss:0.63475\n",
      "[18]\tTest-logloss:0.63205\n",
      "[19]\tTest-logloss:0.62942\n",
      "[20]\tTest-logloss:0.62681\n",
      "[21]\tTest-logloss:0.62426\n",
      "[22]\tTest-logloss:0.62176\n",
      "[23]\tTest-logloss:0.61930\n",
      "[24]\tTest-logloss:0.61689\n",
      "[25]\tTest-logloss:0.61453\n",
      "[26]\tTest-logloss:0.61219\n",
      "[27]\tTest-logloss:0.60991\n",
      "[28]\tTest-logloss:0.60767\n",
      "[29]\tTest-logloss:0.60545\n",
      "[30]\tTest-logloss:0.60328\n",
      "[31]\tTest-logloss:0.60116\n",
      "[32]\tTest-logloss:0.59905\n",
      "[33]\tTest-logloss:0.59700\n",
      "[34]\tTest-logloss:0.59496\n",
      "[35]\tTest-logloss:0.59300\n",
      "[36]\tTest-logloss:0.59105\n",
      "[37]\tTest-logloss:0.58912\n",
      "[38]\tTest-logloss:0.58725\n",
      "[39]\tTest-logloss:0.58539\n",
      "[40]\tTest-logloss:0.58356\n",
      "[41]\tTest-logloss:0.58177\n",
      "[42]\tTest-logloss:0.58000\n",
      "[43]\tTest-logloss:0.57827\n",
      "[44]\tTest-logloss:0.57656\n",
      "[45]\tTest-logloss:0.57488\n",
      "[46]\tTest-logloss:0.57323\n",
      "[47]\tTest-logloss:0.57161\n",
      "[48]\tTest-logloss:0.57000\n",
      "[49]\tTest-logloss:0.56842\n",
      "[50]\tTest-logloss:0.56688\n",
      "[51]\tTest-logloss:0.56536\n",
      "[52]\tTest-logloss:0.56386\n",
      "[53]\tTest-logloss:0.56239\n",
      "[54]\tTest-logloss:0.56093\n",
      "[55]\tTest-logloss:0.55951\n",
      "[56]\tTest-logloss:0.55811\n",
      "[57]\tTest-logloss:0.55673\n",
      "[58]\tTest-logloss:0.55536\n",
      "[59]\tTest-logloss:0.55403\n",
      "[60]\tTest-logloss:0.55273\n",
      "[61]\tTest-logloss:0.55143\n",
      "[62]\tTest-logloss:0.55015\n",
      "[63]\tTest-logloss:0.54891\n",
      "[64]\tTest-logloss:0.54767\n",
      "[65]\tTest-logloss:0.54646\n",
      "[66]\tTest-logloss:0.54529\n",
      "[67]\tTest-logloss:0.54410\n",
      "[68]\tTest-logloss:0.54295\n",
      "[69]\tTest-logloss:0.54181\n",
      "[70]\tTest-logloss:0.54068\n",
      "[71]\tTest-logloss:0.53958\n",
      "[72]\tTest-logloss:0.53850\n",
      "[73]\tTest-logloss:0.53742\n",
      "[74]\tTest-logloss:0.53638\n",
      "[75]\tTest-logloss:0.53536\n",
      "[76]\tTest-logloss:0.53434\n",
      "[77]\tTest-logloss:0.53333\n",
      "[78]\tTest-logloss:0.53235\n",
      "[79]\tTest-logloss:0.53138\n",
      "[80]\tTest-logloss:0.53044\n",
      "[81]\tTest-logloss:0.52950\n",
      "[82]\tTest-logloss:0.52859\n",
      "[83]\tTest-logloss:0.52769\n",
      "[84]\tTest-logloss:0.52679\n",
      "[85]\tTest-logloss:0.52591\n",
      "[86]\tTest-logloss:0.52505\n",
      "[87]\tTest-logloss:0.52418\n",
      "[88]\tTest-logloss:0.52336\n",
      "[89]\tTest-logloss:0.52253\n",
      "[90]\tTest-logloss:0.52172\n",
      "[91]\tTest-logloss:0.52092\n",
      "[92]\tTest-logloss:0.52011\n",
      "[93]\tTest-logloss:0.51934\n",
      "[94]\tTest-logloss:0.51859\n",
      "[95]\tTest-logloss:0.51785\n",
      "[96]\tTest-logloss:0.51713\n",
      "[97]\tTest-logloss:0.51639\n",
      "[98]\tTest-logloss:0.51567\n",
      "[99]\tTest-logloss:0.51499\n",
      "[100]\tTest-logloss:0.51431\n",
      "[101]\tTest-logloss:0.51361\n",
      "[102]\tTest-logloss:0.51293\n",
      "[103]\tTest-logloss:0.51229\n",
      "[104]\tTest-logloss:0.51163\n",
      "[105]\tTest-logloss:0.51100\n",
      "[106]\tTest-logloss:0.51038\n",
      "[107]\tTest-logloss:0.50975\n",
      "[108]\tTest-logloss:0.50914\n",
      "[109]\tTest-logloss:0.50853\n",
      "[110]\tTest-logloss:0.50795\n",
      "[111]\tTest-logloss:0.50737\n",
      "[112]\tTest-logloss:0.50681\n",
      "[113]\tTest-logloss:0.50625\n",
      "[114]\tTest-logloss:0.50569\n",
      "[115]\tTest-logloss:0.50513\n",
      "[116]\tTest-logloss:0.50460\n",
      "[117]\tTest-logloss:0.50409\n",
      "[118]\tTest-logloss:0.50356\n",
      "[119]\tTest-logloss:0.50306\n",
      "[120]\tTest-logloss:0.50256\n",
      "[121]\tTest-logloss:0.50204\n",
      "[122]\tTest-logloss:0.50155\n",
      "[123]\tTest-logloss:0.50108\n",
      "[124]\tTest-logloss:0.50060\n",
      "[125]\tTest-logloss:0.50012\n",
      "[126]\tTest-logloss:0.49966\n",
      "[127]\tTest-logloss:0.49921\n",
      "[128]\tTest-logloss:0.49878\n",
      "[129]\tTest-logloss:0.49835\n",
      "[130]\tTest-logloss:0.49791\n",
      "[131]\tTest-logloss:0.49748\n",
      "[132]\tTest-logloss:0.49705\n",
      "[133]\tTest-logloss:0.49664\n",
      "[134]\tTest-logloss:0.49624\n",
      "[135]\tTest-logloss:0.49585\n",
      "[136]\tTest-logloss:0.49545\n",
      "[137]\tTest-logloss:0.49506\n",
      "[138]\tTest-logloss:0.49467\n",
      "[139]\tTest-logloss:0.49430\n",
      "[140]\tTest-logloss:0.49391\n",
      "[141]\tTest-logloss:0.49356\n",
      "[142]\tTest-logloss:0.49320\n",
      "[143]\tTest-logloss:0.49283\n",
      "[144]\tTest-logloss:0.49248\n",
      "[145]\tTest-logloss:0.49212\n",
      "[146]\tTest-logloss:0.49179\n",
      "[147]\tTest-logloss:0.49144\n",
      "[148]\tTest-logloss:0.49112\n",
      "[149]\tTest-logloss:0.49081\n",
      "[150]\tTest-logloss:0.49047\n",
      "[151]\tTest-logloss:0.49017\n",
      "[152]\tTest-logloss:0.48988\n",
      "[153]\tTest-logloss:0.48956\n",
      "[154]\tTest-logloss:0.48926\n",
      "[155]\tTest-logloss:0.48895\n",
      "[156]\tTest-logloss:0.48865\n",
      "[157]\tTest-logloss:0.48835\n",
      "[158]\tTest-logloss:0.48808\n",
      "[159]\tTest-logloss:0.48780\n",
      "[160]\tTest-logloss:0.48753\n",
      "[161]\tTest-logloss:0.48726\n",
      "[162]\tTest-logloss:0.48698\n",
      "[163]\tTest-logloss:0.48671\n",
      "[164]\tTest-logloss:0.48646\n",
      "[165]\tTest-logloss:0.48618\n",
      "[166]\tTest-logloss:0.48593\n",
      "[167]\tTest-logloss:0.48569\n",
      "[168]\tTest-logloss:0.48544\n",
      "[169]\tTest-logloss:0.48518\n",
      "[170]\tTest-logloss:0.48493\n",
      "[171]\tTest-logloss:0.48471\n",
      "[172]\tTest-logloss:0.48447\n",
      "[173]\tTest-logloss:0.48422\n",
      "[174]\tTest-logloss:0.48398\n",
      "[175]\tTest-logloss:0.48376\n",
      "[176]\tTest-logloss:0.48354\n",
      "[177]\tTest-logloss:0.48333\n",
      "[178]\tTest-logloss:0.48310\n",
      "[179]\tTest-logloss:0.48291\n",
      "[180]\tTest-logloss:0.48271\n",
      "[181]\tTest-logloss:0.48249\n",
      "[182]\tTest-logloss:0.48229\n",
      "[183]\tTest-logloss:0.48210\n",
      "[184]\tTest-logloss:0.48190\n",
      "[185]\tTest-logloss:0.48173\n",
      "[186]\tTest-logloss:0.48153\n",
      "[187]\tTest-logloss:0.48137\n",
      "[188]\tTest-logloss:0.48118\n",
      "[189]\tTest-logloss:0.48100\n",
      "[190]\tTest-logloss:0.48082\n",
      "[191]\tTest-logloss:0.48065\n",
      "[192]\tTest-logloss:0.48050\n",
      "[193]\tTest-logloss:0.48032\n",
      "[194]\tTest-logloss:0.48016\n",
      "[195]\tTest-logloss:0.48002\n",
      "[196]\tTest-logloss:0.47985\n",
      "[197]\tTest-logloss:0.47969\n",
      "[198]\tTest-logloss:0.47954\n",
      "[199]\tTest-logloss:0.47941\n",
      "[200]\tTest-logloss:0.47925\n",
      "[201]\tTest-logloss:0.47910\n",
      "[202]\tTest-logloss:0.47894\n",
      "[203]\tTest-logloss:0.47881\n",
      "[204]\tTest-logloss:0.47868\n",
      "[205]\tTest-logloss:0.47855\n",
      "[206]\tTest-logloss:0.47841\n",
      "[207]\tTest-logloss:0.47828\n",
      "[208]\tTest-logloss:0.47815\n",
      "[209]\tTest-logloss:0.47801\n",
      "[210]\tTest-logloss:0.47789\n",
      "[211]\tTest-logloss:0.47776\n",
      "[212]\tTest-logloss:0.47764\n",
      "[213]\tTest-logloss:0.47751\n",
      "[214]\tTest-logloss:0.47739\n",
      "[215]\tTest-logloss:0.47727\n",
      "[216]\tTest-logloss:0.47716\n",
      "[217]\tTest-logloss:0.47705\n",
      "[218]\tTest-logloss:0.47693\n",
      "[219]\tTest-logloss:0.47682\n",
      "[220]\tTest-logloss:0.47672\n",
      "[221]\tTest-logloss:0.47661\n",
      "[222]\tTest-logloss:0.47649\n",
      "[223]\tTest-logloss:0.47638\n",
      "[224]\tTest-logloss:0.47628\n",
      "[225]\tTest-logloss:0.47617\n",
      "[226]\tTest-logloss:0.47607\n",
      "[227]\tTest-logloss:0.47598\n",
      "[228]\tTest-logloss:0.47588\n",
      "[229]\tTest-logloss:0.47579\n",
      "[230]\tTest-logloss:0.47569\n",
      "[231]\tTest-logloss:0.47559\n",
      "[232]\tTest-logloss:0.47549\n",
      "[233]\tTest-logloss:0.47540\n",
      "[234]\tTest-logloss:0.47531\n",
      "[235]\tTest-logloss:0.47523\n",
      "[236]\tTest-logloss:0.47514\n",
      "[237]\tTest-logloss:0.47505\n",
      "[238]\tTest-logloss:0.47497\n",
      "[239]\tTest-logloss:0.47490\n",
      "[240]\tTest-logloss:0.47481\n",
      "[241]\tTest-logloss:0.47473\n",
      "[242]\tTest-logloss:0.47465\n",
      "[243]\tTest-logloss:0.47458\n",
      "[244]\tTest-logloss:0.47451\n",
      "[245]\tTest-logloss:0.47443\n",
      "[246]\tTest-logloss:0.47434\n",
      "[247]\tTest-logloss:0.47425\n",
      "[248]\tTest-logloss:0.47417\n",
      "[249]\tTest-logloss:0.47410\n",
      "[250]\tTest-logloss:0.47403\n",
      "[251]\tTest-logloss:0.47397\n",
      "[252]\tTest-logloss:0.47390\n",
      "[253]\tTest-logloss:0.47382\n",
      "[254]\tTest-logloss:0.47374\n",
      "[255]\tTest-logloss:0.47367\n",
      "[256]\tTest-logloss:0.47361\n",
      "[257]\tTest-logloss:0.47353\n",
      "[258]\tTest-logloss:0.47345\n",
      "[259]\tTest-logloss:0.47340\n",
      "[260]\tTest-logloss:0.47333\n",
      "[261]\tTest-logloss:0.47327\n",
      "[262]\tTest-logloss:0.47321\n",
      "[263]\tTest-logloss:0.47314\n",
      "[264]\tTest-logloss:0.47309\n",
      "[265]\tTest-logloss:0.47303\n",
      "[266]\tTest-logloss:0.47295\n",
      "[267]\tTest-logloss:0.47288\n",
      "[268]\tTest-logloss:0.47283\n",
      "[269]\tTest-logloss:0.47277\n",
      "[270]\tTest-logloss:0.47269\n",
      "[271]\tTest-logloss:0.47265\n",
      "[272]\tTest-logloss:0.47260\n",
      "[273]\tTest-logloss:0.47253\n",
      "[274]\tTest-logloss:0.47249\n",
      "[275]\tTest-logloss:0.47242\n",
      "[276]\tTest-logloss:0.47238\n",
      "[277]\tTest-logloss:0.47231\n",
      "[278]\tTest-logloss:0.47226\n",
      "[279]\tTest-logloss:0.47219\n",
      "[280]\tTest-logloss:0.47214\n",
      "[281]\tTest-logloss:0.47208\n",
      "[282]\tTest-logloss:0.47204\n",
      "[283]\tTest-logloss:0.47199\n",
      "[284]\tTest-logloss:0.47192\n",
      "[285]\tTest-logloss:0.47188\n",
      "[286]\tTest-logloss:0.47185\n",
      "[287]\tTest-logloss:0.47178\n",
      "[288]\tTest-logloss:0.47173\n",
      "[289]\tTest-logloss:0.47168\n",
      "[290]\tTest-logloss:0.47164\n",
      "[291]\tTest-logloss:0.47160\n",
      "[292]\tTest-logloss:0.47153\n",
      "[293]\tTest-logloss:0.47150\n",
      "[294]\tTest-logloss:0.47146\n",
      "[295]\tTest-logloss:0.47143\n",
      "[296]\tTest-logloss:0.47139\n",
      "[297]\tTest-logloss:0.47137\n",
      "[298]\tTest-logloss:0.47132\n",
      "[299]\tTest-logloss:0.47129\n",
      "[300]\tTest-logloss:0.47122\n",
      "[301]\tTest-logloss:0.47119\n",
      "[302]\tTest-logloss:0.47115\n",
      "[303]\tTest-logloss:0.47112\n",
      "[304]\tTest-logloss:0.47110\n",
      "[305]\tTest-logloss:0.47105\n",
      "[306]\tTest-logloss:0.47103\n",
      "[307]\tTest-logloss:0.47100\n",
      "[308]\tTest-logloss:0.47097\n",
      "[309]\tTest-logloss:0.47094\n",
      "[310]\tTest-logloss:0.47091\n",
      "[311]\tTest-logloss:0.47087\n",
      "[312]\tTest-logloss:0.47085\n",
      "[313]\tTest-logloss:0.47082\n",
      "[314]\tTest-logloss:0.47078\n",
      "[315]\tTest-logloss:0.47076\n",
      "[316]\tTest-logloss:0.47072\n",
      "[317]\tTest-logloss:0.47069\n",
      "[318]\tTest-logloss:0.47065\n",
      "[319]\tTest-logloss:0.47063\n",
      "[320]\tTest-logloss:0.47059\n",
      "[321]\tTest-logloss:0.47057\n",
      "[322]\tTest-logloss:0.47054\n",
      "[323]\tTest-logloss:0.47051\n",
      "[324]\tTest-logloss:0.47048\n",
      "[325]\tTest-logloss:0.47044\n",
      "[326]\tTest-logloss:0.47043\n",
      "[327]\tTest-logloss:0.47037\n",
      "[328]\tTest-logloss:0.47032\n",
      "[329]\tTest-logloss:0.47030\n",
      "[330]\tTest-logloss:0.47026\n",
      "[331]\tTest-logloss:0.47023\n",
      "[332]\tTest-logloss:0.47017\n",
      "[333]\tTest-logloss:0.47015\n",
      "[334]\tTest-logloss:0.47013\n",
      "[335]\tTest-logloss:0.47009\n",
      "[336]\tTest-logloss:0.47006\n",
      "[337]\tTest-logloss:0.47004\n",
      "[338]\tTest-logloss:0.47003\n",
      "[339]\tTest-logloss:0.46998\n",
      "[340]\tTest-logloss:0.46993\n",
      "[341]\tTest-logloss:0.46991\n",
      "[342]\tTest-logloss:0.46988\n",
      "[343]\tTest-logloss:0.46983\n",
      "[344]\tTest-logloss:0.46982\n",
      "[345]\tTest-logloss:0.46977\n",
      "[346]\tTest-logloss:0.46976\n",
      "[347]\tTest-logloss:0.46970\n",
      "[348]\tTest-logloss:0.46969\n",
      "[349]\tTest-logloss:0.46968\n",
      "[350]\tTest-logloss:0.46964\n",
      "[351]\tTest-logloss:0.46961\n",
      "[352]\tTest-logloss:0.46961\n",
      "[353]\tTest-logloss:0.46958\n",
      "[354]\tTest-logloss:0.46957\n",
      "[355]\tTest-logloss:0.46954\n",
      "[356]\tTest-logloss:0.46950\n",
      "[357]\tTest-logloss:0.46948\n",
      "[358]\tTest-logloss:0.46947\n",
      "[359]\tTest-logloss:0.46944\n",
      "[360]\tTest-logloss:0.46942\n",
      "[361]\tTest-logloss:0.46941\n",
      "[362]\tTest-logloss:0.46937\n",
      "[363]\tTest-logloss:0.46935\n",
      "[364]\tTest-logloss:0.46933\n",
      "[365]\tTest-logloss:0.46929\n",
      "[366]\tTest-logloss:0.46927\n",
      "[367]\tTest-logloss:0.46926\n",
      "[368]\tTest-logloss:0.46923\n",
      "[369]\tTest-logloss:0.46922\n",
      "[370]\tTest-logloss:0.46919\n",
      "[371]\tTest-logloss:0.46917\n",
      "[372]\tTest-logloss:0.46918\n",
      "[373]\tTest-logloss:0.46916\n",
      "[374]\tTest-logloss:0.46913\n",
      "[375]\tTest-logloss:0.46911\n",
      "[376]\tTest-logloss:0.46909\n",
      "[377]\tTest-logloss:0.46908\n",
      "[378]\tTest-logloss:0.46906\n",
      "[379]\tTest-logloss:0.46904\n",
      "[380]\tTest-logloss:0.46902\n",
      "[381]\tTest-logloss:0.46900\n",
      "[382]\tTest-logloss:0.46897\n",
      "[383]\tTest-logloss:0.46897\n",
      "[384]\tTest-logloss:0.46896\n",
      "[385]\tTest-logloss:0.46896\n",
      "[386]\tTest-logloss:0.46893\n",
      "[387]\tTest-logloss:0.46892\n",
      "[388]\tTest-logloss:0.46891\n",
      "[389]\tTest-logloss:0.46890\n",
      "[390]\tTest-logloss:0.46888\n",
      "[391]\tTest-logloss:0.46887\n",
      "[392]\tTest-logloss:0.46885\n",
      "[393]\tTest-logloss:0.46885\n",
      "[394]\tTest-logloss:0.46883\n",
      "[395]\tTest-logloss:0.46881\n",
      "[396]\tTest-logloss:0.46878\n",
      "[397]\tTest-logloss:0.46875\n",
      "[398]\tTest-logloss:0.46873\n",
      "[399]\tTest-logloss:0.46871\n",
      "[400]\tTest-logloss:0.46868\n",
      "[401]\tTest-logloss:0.46868\n",
      "[402]\tTest-logloss:0.46867\n",
      "[403]\tTest-logloss:0.46867\n",
      "[404]\tTest-logloss:0.46866\n",
      "[405]\tTest-logloss:0.46864\n",
      "[406]\tTest-logloss:0.46864\n",
      "[407]\tTest-logloss:0.46864\n",
      "[408]\tTest-logloss:0.46863\n",
      "[409]\tTest-logloss:0.46862\n",
      "[410]\tTest-logloss:0.46862\n",
      "[411]\tTest-logloss:0.46859\n",
      "[412]\tTest-logloss:0.46860\n",
      "[413]\tTest-logloss:0.46859\n",
      "[414]\tTest-logloss:0.46858\n",
      "[415]\tTest-logloss:0.46856\n",
      "[416]\tTest-logloss:0.46855\n",
      "[417]\tTest-logloss:0.46852\n",
      "[418]\tTest-logloss:0.46850\n",
      "[419]\tTest-logloss:0.46850\n",
      "[420]\tTest-logloss:0.46849\n",
      "[421]\tTest-logloss:0.46847\n",
      "[422]\tTest-logloss:0.46845\n",
      "[423]\tTest-logloss:0.46844\n",
      "[424]\tTest-logloss:0.46843\n",
      "[425]\tTest-logloss:0.46841\n",
      "[426]\tTest-logloss:0.46841\n",
      "[427]\tTest-logloss:0.46839\n",
      "[428]\tTest-logloss:0.46838\n",
      "[429]\tTest-logloss:0.46835\n",
      "[430]\tTest-logloss:0.46834\n",
      "[431]\tTest-logloss:0.46834\n",
      "[432]\tTest-logloss:0.46833\n",
      "[433]\tTest-logloss:0.46831\n",
      "[434]\tTest-logloss:0.46830\n",
      "[435]\tTest-logloss:0.46830\n",
      "[436]\tTest-logloss:0.46828\n",
      "[437]\tTest-logloss:0.46828\n",
      "[438]\tTest-logloss:0.46826\n",
      "[439]\tTest-logloss:0.46825\n",
      "[440]\tTest-logloss:0.46824\n",
      "[441]\tTest-logloss:0.46824\n",
      "[442]\tTest-logloss:0.46824\n",
      "[443]\tTest-logloss:0.46820\n",
      "[444]\tTest-logloss:0.46818\n",
      "[445]\tTest-logloss:0.46817\n",
      "[446]\tTest-logloss:0.46815\n",
      "[447]\tTest-logloss:0.46812\n",
      "[448]\tTest-logloss:0.46808\n",
      "[449]\tTest-logloss:0.46807\n",
      "[450]\tTest-logloss:0.46806\n",
      "[451]\tTest-logloss:0.46807\n",
      "[452]\tTest-logloss:0.46804\n",
      "[453]\tTest-logloss:0.46803\n",
      "[454]\tTest-logloss:0.46802\n",
      "[455]\tTest-logloss:0.46802\n",
      "[456]\tTest-logloss:0.46803\n",
      "[457]\tTest-logloss:0.46800\n",
      "[458]\tTest-logloss:0.46800\n",
      "[459]\tTest-logloss:0.46800\n",
      "[460]\tTest-logloss:0.46799\n",
      "[461]\tTest-logloss:0.46799\n",
      "[462]\tTest-logloss:0.46800\n",
      "[463]\tTest-logloss:0.46799\n",
      "[464]\tTest-logloss:0.46796\n",
      "[465]\tTest-logloss:0.46794\n",
      "[466]\tTest-logloss:0.46794\n",
      "[467]\tTest-logloss:0.46792\n",
      "[468]\tTest-logloss:0.46791\n",
      "[469]\tTest-logloss:0.46791\n",
      "[470]\tTest-logloss:0.46788\n",
      "[471]\tTest-logloss:0.46787\n",
      "[472]\tTest-logloss:0.46788\n",
      "[473]\tTest-logloss:0.46788\n",
      "[474]\tTest-logloss:0.46787\n",
      "[475]\tTest-logloss:0.46787\n",
      "[476]\tTest-logloss:0.46784\n",
      "[477]\tTest-logloss:0.46783\n",
      "[478]\tTest-logloss:0.46783\n",
      "[479]\tTest-logloss:0.46782\n",
      "[480]\tTest-logloss:0.46781\n",
      "[481]\tTest-logloss:0.46780\n",
      "[482]\tTest-logloss:0.46779\n",
      "[483]\tTest-logloss:0.46779\n",
      "[484]\tTest-logloss:0.46779\n",
      "[485]\tTest-logloss:0.46780\n",
      "[486]\tTest-logloss:0.46780\n",
      "[487]\tTest-logloss:0.46779\n",
      "[488]\tTest-logloss:0.46777\n",
      "[489]\tTest-logloss:0.46775\n",
      "[490]\tTest-logloss:0.46776\n",
      "[491]\tTest-logloss:0.46776\n",
      "[492]\tTest-logloss:0.46776\n",
      "[493]\tTest-logloss:0.46775\n",
      "[494]\tTest-logloss:0.46775\n",
      "[495]\tTest-logloss:0.46773\n",
      "[496]\tTest-logloss:0.46774\n",
      "[497]\tTest-logloss:0.46774\n",
      "[498]\tTest-logloss:0.46772\n",
      "[499]\tTest-logloss:0.46769\n",
      "[500]\tTest-logloss:0.46768\n",
      "[501]\tTest-logloss:0.46767\n",
      "[502]\tTest-logloss:0.46765\n",
      "[503]\tTest-logloss:0.46765\n",
      "[504]\tTest-logloss:0.46765\n",
      "[505]\tTest-logloss:0.46765\n",
      "[506]\tTest-logloss:0.46764\n",
      "[507]\tTest-logloss:0.46761\n",
      "[508]\tTest-logloss:0.46761\n",
      "[509]\tTest-logloss:0.46761\n",
      "[510]\tTest-logloss:0.46761\n",
      "[511]\tTest-logloss:0.46761\n",
      "[512]\tTest-logloss:0.46762\n",
      "[513]\tTest-logloss:0.46761\n",
      "[514]\tTest-logloss:0.46762\n",
      "[515]\tTest-logloss:0.46762\n",
      "[516]\tTest-logloss:0.46761\n",
      "[517]\tTest-logloss:0.46761\n",
      "[518]\tTest-logloss:0.46759\n",
      "[519]\tTest-logloss:0.46759\n",
      "[520]\tTest-logloss:0.46758\n",
      "[521]\tTest-logloss:0.46758\n",
      "[522]\tTest-logloss:0.46758\n",
      "[523]\tTest-logloss:0.46756\n",
      "[524]\tTest-logloss:0.46756\n",
      "[525]\tTest-logloss:0.46757\n",
      "[526]\tTest-logloss:0.46757\n",
      "[527]\tTest-logloss:0.46757\n",
      "[528]\tTest-logloss:0.46756\n",
      "[529]\tTest-logloss:0.46757\n",
      "[530]\tTest-logloss:0.46756\n",
      "[531]\tTest-logloss:0.46757\n",
      "[532]\tTest-logloss:0.46755\n",
      "[533]\tTest-logloss:0.46755\n",
      "[534]\tTest-logloss:0.46828\n",
      "[535]\tTest-logloss:0.46827\n",
      "[536]\tTest-logloss:0.46827\n",
      "[537]\tTest-logloss:0.46827\n",
      "[538]\tTest-logloss:0.46826\n",
      "[539]\tTest-logloss:0.46825\n",
      "[540]\tTest-logloss:0.46828\n",
      "[541]\tTest-logloss:0.46827\n",
      "Best Log Loss: 0.47 in 533 rounds\n",
      "Best Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'logloss','error'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "print(\"Best Log Loss: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))\n",
    "print(\"Best Accuracy: {:.2f}\".format(1-cv_results['test-error-mean'].min()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = model.get_score(importance_type='gain')\n",
    "l1 = list(d1.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: v50                  Importance: 8038\n",
      "Variable: v21                  Importance: 3342\n",
      "Variable: v22                  Importance: 3336\n",
      "Variable: v34                  Importance: 3138\n",
      "Variable: v10                  Importance: 3103\n",
      "Variable: v14                  Importance: 2767\n",
      "Variable: v12                  Importance: 2719\n",
      "Variable: v40                  Importance: 2701\n",
      "Variable: v66                  Importance: 2432\n",
      "Variable: v125                 Importance: 2107\n",
      "Variable: v56                  Importance: 2068\n",
      "Variable: v114                 Importance: 1818\n",
      "Variable: v113                 Importance: 1532\n",
      "Variable: v24                  Importance: 1498\n",
      "Variable: v47                  Importance: 1456\n",
      "Variable: v52                  Importance: 1416\n",
      "Variable: v23                  Importance: 1416\n",
      "Variable: v6                   Importance: 1386\n",
      "Variable: v99                  Importance: 1318\n",
      "Variable: v112                 Importance: 1285\n",
      "Variable: v88                  Importance: 1208\n",
      "Variable: v120                 Importance: 1136\n",
      "Variable: v57                  Importance: 1119\n",
      "Variable: v102                 Importance: 1116\n",
      "Variable: v39                  Importance: 1101\n",
      "Variable: v1                   Importance: 1042\n",
      "Variable: v9                   Importance: 1039\n",
      "Variable: v79                  Importance: 1037\n",
      "Variable: v124                 Importance: 1035\n",
      "Variable: v69                  Importance: 1030\n",
      "Variable: v127                 Importance: 1021\n",
      "Variable: v119                 Importance: 1021\n",
      "Variable: v78                  Importance: 1017\n",
      "Variable: v82                  Importance: 1003\n",
      "Variable: v45                  Importance: 990\n",
      "Variable: v97                  Importance: 985\n",
      "Variable: v2                   Importance: 977\n",
      "Variable: v37                  Importance: 950\n",
      "Variable: v16                  Importance: 949\n",
      "Variable: v68                  Importance: 932\n",
      "Variable: v18                  Importance: 930\n",
      "Variable: v85                  Importance: 909\n",
      "Variable: v131                 Importance: 907\n",
      "Variable: v35                  Importance: 890\n",
      "Variable: v58                  Importance: 884\n",
      "Variable: v28                  Importance: 882\n",
      "Variable: v90                  Importance: 878\n",
      "Variable: v122                 Importance: 870\n",
      "Variable: v42                  Importance: 868\n",
      "Variable: v117                 Importance: 860\n",
      "Variable: v19                  Importance: 845\n",
      "Variable: v80                  Importance: 820\n",
      "Variable: v36                  Importance: 817\n",
      "Variable: v4                   Importance: 789\n",
      "Variable: v11                  Importance: 777\n",
      "Variable: v5                   Importance: 771\n",
      "Variable: v126                 Importance: 771\n",
      "Variable: v98                  Importance: 765\n",
      "Variable: v20                  Importance: 744\n",
      "Variable: v44                  Importance: 736\n",
      "Variable: v27                  Importance: 733\n",
      "Variable: v13                  Importance: 718\n",
      "Variable: v111                 Importance: 718\n",
      "Variable: v59                  Importance: 712\n",
      "Variable: v15                  Importance: 704\n",
      "Variable: v7                   Importance: 702\n",
      "Variable: v87                  Importance: 702\n",
      "Variable: v107                 Importance: 698\n",
      "Variable: v54                  Importance: 691\n",
      "Variable: v103                 Importance: 688\n",
      "Variable: v100                 Importance: 672\n",
      "Variable: v118                 Importance: 665\n",
      "Variable: v51                  Importance: 658\n",
      "Variable: v104                 Importance: 657\n",
      "Variable: v86                  Importance: 657\n",
      "Variable: v94                  Importance: 656\n",
      "Variable: v70                  Importance: 653\n",
      "Variable: v32                  Importance: 652\n",
      "Variable: v91                  Importance: 651\n",
      "Variable: v84                  Importance: 646\n",
      "Variable: v26                  Importance: 645\n",
      "Variable: v53                  Importance: 639\n",
      "Variable: v60                  Importance: 636\n",
      "Variable: v116                 Importance: 627\n",
      "Variable: v43                  Importance: 623\n",
      "Variable: v61                  Importance: 615\n",
      "Variable: v130                 Importance: 608\n",
      "Variable: v101                 Importance: 605\n",
      "Variable: v81                  Importance: 604\n",
      "Variable: v89                  Importance: 589\n",
      "Variable: v123                 Importance: 586\n",
      "Variable: v73                  Importance: 583\n",
      "Variable: v8                   Importance: 579\n",
      "Variable: v25                  Importance: 578\n",
      "Variable: v31                  Importance: 567\n",
      "Variable: v109                 Importance: 566\n",
      "Variable: v95                  Importance: 560\n",
      "Variable: v108                 Importance: 545\n",
      "Variable: v29                  Importance: 539\n",
      "Variable: v49                  Importance: 537\n",
      "Variable: v33                  Importance: 535\n",
      "Variable: v93                  Importance: 528\n",
      "Variable: v92                  Importance: 523\n",
      "Variable: v83                  Importance: 517\n",
      "Variable: v65                  Importance: 516\n",
      "Variable: v115                 Importance: 514\n",
      "Variable: v55                  Importance: 511\n",
      "Variable: v77                  Importance: 510\n",
      "Variable: v105                 Importance: 495\n",
      "Variable: v46                  Importance: 483\n",
      "Variable: v67                  Importance: 480\n",
      "Variable: v71                  Importance: 453\n",
      "Variable: v121                 Importance: 449\n",
      "Variable: v62                  Importance: 439\n",
      "Variable: v63                  Importance: 426\n",
      "Variable: v41                  Importance: 425\n",
      "Variable: v72                  Importance: 413\n",
      "Variable: v17                  Importance: 403\n",
      "Variable: v128                 Importance: 367\n",
      "Variable: v129                 Importance: 351\n",
      "Variable: v48                  Importance: 326\n",
      "Variable: v96                  Importance: 296\n",
      "Variable: v30                  Importance: 289\n",
      "Variable: v106                 Importance: 219\n",
      "Variable: v38                  Importance: 206\n",
      "Variable: v76                  Importance: 180\n",
      "Variable: v64                  Importance: 180\n",
      "Variable: v74                  Importance: 144\n",
      "Variable: v110                 Importance: 36\n",
      "Variable: v75                  Importance: 27\n"
     ]
    }
   ],
   "source": [
    "# List of tuples with variable and importance\n",
    "feature_importances = list(model.get_score(importance_type='weight').items())\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of features sorted from most to least important\n",
    "sorted_importances = [importance[1] for importance in feature_importances]\n",
    "sorted_features = [importance[0] for importance in feature_importances]\n",
    "\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(feature_importances)))\n",
    "\n",
    "# Make a line graph\n",
    "plt.plot(x_values, cumulative_importances, 'g-')\n",
    "\n",
    "# Draw line at 95% of importance retained\n",
    "plt.hlines(y = 0.95, xmin=0, xmax=len(sorted_importances), color = 'r', linestyles = 'dashed')\n",
    "\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-75-29cddb0ced68>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-75-29cddb0ced68>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    print('Number of features for 95% importance:', np.where(((sum(range(sorted_importances))/cumulative_importances) > 0.95)[0][0] + 1)\u001b[0m\n\u001b[1;37m                                                                                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# Find number of features for cumulative importance of 95%\n",
    "# Add 1 because Python is zero-indexed\n",
    "print('Number of features for 95% importance:', np.where(((sum(range(sorted_importances))/cumulative_importances) > 0.95)[0][0] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "import numpy as np\n",
    "\n",
    "original_features = np.array(train)\n",
    "original_labels = np.array(target)\n",
    "\n",
    "# Training and Testing Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "original_train_features, original_test_features, original_train_labels, original_test_labels = train_test_split(original_features, original_labels, \n",
    "                                                                            test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average log loss: 7.61 .\n",
      "Average accuracy: 0.78 .\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, log_loss\n",
    "feature_list = list(train.columns)\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate model \n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(original_train_features, original_train_labels);\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(original_test_features)\n",
    "\n",
    "#Get Log Loss and Accuracy\n",
    "score = log_loss(original_test_labels, predictions)\n",
    "acc = accuracy_score(original_test_labels, predictions)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Average log loss:', round(np.mean(score), 2),'.')\n",
    "print('Average accuracy:', round(np.mean(acc), 2),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: v50                  Importance: 0.08\n",
      "Variable: v12                  Importance: 0.04\n",
      "Variable: v10                  Importance: 0.03\n",
      "Variable: v14                  Importance: 0.03\n",
      "Variable: v21                  Importance: 0.03\n",
      "Variable: v22                  Importance: 0.03\n",
      "Variable: v34                  Importance: 0.03\n",
      "Variable: v40                  Importance: 0.03\n",
      "Variable: v114                 Importance: 0.03\n",
      "Variable: v52                  Importance: 0.02\n",
      "Variable: v56                  Importance: 0.02\n",
      "Variable: v66                  Importance: 0.02\n",
      "Variable: v112                 Importance: 0.02\n",
      "Variable: v125                 Importance: 0.02\n",
      "Variable: v1                   Importance: 0.01\n",
      "Variable: v5                   Importance: 0.01\n",
      "Variable: v6                   Importance: 0.01\n",
      "Variable: v24                  Importance: 0.01\n",
      "Variable: v28                  Importance: 0.01\n",
      "Variable: v31                  Importance: 0.01\n",
      "Variable: v36                  Importance: 0.01\n",
      "Variable: v47                  Importance: 0.01\n",
      "Variable: v54                  Importance: 0.01\n",
      "Variable: v62                  Importance: 0.01\n",
      "Variable: v68                  Importance: 0.01\n",
      "Variable: v70                  Importance: 0.01\n",
      "Variable: v71                  Importance: 0.01\n",
      "Variable: v72                  Importance: 0.01\n",
      "Variable: v79                  Importance: 0.01\n",
      "Variable: v82                  Importance: 0.01\n",
      "Variable: v88                  Importance: 0.01\n",
      "Variable: v91                  Importance: 0.01\n",
      "Variable: v98                  Importance: 0.01\n",
      "Variable: v99                  Importance: 0.01\n",
      "Variable: v107                 Importance: 0.01\n",
      "Variable: v110                 Importance: 0.01\n",
      "Variable: v113                 Importance: 0.01\n",
      "Variable: v117                 Importance: 0.01\n",
      "Variable: v120                 Importance: 0.01\n",
      "Variable: v124                 Importance: 0.01\n",
      "Variable: v129                 Importance: 0.01\n",
      "Variable: v2                   Importance: 0.0\n",
      "Variable: v3                   Importance: 0.0\n",
      "Variable: v4                   Importance: 0.0\n",
      "Variable: v7                   Importance: 0.0\n",
      "Variable: v8                   Importance: 0.0\n",
      "Variable: v9                   Importance: 0.0\n",
      "Variable: v11                  Importance: 0.0\n",
      "Variable: v13                  Importance: 0.0\n",
      "Variable: v15                  Importance: 0.0\n",
      "Variable: v16                  Importance: 0.0\n",
      "Variable: v17                  Importance: 0.0\n",
      "Variable: v18                  Importance: 0.0\n",
      "Variable: v19                  Importance: 0.0\n",
      "Variable: v20                  Importance: 0.0\n",
      "Variable: v23                  Importance: 0.0\n",
      "Variable: v25                  Importance: 0.0\n",
      "Variable: v26                  Importance: 0.0\n",
      "Variable: v27                  Importance: 0.0\n",
      "Variable: v29                  Importance: 0.0\n",
      "Variable: v30                  Importance: 0.0\n",
      "Variable: v32                  Importance: 0.0\n",
      "Variable: v33                  Importance: 0.0\n",
      "Variable: v35                  Importance: 0.0\n",
      "Variable: v37                  Importance: 0.0\n",
      "Variable: v38                  Importance: 0.0\n",
      "Variable: v39                  Importance: 0.0\n",
      "Variable: v41                  Importance: 0.0\n",
      "Variable: v42                  Importance: 0.0\n",
      "Variable: v43                  Importance: 0.0\n",
      "Variable: v44                  Importance: 0.0\n",
      "Variable: v45                  Importance: 0.0\n",
      "Variable: v46                  Importance: 0.0\n",
      "Variable: v48                  Importance: 0.0\n",
      "Variable: v49                  Importance: 0.0\n",
      "Variable: v51                  Importance: 0.0\n",
      "Variable: v53                  Importance: 0.0\n",
      "Variable: v55                  Importance: 0.0\n",
      "Variable: v57                  Importance: 0.0\n",
      "Variable: v58                  Importance: 0.0\n",
      "Variable: v59                  Importance: 0.0\n",
      "Variable: v60                  Importance: 0.0\n",
      "Variable: v61                  Importance: 0.0\n",
      "Variable: v63                  Importance: 0.0\n",
      "Variable: v64                  Importance: 0.0\n",
      "Variable: v65                  Importance: 0.0\n",
      "Variable: v67                  Importance: 0.0\n",
      "Variable: v69                  Importance: 0.0\n",
      "Variable: v73                  Importance: 0.0\n",
      "Variable: v74                  Importance: 0.0\n",
      "Variable: v75                  Importance: 0.0\n",
      "Variable: v76                  Importance: 0.0\n",
      "Variable: v77                  Importance: 0.0\n",
      "Variable: v78                  Importance: 0.0\n",
      "Variable: v80                  Importance: 0.0\n",
      "Variable: v81                  Importance: 0.0\n",
      "Variable: v83                  Importance: 0.0\n",
      "Variable: v84                  Importance: 0.0\n",
      "Variable: v85                  Importance: 0.0\n",
      "Variable: v86                  Importance: 0.0\n",
      "Variable: v87                  Importance: 0.0\n",
      "Variable: v89                  Importance: 0.0\n",
      "Variable: v90                  Importance: 0.0\n",
      "Variable: v92                  Importance: 0.0\n",
      "Variable: v93                  Importance: 0.0\n",
      "Variable: v94                  Importance: 0.0\n",
      "Variable: v95                  Importance: 0.0\n",
      "Variable: v96                  Importance: 0.0\n",
      "Variable: v97                  Importance: 0.0\n",
      "Variable: v100                 Importance: 0.0\n",
      "Variable: v101                 Importance: 0.0\n",
      "Variable: v102                 Importance: 0.0\n",
      "Variable: v103                 Importance: 0.0\n",
      "Variable: v104                 Importance: 0.0\n",
      "Variable: v105                 Importance: 0.0\n",
      "Variable: v106                 Importance: 0.0\n",
      "Variable: v108                 Importance: 0.0\n",
      "Variable: v109                 Importance: 0.0\n",
      "Variable: v111                 Importance: 0.0\n",
      "Variable: v115                 Importance: 0.0\n",
      "Variable: v116                 Importance: 0.0\n",
      "Variable: v118                 Importance: 0.0\n",
      "Variable: v119                 Importance: 0.0\n",
      "Variable: v121                 Importance: 0.0\n",
      "Variable: v122                 Importance: 0.0\n",
      "Variable: v123                 Importance: 0.0\n",
      "Variable: v126                 Importance: 0.0\n",
      "Variable: v127                 Importance: 0.0\n",
      "Variable: v128                 Importance: 0.0\n",
      "Variable: v130                 Importance: 0.0\n",
      "Variable: v131                 Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reset style \n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "# List of features sorted from most to least important\n",
    "sorted_importances = [importance[1] for importance in feature_importances]\n",
    "sorted_features = [importance[0] for importance in feature_importances]\n",
    "\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "\n",
    "# Make a line graph\n",
    "plt.plot(x_values, cumulative_importances, 'g-')\n",
    "\n",
    "# Draw line at 95% of importance retained\n",
    "plt.hlines(y = 0.66, xmin=0, xmax=len(sorted_importances), color = 'r', linestyles = 'dashed')\n",
    "\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for max importance: 37\n"
     ]
    }
   ],
   "source": [
    "# Find number of features for cumulative importance of 66% (max importance)\n",
    "# Add 1 because Python is zero-indexed\n",
    "print('Number of features for max importance:', np.where(cumulative_importances > 0.66)[0][0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                                 class_weight=None,\n",
       "                                                 criterion='gini',\n",
       "                                                 max_depth=None,\n",
       "                                                 max_features='auto',\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 max_samples=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100, n_jobs=None,\n",
       "                                                 oob_score=False,\n",
       "                                                 random_state=None, verbose=0,\n",
       "                                                 warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=0.01)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.01\n",
    "sfm = SelectFromModel(rf, threshold=0.01)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(original_train_features, original_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v10\n",
      "v12\n",
      "v14\n",
      "v21\n",
      "v22\n",
      "v34\n",
      "v40\n",
      "v47\n",
      "v50\n",
      "v52\n",
      "v56\n",
      "v66\n",
      "v79\n",
      "v91\n",
      "v107\n",
      "v112\n",
      "v113\n",
      "v114\n",
      "v125\n"
     ]
    }
   ],
   "source": [
    "# Print the names of the most important features\n",
    "feat_labels = list(train.columns)\n",
    "\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new random forest classifier for the most important features\n",
    "clf_important = RandomForestClassifier()\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(X_important_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7792503843503155\n",
      "7.624571249925074\n"
     ]
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = clf_important.predict(X_important_test)\n",
    "\n",
    "# View The Accuracy Of Our  Model\n",
    "print(accuracy_score(y_test, y_important_pred))\n",
    "print(log_loss(y_test,y_important_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 164.7min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 323.4min finished\n"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                              n_iter = 100, \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_important_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1800,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 113.5min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 196.3min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed: 272.8min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_important_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 80,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7817420346710492\n",
      "7.53851746548729\n"
     ]
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = grid_search.predict(X_important_test)\n",
    "\n",
    "# View The Accuracy Of Our  Model\n",
    "print(accuracy_score(y_test, y_important_pred))\n",
    "print(log_loss(y_test,y_important_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\n"
     ]
    }
   ],
   "source": [
    "# Reading in data file\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Reading in data file\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\n"
     ]
    }
   ],
   "source": [
    "# Reading in data file\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID          int64\n",
       "target      int64\n",
       "v1        float64\n",
       "v2        float64\n",
       "v3         object\n",
       "           ...   \n",
       "v127      float64\n",
       "v128      float64\n",
       "v129        int64\n",
       "v130      float64\n",
       "v131      float64\n",
       "Length: 133, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114321 entries, 0 to 114320\n",
      "Columns: 133 entries, ID to v131\n",
      "dtypes: float64(108), int64(6), object(19)\n",
      "memory usage: 116.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v125</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v129</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>C</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>AU</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>2.024285</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636365</td>\n",
       "      <td>2.857144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>C</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>...</td>\n",
       "      <td>6.822439</td>\n",
       "      <td>3.549938</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>AF</td>\n",
       "      <td>1.672658</td>\n",
       "      <td>3.239542</td>\n",
       "      <td>1.957825</td>\n",
       "      <td>0</td>\n",
       "      <td>1.925763</td>\n",
       "      <td>1.739389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>C</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>...</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>AE</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>1.120468</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>C</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>...</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>CJ</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1.990847</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>C</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>1.496569</td>\n",
       "      <td>...</td>\n",
       "      <td>6.822439</td>\n",
       "      <td>3.549938</td>\n",
       "      <td>0.919812</td>\n",
       "      <td>Z</td>\n",
       "      <td>1.672658</td>\n",
       "      <td>3.239542</td>\n",
       "      <td>2.030373</td>\n",
       "      <td>0</td>\n",
       "      <td>1.925763</td>\n",
       "      <td>1.739389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target        v1        v2 v3        v4         v5        v6        v7  \\\n",
       "0   3       1  1.335739  8.727474  C  3.921026   7.915266  2.599278  3.176895   \n",
       "1   4       1  1.630686  7.464411  C  4.145098   9.191265  2.436402  2.483921   \n",
       "2   5       1  0.943877  5.310079  C  4.410969   5.326159  3.979592  3.928571   \n",
       "3   6       1  0.797415  8.304757  C  4.225930  11.627438  2.097700  1.987549   \n",
       "4   8       1  1.630686  7.464411  C  4.145098   8.742359  2.436402  2.483921   \n",
       "\n",
       "         v8  ...      v122      v123      v124  v125      v126      v127  \\\n",
       "0  0.012941  ...  8.000000  1.989780  0.035754    AU  1.804126  3.113719   \n",
       "1  2.301630  ...  6.822439  3.549938  0.598896    AF  1.672658  3.239542   \n",
       "2  0.019645  ...  9.333333  2.477596  0.013452    AE  1.773709  3.922193   \n",
       "3  0.171947  ...  7.018256  1.812795  0.002267    CJ  1.415230  2.954381   \n",
       "4  1.496569  ...  6.822439  3.549938  0.919812     Z  1.672658  3.239542   \n",
       "\n",
       "       v128  v129      v130      v131  \n",
       "0  2.024285     0  0.636365  2.857144  \n",
       "1  1.957825     0  1.925763  1.739389  \n",
       "2  1.120468     2  0.883118  1.176472  \n",
       "3  1.990847     1  1.677108  1.034483  \n",
       "4  2.030373     0  1.925763  1.739389  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114321 entries, 0 to 114320\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   v3      114321 non-null  object\n",
      " 1   v22     114321 non-null  object\n",
      " 2   v24     114321 non-null  object\n",
      " 3   v30     114321 non-null  object\n",
      " 4   v31     114321 non-null  object\n",
      " 5   v47     114321 non-null  object\n",
      " 6   v52     114321 non-null  object\n",
      " 7   v56     114321 non-null  object\n",
      " 8   v66     114321 non-null  object\n",
      " 9   v71     114321 non-null  object\n",
      " 10  v74     114321 non-null  object\n",
      " 11  v75     114321 non-null  object\n",
      " 12  v79     114321 non-null  object\n",
      " 13  v91     114321 non-null  object\n",
      " 14  v107    114321 non-null  object\n",
      " 15  v110    114321 non-null  object\n",
      " 16  v112    114321 non-null  object\n",
      " 17  v113    114321 non-null  object\n",
      " 18  v125    114321 non-null  object\n",
      "dtypes: object(19)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cat = df.select_dtypes('object')\n",
    "df_cat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variable 'v3' Combination\n",
    "df_cat['v3'].value_counts()\n",
    "C    114041\n",
    "A       227\n",
    "B        53\n",
    "Name: v3, dtype: int64\n",
    "df_cat['v3'] = df_cat['v3'].replace(['C','A','B'],['C','AB','AB'])\n",
    "df_cat['v3'].value_counts()\n",
    "C     114041\n",
    "AB       280\n",
    "Name: v3, dtype: int64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v22' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGDF    2886\n",
       "YGJ     2119\n",
       "QKI      668\n",
       "PWR      649\n",
       "HZE      423\n",
       "        ... \n",
       "ACKY       1\n",
       "PPF        1\n",
       "MMC        1\n",
       "WXH        1\n",
       "ZDI        1\n",
       "Name: v22, Length: 18210, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v22'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N!!     107576\n",
       "AGDF      2886\n",
       "YGJ       2119\n",
       "QKI        668\n",
       "PWR        649\n",
       "HZE        423\n",
       "Name: v22, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v22_dict = ['AGDF','YGJ','QKI','PWR','HZE']\n",
    "df_cat.loc[~df_cat[\"v22\"].isin(v22_dict), \"v22\"] = \"N!!\"\n",
    "df_cat['v22'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable 'v22' Combination\n",
    "\n",
    "df_cat['v22'].value_counts()\n",
    "\n",
    "v22_dict = ['AGDF','YGJ','QKI','PWR','HZE']\n",
    "df_cat.loc[~df_cat[\"v22\"].isin(v22_dict), \"v22\"] = \"N!!\"\n",
    "df_cat['v22'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v24' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E    55177\n",
       "D    26333\n",
       "C    20872\n",
       "B     8150\n",
       "A     3789\n",
       "Name: v24, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v24'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E     55177\n",
       "D     26333\n",
       "C     20872\n",
       "BA    11939\n",
       "Name: v24, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v24'] = df_cat['v24'].replace(['E','D','C','B','A'],['E','D','C','BA','BA'])\n",
    "df_cat['v24'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v30' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    92288\n",
       "G     8728\n",
       "D     5225\n",
       "E     2973\n",
       "F     2589\n",
       "A     2313\n",
       "B      205\n",
       "Name: v30, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v30'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C       92288\n",
       "G        8728\n",
       "EFAB     8080\n",
       "D        5225\n",
       "Name: v30, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v30'] = df_cat['v30'].replace(['C','G','D','E','F','A','B'],['C','G','D','EFAB','EFAB','EFAB','EFAB'])\n",
    "df_cat['v30'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v31' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    91804\n",
       "B    18947\n",
       "C     3570\n",
       "Name: v31, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v31'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A     91804\n",
       "BC    22517\n",
       "Name: v31, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v31'] = df_cat['v31'].replace(['A','B','C'],['A','BC','BC'])\n",
    "df_cat['v31'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v31' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    91804\n",
       "B    18947\n",
       "C     3570\n",
       "Name: v31, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v31'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A     91804\n",
       "BC    22517\n",
       "Name: v31, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v31'] = df_cat['v31'].replace(['A','B','C'],['A','BC','BC'])\n",
    "df_cat['v31'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable 'v31' Combination\n",
    "\n",
    "df_cat['v31'].value_counts()\n",
    "\n",
    "df_cat['v31'] = df_cat['v31'].replace(['A','B','C'],['A','BC','BC'])\n",
    "df_cat['v31'].value_counts()# Variable 'v52' Combination\n",
    "\n",
    "df_cat['v52'].value_counts()\n",
    "\n",
    "df_cat['v52'] = df_cat['v52'].replace(['J','I','F','C','D','L','G','B','E','K','A','H'],['J','I','F','C','D','L','G','B','E',\n",
    "                                                                                        'KAH','KAH','KAH'])\n",
    "df_cat['v52'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v47' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    55425\n",
       "I    39071\n",
       "E     5301\n",
       "F     4322\n",
       "G     3946\n",
       "D     3157\n",
       "J     3010\n",
       "B       50\n",
       "A       38\n",
       "H        1\n",
       "Name: v47, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v47'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C      55425\n",
       "I      39071\n",
       "G_H    10202\n",
       "E       5301\n",
       "F       4322\n",
       "Name: v47, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v47'] = df_cat['v47'].replace(['C','I','E','F','G','D','J','B','A','H'],\n",
    "                                      ['C','I','E','F','G_H','G_H','G_H','G_H','G_H','G_H'])\n",
    "df_cat['v47'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v52' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "J    11106\n",
       "I    10260\n",
       "F     9806\n",
       "C     9681\n",
       "D     9607\n",
       "L     9578\n",
       "G     9419\n",
       "B     9385\n",
       "E     9282\n",
       "K     8949\n",
       "A     8925\n",
       "H     8323\n",
       "Name: v52, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v52'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KAH    26197\n",
       "J      11106\n",
       "I      10260\n",
       "F       9806\n",
       "C       9681\n",
       "D       9607\n",
       "L       9578\n",
       "G       9419\n",
       "B       9385\n",
       "E       9282\n",
       "Name: v52, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v52'] = df_cat['v52'].replace(['J','I','F','C','D','L','G','B','E','K','A','H'],['J','I','F','C','D','L','G','B','E',\n",
    "                                                                                        'KAH','KAH','KAH'])\n",
    "df_cat['v52'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v56' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BW    18233\n",
       "DI    10256\n",
       "AS     8832\n",
       "BZ     7174\n",
       "AW     6369\n",
       "      ...  \n",
       "CZ        1\n",
       "D         1\n",
       "AX        1\n",
       "DB        1\n",
       "CE        1\n",
       "Name: v56, Length: 122, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v56'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C!!    63457\n",
       "BW     18233\n",
       "DI     10256\n",
       "AS      8832\n",
       "BZ      7174\n",
       "AW      6369\n",
       "Name: v56, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v56_dict = ['BW','DI','AS','BZ','AW']\n",
    "df_cat.loc[~df_cat[\"v56\"].isin(v56_dict), \"v56\"] = \"C!!\"\n",
    "df_cat['v56'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable 'v56' Combination\n",
    "\n",
    "df_cat['v56'].value_counts()\n",
    "\n",
    "v56_dict = ['BW','DI','AS','BZ','AW']\n",
    "df_cat.loc[~df_cat[\"v56\"].isin(v56_dict), \"v56\"] = \"C!!\"\n",
    "df_cat['v56'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v66' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    70353\n",
       "C    25704\n",
       "B    18264\n",
       "Name: v66, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v66'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v71' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F    75094\n",
       "B    30255\n",
       "C     8947\n",
       "I       16\n",
       "G        5\n",
       "A        1\n",
       "L        1\n",
       "K        1\n",
       "D        1\n",
       "Name: v71, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v71'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F         75094\n",
       "B         30255\n",
       "C          8947\n",
       "IGDLKA       25\n",
       "Name: v71, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v71'] = df_cat['v71'].replace(['F','B','C','I','G','D','L','K','A'],['F','B','C','IGDLKA','IGDLKA','IGDLKA',\n",
    "                                                                            'IGDLKA','IGDLKA','IGDLKA'])\n",
    "                                                                           \n",
    "df_cat['v71'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v74' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    113560\n",
       "C       716\n",
       "A        45\n",
       "Name: v74, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v74'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B     113560\n",
       "CA       761\n",
       "Name: v74, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v74'] = df_cat['v74'].replace(['B','C','A'],['B','CA','CA'])\n",
    "df_cat['v74'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v75' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    75087\n",
       "B    39192\n",
       "C       24\n",
       "A       18\n",
       "Name: v75, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v75'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D     75087\n",
       "B     39192\n",
       "CA       42\n",
       "Name: v75, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v75'] = df_cat['v75'].replace(['D','B','C','A'],['D','B','CA','CA'])\n",
    "df_cat['v75'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v79' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    34561\n",
       "B    25801\n",
       "E    25257\n",
       "D     5302\n",
       "I     4561\n",
       "K     4308\n",
       "M     3946\n",
       "O     3331\n",
       "P     2217\n",
       "H     2004\n",
       "Q     1006\n",
       "J      933\n",
       "F      571\n",
       "A      417\n",
       "R       50\n",
       "N       49\n",
       "G        6\n",
       "L        1\n",
       "Name: v79, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v79'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C      34561\n",
       "B      25801\n",
       "E      25257\n",
       "O_L    10585\n",
       "D       5302\n",
       "I       4561\n",
       "K       4308\n",
       "M       3946\n",
       "Name: v79, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v79'] = df_cat['v79'].replace(['C','B','E','D','I','K','M','O','P','H','Q','J','F','A','R','N','G','L'],\n",
    "                                      ['C','B','E','D','I','K','M','O_L','O_L','O_L','O_L','O_L','O_L','O_L','O_L','O_L',\n",
    "                                      'O_L','O_L'])\n",
    "                                                                           \n",
    "df_cat['v79'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v91' combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    27082\n",
       "G    24545\n",
       "C    23157\n",
       "B    22683\n",
       "F    13418\n",
       "E     3206\n",
       "D      230\n",
       "Name: v91, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v91'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A     27082\n",
       "G     24545\n",
       "C     23157\n",
       "B     22683\n",
       "F     13418\n",
       "ED     3436\n",
       "Name: v91, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v91'] = df_cat['v91'].replace(['A','G','C','B','F','E','D'],['A','G','C','B','F','ED','ED'])\n",
    "df_cat['v91'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v107' Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E    27082\n",
       "C    24545\n",
       "D    23157\n",
       "B    22683\n",
       "A    13418\n",
       "F     3206\n",
       "G      230\n",
       "Name: v107, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v107'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E     27082\n",
       "C     24545\n",
       "D     23157\n",
       "B     22683\n",
       "A     13418\n",
       "FG     3436\n",
       "Name: v107, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v107'] = df_cat['v107'].replace(['E','C','D','B','A','F','G'],['E','C','D','B','A','FG','FG'])\n",
    "df_cat['v107'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v110' Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    55688\n",
       "B    55426\n",
       "C     3207\n",
       "Name: v110, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v110'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v112' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F    22053\n",
       "I    10224\n",
       "A     9545\n",
       "N     9086\n",
       "D     7327\n",
       "H     5651\n",
       "U     4803\n",
       "E     4748\n",
       "P     4675\n",
       "L     4479\n",
       "R     4170\n",
       "T     3980\n",
       "J     3967\n",
       "O     3661\n",
       "K     3252\n",
       "B     2688\n",
       "Q     2346\n",
       "C     2055\n",
       "V     1883\n",
       "G     1702\n",
       "M     1193\n",
       "S      833\n",
       "Name: v112, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v112'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F        22053\n",
       "112!!    12700\n",
       "I        10224\n",
       "A         9545\n",
       "N         9086\n",
       "D         7327\n",
       "H         5651\n",
       "U         4803\n",
       "E         4748\n",
       "P         4675\n",
       "L         4479\n",
       "R         4170\n",
       "T         3980\n",
       "J         3967\n",
       "O         3661\n",
       "K         3252\n",
       "Name: v112, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v112_dict = ['F','I','A','N','D','H','U','E','P','L','R','T','J','O','K']\n",
    "df_cat.loc[~df_cat[\"v112\"].isin(v112_dict), \"v112\"] = \"112!!\"\n",
    "df_cat['v112'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v113' Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G     71556\n",
       "M      7374\n",
       "AC     5956\n",
       "AF     3568\n",
       "I      2605\n",
       "P      1975\n",
       "AG     1712\n",
       "V      1673\n",
       "X      1635\n",
       "T      1608\n",
       "W      1497\n",
       "B      1358\n",
       "Y      1282\n",
       "AB     1273\n",
       "N      1186\n",
       "AJ      872\n",
       "AH      797\n",
       "C       707\n",
       "AE      680\n",
       "S       614\n",
       "U       612\n",
       "Q       594\n",
       "L       477\n",
       "Z       453\n",
       "A       334\n",
       "E       324\n",
       "J       322\n",
       "AI      313\n",
       "AD      265\n",
       "F       233\n",
       "R       181\n",
       "D       142\n",
       "O       100\n",
       "H        41\n",
       "AK        1\n",
       "AA        1\n",
       "Name: v113, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v113'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G        71556\n",
       "M         7374\n",
       "AC        5956\n",
       "113!!     5687\n",
       "AF        3568\n",
       "I         2605\n",
       "P         1975\n",
       "AG        1712\n",
       "V         1673\n",
       "X         1635\n",
       "T         1608\n",
       "W         1497\n",
       "B         1358\n",
       "Y         1282\n",
       "AB        1273\n",
       "N         1186\n",
       "AJ         872\n",
       "AH         797\n",
       "C          707\n",
       "Name: v113, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v113_dict = ['G','M','AC','AF','I','P','AG','V','X','T','W','B','Y','AB','N','AJ','AH','C']\n",
    "df_cat.loc[~df_cat[\"v113\"].isin(v113_dict), \"v113\"] = \"113!!\"\n",
    "df_cat['v113'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable 'v125' Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BM    5836\n",
       "AK    5337\n",
       "BJ    4465\n",
       "CG    3826\n",
       "AP    3410\n",
       "      ... \n",
       "AB     189\n",
       "AJ      82\n",
       "BB      68\n",
       "AX      13\n",
       "BZ       3\n",
       "Name: v125, Length: 90, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['v125'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125!!    91447\n",
       "BM        5836\n",
       "AK        5337\n",
       "BJ        4465\n",
       "CG        3826\n",
       "AP        3410\n",
       "Name: v125, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v125_dict = ['BM','AK','BJ','CG','AP']\n",
    "df_cat.loc[~df_cat[\"v125\"].isin(v125_dict), \"v125\"] = \"125!!\"\n",
    "df_cat['v125'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding the Entire DF_Cat Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import labelEncoder from sklearn\n",
    "# Create one hot encoder object by default\n",
    "# The entire df_cat dataframe is one hot encoded\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_cat1 = df_cat.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v3</th>\n",
       "      <th>v22</th>\n",
       "      <th>v24</th>\n",
       "      <th>v30</th>\n",
       "      <th>v31</th>\n",
       "      <th>v47</th>\n",
       "      <th>v52</th>\n",
       "      <th>v56</th>\n",
       "      <th>v66</th>\n",
       "      <th>v71</th>\n",
       "      <th>v74</th>\n",
       "      <th>v75</th>\n",
       "      <th>v79</th>\n",
       "      <th>v91</th>\n",
       "      <th>v107</th>\n",
       "      <th>v110</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v3  v22  v24  v30  v31  v47  v52  v56  v66  v71  v74  v75  v79  v91  v107  \\\n",
       "0   1    2    1    0    0    0    5    5    2    2    0    2    3    0     4   \n",
       "1   1    2    1    0    0    1    5    4    0    2    0    2    2    1     1   \n",
       "2   1    2    3    0    0    0    4    0    0    0    0    0    3    5     2   \n",
       "3   1    2    2    0    1    0    8    2    0    2    0    2    0    1     1   \n",
       "4   1    2    3    0    0    4    8    2    2    2    0    2    1    5     2   \n",
       "\n",
       "   v110  v112  v113  v125  \n",
       "0     1    11     9     0  \n",
       "1     0    15     9     0  \n",
       "2     1     0     9     0  \n",
       "3     1     7     9     0  \n",
       "4     0    14     9     0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataframe with  numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114321 entries, 0 to 114320\n",
      "Columns: 114 entries, ID to v131\n",
      "dtypes: float64(108), int64(6)\n",
      "memory usage: 99.4 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v121</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v129</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803572</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>2.024285</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636365</td>\n",
       "      <td>2.857144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>...</td>\n",
       "      <td>2.737596</td>\n",
       "      <td>6.822439</td>\n",
       "      <td>3.549938</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>1.672658</td>\n",
       "      <td>3.239542</td>\n",
       "      <td>1.957825</td>\n",
       "      <td>0</td>\n",
       "      <td>1.925763</td>\n",
       "      <td>1.739389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>2.238806</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>1.120468</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>...</td>\n",
       "      <td>1.956521</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1.990847</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>1.496569</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>...</td>\n",
       "      <td>2.737596</td>\n",
       "      <td>6.822439</td>\n",
       "      <td>3.549938</td>\n",
       "      <td>0.919812</td>\n",
       "      <td>1.672658</td>\n",
       "      <td>3.239542</td>\n",
       "      <td>2.030373</td>\n",
       "      <td>0</td>\n",
       "      <td>1.925763</td>\n",
       "      <td>1.739389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target        v1        v2        v4         v5        v6        v7  \\\n",
       "0   3       1  1.335739  8.727474  3.921026   7.915266  2.599278  3.176895   \n",
       "1   4       1  1.630686  7.464411  4.145098   9.191265  2.436402  2.483921   \n",
       "2   5       1  0.943877  5.310079  4.410969   5.326159  3.979592  3.928571   \n",
       "3   6       1  0.797415  8.304757  4.225930  11.627438  2.097700  1.987549   \n",
       "4   8       1  1.630686  7.464411  4.145098   8.742359  2.436402  2.483921   \n",
       "\n",
       "         v8         v9  ...      v121      v122      v123      v124      v126  \\\n",
       "0  0.012941   9.999999  ...  0.803572  8.000000  1.989780  0.035754  1.804126   \n",
       "1  2.301630   9.031859  ...  2.737596  6.822439  3.549938  0.598896  1.672658   \n",
       "2  0.019645  12.666667  ...  2.238806  9.333333  2.477596  0.013452  1.773709   \n",
       "3  0.171947   8.965516  ...  1.956521  7.018256  1.812795  0.002267  1.415230   \n",
       "4  1.496569   9.031859  ...  2.737596  6.822439  3.549938  0.919812  1.672658   \n",
       "\n",
       "       v127      v128  v129      v130      v131  \n",
       "0  3.113719  2.024285     0  0.636365  2.857144  \n",
       "1  3.239542  1.957825     0  1.925763  1.739389  \n",
       "2  3.922193  1.120468     2  0.883118  1.176472  \n",
       "3  2.954381  1.990847     1  1.677108  1.034483  \n",
       "4  3.239542  2.030373     0  1.925763  1.739389  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num =df.select_dtypes(exclude='object')\n",
    "df_num.info()\n",
    "df_num.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append df_num and df_cat1 (label encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v71</th>\n",
       "      <th>v74</th>\n",
       "      <th>v75</th>\n",
       "      <th>v79</th>\n",
       "      <th>v91</th>\n",
       "      <th>v107</th>\n",
       "      <th>v110</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>1.496569</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114316</th>\n",
       "      <td>228708</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>1.496569</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114317</th>\n",
       "      <td>228710</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>1.496569</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114318</th>\n",
       "      <td>228711</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>10.069277</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>0.323324</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114319</th>\n",
       "      <td>228712</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>10.106144</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>0.309226</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114320</th>\n",
       "      <td>228713</td>\n",
       "      <td>1</td>\n",
       "      <td>1.619763</td>\n",
       "      <td>7.932978</td>\n",
       "      <td>4.640085</td>\n",
       "      <td>8.473141</td>\n",
       "      <td>2.351470</td>\n",
       "      <td>2.826766</td>\n",
       "      <td>3.479754</td>\n",
       "      <td>9.629630</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114321 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  target        v1        v2        v4         v5        v6  \\\n",
       "0            3       1  1.335739  8.727474  3.921026   7.915266  2.599278   \n",
       "1            4       1  1.630686  7.464411  4.145098   9.191265  2.436402   \n",
       "2            5       1  0.943877  5.310079  4.410969   5.326159  3.979592   \n",
       "3            6       1  0.797415  8.304757  4.225930  11.627438  2.097700   \n",
       "4            8       1  1.630686  7.464411  4.145098   8.742359  2.436402   \n",
       "...        ...     ...       ...       ...       ...        ...       ...   \n",
       "114316  228708       1  1.630686  7.464411  4.145098   8.742359  2.436402   \n",
       "114317  228710       1  1.630686  7.464411  4.145098   8.742359  2.436402   \n",
       "114318  228711       1  1.630686  7.464411  4.145098  10.069277  2.436402   \n",
       "114319  228712       1  1.630686  7.464411  4.145098  10.106144  2.436402   \n",
       "114320  228713       1  1.619763  7.932978  4.640085   8.473141  2.351470   \n",
       "\n",
       "              v7        v8         v9  ...  v71  v74  v75  v79  v91  v107  \\\n",
       "0       3.176895  0.012941   9.999999  ...    2    0    2    3    0     4   \n",
       "1       2.483921  2.301630   9.031859  ...    2    0    2    2    1     1   \n",
       "2       3.928571  0.019645  12.666667  ...    0    0    0    3    5     2   \n",
       "3       1.987549  0.171947   8.965516  ...    2    0    2    0    1     1   \n",
       "4       2.483921  1.496569   9.031859  ...    2    0    2    1    5     2   \n",
       "...          ...       ...        ...  ...  ...  ...  ...  ...  ...   ...   \n",
       "114316  2.483921  1.496569   9.031859  ...    0    0    0    1    0     4   \n",
       "114317  2.483921  1.496569   9.031859  ...    2    0    2    0    5     2   \n",
       "114318  2.483921  0.323324   9.031859  ...    0    0    0    0    5     2   \n",
       "114319  2.483921  0.309226   9.031859  ...    2    0    2    3    0     4   \n",
       "114320  2.826766  3.479754   9.629630  ...    2    0    2    3    4     0   \n",
       "\n",
       "        v110  v112  v113  v125  \n",
       "0          1    11     9     0  \n",
       "1          0    15     9     0  \n",
       "2          1     0     9     0  \n",
       "3          1     7     9     0  \n",
       "4          0    14     9     0  \n",
       "...      ...   ...   ...   ...  \n",
       "114316     0    15     9     0  \n",
       "114317     1     7     9     0  \n",
       "114318     1    13     9     0  \n",
       "114319     1     1     9     0  \n",
       "114320     1     1     9     0  \n",
       "\n",
       "[114321 rows x 133 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizontal_stack = pd.concat([df_num, df_cat1], axis=1)\n",
    "horizontal_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_stack.to_csv('raw_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Duration of Time for SVM using samples of n= {1000,2000,5000,10,000 and 50,000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_H1000 = horizontal_stack.sample(n=1000, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine with Hyperparameter Tuning \n",
    "\n",
    "# Separate target and feature variables into separate data sets\n",
    "\n",
    "Y1000 = df_H1000['target']\n",
    "X1000 = df_H1000.drop(['target'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v71</th>\n",
       "      <th>v74</th>\n",
       "      <th>v75</th>\n",
       "      <th>v79</th>\n",
       "      <th>v91</th>\n",
       "      <th>v107</th>\n",
       "      <th>v110</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16140</th>\n",
       "      <td>32411</td>\n",
       "      <td>0.916977</td>\n",
       "      <td>10.959701</td>\n",
       "      <td>3.834475</td>\n",
       "      <td>7.812437</td>\n",
       "      <td>2.589840</td>\n",
       "      <td>3.060718</td>\n",
       "      <td>6.088222</td>\n",
       "      <td>7.142858</td>\n",
       "      <td>1.838075</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>24225</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>1.496569</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>0.787745</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8130</th>\n",
       "      <td>16215</td>\n",
       "      <td>1.793939</td>\n",
       "      <td>7.083087</td>\n",
       "      <td>4.919902</td>\n",
       "      <td>7.531944</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>3.006061</td>\n",
       "      <td>0.035744</td>\n",
       "      <td>7.719298</td>\n",
       "      <td>1.050329</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88034</th>\n",
       "      <td>175818</td>\n",
       "      <td>1.992630</td>\n",
       "      <td>3.495210</td>\n",
       "      <td>3.570470</td>\n",
       "      <td>8.866604</td>\n",
       "      <td>3.174603</td>\n",
       "      <td>2.692744</td>\n",
       "      <td>17.297778</td>\n",
       "      <td>7.404845</td>\n",
       "      <td>0.722101</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100381</th>\n",
       "      <td>200583</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>1.496569</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82771</th>\n",
       "      <td>165226</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>1.496569</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>1.575492</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95427</th>\n",
       "      <td>190712</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>1.496569</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51505</th>\n",
       "      <td>102906</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>1.496569</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>8835</td>\n",
       "      <td>1.963733</td>\n",
       "      <td>3.699428</td>\n",
       "      <td>4.192277</td>\n",
       "      <td>8.924797</td>\n",
       "      <td>3.591331</td>\n",
       "      <td>2.538699</td>\n",
       "      <td>1.962591</td>\n",
       "      <td>11.985294</td>\n",
       "      <td>1.028447</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60506</th>\n",
       "      <td>120801</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>1.496569</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>1.422320</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID        v1         v2        v4        v5        v6        v7  \\\n",
       "16140    32411  0.916977  10.959701  3.834475  7.812437  2.589840  3.060718   \n",
       "12090    24225  1.630686   7.464411  4.145098  8.742359  2.436402  2.483921   \n",
       "8130     16215  1.793939   7.083087  4.919902  7.531944  2.133333  3.006061   \n",
       "88034   175818  1.992630   3.495210  3.570470  8.866604  3.174603  2.692744   \n",
       "100381  200583  1.630686   7.464411  4.145098  8.742359  2.436402  2.483921   \n",
       "...        ...       ...        ...       ...       ...       ...       ...   \n",
       "82771   165226  1.630686   7.464411  4.145098  8.742359  2.436402  2.483921   \n",
       "95427   190712  1.630686   7.464411  4.145098  8.742359  2.436402  2.483921   \n",
       "51505   102906  1.630686   7.464411  4.145098  8.742359  2.436402  2.483921   \n",
       "4438      8835  1.963733   3.699428  4.192277  8.924797  3.591331  2.538699   \n",
       "60506   120801  1.630686   7.464411  4.145098  8.742359  2.436402  2.483921   \n",
       "\n",
       "               v8         v9       v10  ...  v71  v74  v75  v79  v91  v107  \\\n",
       "16140    6.088222   7.142858  1.838075  ...    2    0    2    1    0     4   \n",
       "12090    1.496569   9.031859  0.787745  ...    2    0    2    6    4     0   \n",
       "8130     0.035744   7.719298  1.050329  ...    2    0    2    1    1     1   \n",
       "88034   17.297778   7.404845  0.722101  ...    2    0    2    3    2     3   \n",
       "100381   1.496569   9.031859  1.312910  ...    0    0    0    1    0     4   \n",
       "...           ...        ...       ...  ...  ...  ...  ...  ...  ...   ...   \n",
       "82771    1.496569   9.031859  1.575492  ...    2    0    2    1    0     4   \n",
       "95427    1.496569   9.031859  1.312910  ...    2    0    2    1    2     3   \n",
       "51505    1.496569   9.031859  1.050328  ...    2    0    2    1    2     3   \n",
       "4438     1.962591  11.985294  1.028447  ...    2    0    2    3    5     2   \n",
       "60506    1.496569   9.031859  1.422320  ...    1    0    0    1    0     4   \n",
       "\n",
       "        v110  v112  v113  v125  \n",
       "16140      0    13     2     0  \n",
       "12090      0     4    11     2  \n",
       "8130       0     3    11     0  \n",
       "88034      1     0     9     0  \n",
       "100381     0    14     7     0  \n",
       "...      ...   ...   ...   ...  \n",
       "82771      0    10    15     1  \n",
       "95427      0     4    16     0  \n",
       "51505      0     4    15     0  \n",
       "4438       1    10     9     1  \n",
       "60506      0     4    16     0  \n",
       "\n",
       "[1000 rows x 132 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    778\n",
       "0    222\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1000.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "                        X1000, Y1000, test_size = 0.30, random_state = 101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Results for SVM with Randomized Search 3-CV, Rows = 1000\n",
      "{'mean_fit_time': array([0.0510842 , 0.0308938 , 0.02602506, 0.02601695, 0.02084732,\n",
      "       0.03122338, 0.02603594, 0.02603579, 0.02603634, 0.02082841,\n",
      "       0.02603428, 0.01562158, 0.02603428, 0.02603467, 0.0260551 ,\n",
      "       0.02603587, 0.02639135, 0.03159833, 0.02083   , 0.02603555,\n",
      "       0.02603547, 0.02082809, 0.03125175, 0.03645849, 0.02082801,\n",
      "       0.02084668, 0.03121352, 0.02082809, 0.02082872, 0.02603539]), 'std_fit_time': array([7.36378498e-03, 1.23659972e-02, 7.37742322e-03, 1.47409446e-02,\n",
      "       7.37064982e-03, 1.35993831e-05, 7.36350400e-03, 7.36389737e-03,\n",
      "       7.36412216e-03, 7.36429077e-03, 7.36266106e-03, 2.97360213e-07,\n",
      "       7.36417837e-03, 7.36445933e-03, 7.37792558e-03, 7.36445937e-03,\n",
      "       1.52318149e-02, 1.31937830e-02, 7.36266132e-03, 7.36406610e-03,\n",
      "       7.36502141e-03, 7.36417836e-03, 1.27663266e-02, 1.47342062e-02,\n",
      "       7.36339161e-03, 7.37076251e-03, 0.00000000e+00, 7.36451553e-03,\n",
      "       7.36406598e-03, 7.36412216e-03]), 'mean_score_time': array([0.01861723, 0.02294477, 0.02603571, 0.02083794, 0.02081887,\n",
      "       0.02082841, 0.01562111, 0.0156219 , 0.01562285, 0.02082777,\n",
      "       0.0156215 , 0.03124269, 0.01562222, 0.01562158, 0.01631212,\n",
      "       0.01562095, 0.0208288 , 0.02082769, 0.02603507, 0.01562119,\n",
      "       0.02603531, 0.02082952, 0.02603594, 0.02081911, 0.02082912,\n",
      "       0.01562174, 0.01562142, 0.0208288 , 0.0156215 , 0.02082864]), 'std_score_time': array([4.70246438e-04, 6.42845219e-03, 7.38374357e-03, 7.37727197e-03,\n",
      "       7.39075896e-03, 7.36395357e-03, 5.94720425e-07, 0.00000000e+00,\n",
      "       0.00000000e+00, 7.36389738e-03, 2.24783192e-07, 2.97360213e-07,\n",
      "       8.99132768e-07, 8.99132768e-07, 4.89174386e-04, 5.15042996e-07,\n",
      "       7.36350405e-03, 7.36429076e-03, 7.36238009e-03, 0.00000000e+00,\n",
      "       7.36389737e-03, 7.36333546e-03, 7.36400993e-03, 7.37036899e-03,\n",
      "       7.36513369e-03, 1.12391596e-07, 0.00000000e+00, 7.36434694e-03,\n",
      "       1.12391596e-07, 7.36412216e-03]), 'param_C': masked_array(data=[517.3986277024461, 29.47422647809694,\n",
      "                   686.2769816973125, 307.9662196722378,\n",
      "                   722.5438617683046, 555.2275911247872,\n",
      "                   182.89240266007866, 966.4832224119692,\n",
      "                   84.56143366334368, 729.9927572876178,\n",
      "                   686.3063287801783, 49.48453742640058,\n",
      "                   187.96742613792105, 521.6653966849669,\n",
      "                   735.8190582693819, 914.1535576757685,\n",
      "                   403.99783069378736, 953.8767147108732,\n",
      "                   866.099816318328, 539.1614492475574, 98.14647976501556,\n",
      "                   702.5072956958257, 160.56030089820405,\n",
      "                   673.4915296568056, 702.3711366090863,\n",
      "                   681.6777681763589, 44.39669443408434,\n",
      "                   576.2050868680129, 501.11671380079326,\n",
      "                   53.80840108926621],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.5707675868681398, 0.17162165622510306,\n",
      "                   0.8339968626360765, 0.8937130796833973,\n",
      "                   0.19003895420479677, 0.3522319540266141,\n",
      "                   0.7857017618643588, 0.23245366181476068,\n",
      "                   0.6036484222912185, 0.27633882849726277,\n",
      "                   0.5179674741970474, 0.1379692375621061,\n",
      "                   0.994417901154097, 0.5788895354754169,\n",
      "                   0.5420617722295935, 0.8080201509879171,\n",
      "                   0.35732434282078784, 0.3437315778925598,\n",
      "                   0.830377712198797, 0.9225693725672236,\n",
      "                   0.10294749316074948, 0.8905798691284313,\n",
      "                   0.2756725448969536, 0.1644031240201702,\n",
      "                   0.48773522220572807, 0.5216481923258594,\n",
      "                   0.22403660350197763, 0.1205336601272924,\n",
      "                   0.13810956825889598, 0.17837692253615167],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 517.3986277024461, 'gamma': 0.5707675868681398}, {'C': 29.47422647809694, 'gamma': 0.17162165622510306}, {'C': 686.2769816973125, 'gamma': 0.8339968626360765}, {'C': 307.9662196722378, 'gamma': 0.8937130796833973}, {'C': 722.5438617683046, 'gamma': 0.19003895420479677}, {'C': 555.2275911247872, 'gamma': 0.3522319540266141}, {'C': 182.89240266007866, 'gamma': 0.7857017618643588}, {'C': 966.4832224119692, 'gamma': 0.23245366181476068}, {'C': 84.56143366334368, 'gamma': 0.6036484222912185}, {'C': 729.9927572876178, 'gamma': 0.27633882849726277}, {'C': 686.3063287801783, 'gamma': 0.5179674741970474}, {'C': 49.48453742640058, 'gamma': 0.1379692375621061}, {'C': 187.96742613792105, 'gamma': 0.994417901154097}, {'C': 521.6653966849669, 'gamma': 0.5788895354754169}, {'C': 735.8190582693819, 'gamma': 0.5420617722295935}, {'C': 914.1535576757685, 'gamma': 0.8080201509879171}, {'C': 403.99783069378736, 'gamma': 0.35732434282078784}, {'C': 953.8767147108732, 'gamma': 0.3437315778925598}, {'C': 866.099816318328, 'gamma': 0.830377712198797}, {'C': 539.1614492475574, 'gamma': 0.9225693725672236}, {'C': 98.14647976501556, 'gamma': 0.10294749316074948}, {'C': 702.5072956958257, 'gamma': 0.8905798691284313}, {'C': 160.56030089820405, 'gamma': 0.2756725448969536}, {'C': 673.4915296568056, 'gamma': 0.1644031240201702}, {'C': 702.3711366090863, 'gamma': 0.48773522220572807}, {'C': 681.6777681763589, 'gamma': 0.5216481923258594}, {'C': 44.39669443408434, 'gamma': 0.22403660350197763}, {'C': 576.2050868680129, 'gamma': 0.1205336601272924}, {'C': 501.11671380079326, 'gamma': 0.13810956825889598}, {'C': 53.80840108926621, 'gamma': 0.17837692253615167}], 'split0_test_score': array([0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778,\n",
      "       0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778,\n",
      "       0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778,\n",
      "       0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778,\n",
      "       0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778,\n",
      "       0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778]), 'split1_test_score': array([0.78111588, 0.78111588, 0.78111588, 0.78111588, 0.78111588,\n",
      "       0.78111588, 0.78111588, 0.78111588, 0.78111588, 0.78111588,\n",
      "       0.78111588, 0.78111588, 0.78111588, 0.78111588, 0.78111588,\n",
      "       0.78111588, 0.78111588, 0.78111588, 0.78111588, 0.78111588,\n",
      "       0.78111588, 0.78111588, 0.78111588, 0.78111588, 0.78111588,\n",
      "       0.78111588, 0.78111588, 0.78111588, 0.78111588, 0.78111588]), 'split2_test_score': array([0.78111588, 0.78111588, 0.78111588, 0.78111588, 0.78111588,\n",
      "       0.78111588, 0.78111588, 0.78111588, 0.78111588, 0.78111588,\n",
      "       0.78111588, 0.78111588, 0.78111588, 0.78111588, 0.78111588,\n",
      "       0.78111588, 0.78111588, 0.78111588, 0.78111588, 0.78111588,\n",
      "       0.78111588, 0.78111588, 0.78111588, 0.78111588, 0.78111588,\n",
      "       0.78111588, 0.78111588, 0.78111588, 0.78111588, 0.78111588]), 'mean_test_score': array([0.78000318, 0.78000318, 0.78000318, 0.78000318, 0.78000318,\n",
      "       0.78000318, 0.78000318, 0.78000318, 0.78000318, 0.78000318,\n",
      "       0.78000318, 0.78000318, 0.78000318, 0.78000318, 0.78000318,\n",
      "       0.78000318, 0.78000318, 0.78000318, 0.78000318, 0.78000318,\n",
      "       0.78000318, 0.78000318, 0.78000318, 0.78000318, 0.78000318,\n",
      "       0.78000318, 0.78000318, 0.78000318, 0.78000318, 0.78000318]), 'std_test_score': array([0.0015736, 0.0015736, 0.0015736, 0.0015736, 0.0015736, 0.0015736,\n",
      "       0.0015736, 0.0015736, 0.0015736, 0.0015736, 0.0015736, 0.0015736,\n",
      "       0.0015736, 0.0015736, 0.0015736, 0.0015736, 0.0015736, 0.0015736,\n",
      "       0.0015736, 0.0015736, 0.0015736, 0.0015736, 0.0015736, 0.0015736,\n",
      "       0.0015736, 0.0015736, 0.0015736, 0.0015736, 0.0015736, 0.0015736]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "Best SVC() Parameters\n",
      "{'C': 517.3986277024461, 'gamma': 0.5707675868681398}\n",
      "Confusion Matrix - Rows = 1,000\n",
      "[[  0  68]\n",
      " [  0 232]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       0.77      1.00      0.87       232\n",
      "\n",
      "    accuracy                           0.77       300\n",
      "   macro avg       0.39      0.50      0.44       300\n",
      "weighted avg       0.60      0.77      0.67       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "rand_list = {'C': stats.uniform(1,1000), 'gamma':stats.uniform(0.0001,1)}\n",
    "rand_search = RandomizedSearchCV(SVC(),param_distributions = rand_list, n_iter = 30, n_jobs=4, cv = 3, refit = True, random_state = 101, verbose = 1)\n",
    "rand_search.fit(X_train,y_train)\n",
    "\n",
    "print ('Results for SVM with Randomized Search 3-CV, Rows = 1000')\n",
    "print(rand_search.cv_results_)\n",
    "\n",
    "print('Best SVC() Parameters')\n",
    "print(rand_search.best_params_)\n",
    "\n",
    "rand_predictions=rand_search.predict(X_test)\n",
    "print('Confusion Matrix - Rows = 1,000')\n",
    "CFM = confusion_matrix(y_test,rand_predictions,labels =[0,1])\n",
    "print(CFM)\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test,rand_predictions,labels = [0,1]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_H2000 = horizontal_stack.sample(n=2000, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine with Hyperparameter Tuning \n",
    "\n",
    "# Separate target and feature variables into separate data sets\n",
    "\n",
    "Y2000 = df_H2000['target']\n",
    "X2000 = df_H2000.drop(['target'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1518\n",
       "0     482\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2000.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split( \n",
    "                        X2000, Y2000, test_size = 0.30, random_state = 101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Results for SVM with Randomized Search 3-CV, Rows = 2000\n",
      "{'mean_fit_time': array([0.12345982, 0.08480493, 0.08579628, 0.09868519, 0.10454488,\n",
      "       0.10016505, 0.10685698, 0.11526879, 0.08651781, 0.09263515,\n",
      "       0.08991146, 0.07884518, 0.09416429, 0.08973598, 0.09416119,\n",
      "       0.10414195, 0.0937283 , 0.08330448, 0.09371853, 0.08366855,\n",
      "       0.08331394, 0.08331386, 0.08890335, 0.08331386, 0.09894379,\n",
      "       0.09373657, 0.08851043, 0.1049823 , 0.08485428, 0.09963473]), 'std_fit_time': array([5.80895142e-03, 7.51488586e-03, 6.86943859e-03, 8.28696955e-03,\n",
      "       6.94907944e-03, 5.94231041e-03, 2.73828921e-02, 3.14723179e-02,\n",
      "       1.00107790e-02, 1.21030811e-02, 6.85486168e-03, 1.04411793e-03,\n",
      "       6.37929244e-04, 7.36687262e-03, 1.22285094e-02, 1.47277947e-02,\n",
      "       2.38474204e-05, 7.35052277e-03, 1.40012144e-05, 7.12743132e-03,\n",
      "       7.36490890e-03, 7.36378499e-03, 7.64906661e-03, 7.36530227e-03,\n",
      "       1.94953183e-02, 1.27540674e-02, 7.37867687e-03, 2.03953024e-02,\n",
      "       8.05617341e-03, 7.62244871e-03]), 'mean_score_time': array([0.07764212, 0.07758673, 0.0781064 , 0.06769188, 0.08366617,\n",
      "       0.09512067, 0.07327374, 0.07821695, 0.07978161, 0.07290125,\n",
      "       0.08332316, 0.0735863 , 0.06282043, 0.06248522, 0.08852053,\n",
      "       0.06770261, 0.07289886, 0.07846125, 0.06840142, 0.06248434,\n",
      "       0.06807351, 0.07887109, 0.07290053, 0.07810672, 0.07290053,\n",
      "       0.07809718, 0.078456  , 0.10533245, 0.07894603, 0.0676926 ]), 'std_score_time': array([3.99553319e-03, 6.93456175e-04, 1.27548391e-02, 7.36384118e-03,\n",
      "       2.99560693e-02, 3.37763854e-02, 7.60919786e-03, 1.28914471e-02,\n",
      "       1.48298147e-02, 7.36490894e-03, 1.94803903e-02, 7.12557656e-03,\n",
      "       4.75416451e-04, 3.37174788e-07, 2.65509563e-02, 7.37732820e-03,\n",
      "       7.36410457e-03, 5.02165802e-04, 7.62726492e-03, 4.05233662e-07,\n",
      "       7.10991295e-03, 1.27664611e-02, 7.36372879e-03, 4.05233662e-07,\n",
      "       7.36440321e-03, 1.37131565e-05, 4.95591211e-04, 2.95732998e-02,\n",
      "       1.18657437e-03, 7.36535846e-03]), 'param_C': masked_array(data=[517.3986277024461, 29.47422647809694,\n",
      "                   686.2769816973125, 307.9662196722378,\n",
      "                   722.5438617683046, 555.2275911247872,\n",
      "                   182.89240266007866, 966.4832224119692,\n",
      "                   84.56143366334368, 729.9927572876178,\n",
      "                   686.3063287801783, 49.48453742640058,\n",
      "                   187.96742613792105, 521.6653966849669,\n",
      "                   735.8190582693819, 914.1535576757685,\n",
      "                   403.99783069378736, 953.8767147108732,\n",
      "                   866.099816318328, 539.1614492475574, 98.14647976501556,\n",
      "                   702.5072956958257, 160.56030089820405,\n",
      "                   673.4915296568056, 702.3711366090863,\n",
      "                   681.6777681763589, 44.39669443408434,\n",
      "                   576.2050868680129, 501.11671380079326,\n",
      "                   53.80840108926621],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.5707675868681398, 0.17162165622510306,\n",
      "                   0.8339968626360765, 0.8937130796833973,\n",
      "                   0.19003895420479677, 0.3522319540266141,\n",
      "                   0.7857017618643588, 0.23245366181476068,\n",
      "                   0.6036484222912185, 0.27633882849726277,\n",
      "                   0.5179674741970474, 0.1379692375621061,\n",
      "                   0.994417901154097, 0.5788895354754169,\n",
      "                   0.5420617722295935, 0.8080201509879171,\n",
      "                   0.35732434282078784, 0.3437315778925598,\n",
      "                   0.830377712198797, 0.9225693725672236,\n",
      "                   0.10294749316074948, 0.8905798691284313,\n",
      "                   0.2756725448969536, 0.1644031240201702,\n",
      "                   0.48773522220572807, 0.5216481923258594,\n",
      "                   0.22403660350197763, 0.1205336601272924,\n",
      "                   0.13810956825889598, 0.17837692253615167],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 517.3986277024461, 'gamma': 0.5707675868681398}, {'C': 29.47422647809694, 'gamma': 0.17162165622510306}, {'C': 686.2769816973125, 'gamma': 0.8339968626360765}, {'C': 307.9662196722378, 'gamma': 0.8937130796833973}, {'C': 722.5438617683046, 'gamma': 0.19003895420479677}, {'C': 555.2275911247872, 'gamma': 0.3522319540266141}, {'C': 182.89240266007866, 'gamma': 0.7857017618643588}, {'C': 966.4832224119692, 'gamma': 0.23245366181476068}, {'C': 84.56143366334368, 'gamma': 0.6036484222912185}, {'C': 729.9927572876178, 'gamma': 0.27633882849726277}, {'C': 686.3063287801783, 'gamma': 0.5179674741970474}, {'C': 49.48453742640058, 'gamma': 0.1379692375621061}, {'C': 187.96742613792105, 'gamma': 0.994417901154097}, {'C': 521.6653966849669, 'gamma': 0.5788895354754169}, {'C': 735.8190582693819, 'gamma': 0.5420617722295935}, {'C': 914.1535576757685, 'gamma': 0.8080201509879171}, {'C': 403.99783069378736, 'gamma': 0.35732434282078784}, {'C': 953.8767147108732, 'gamma': 0.3437315778925598}, {'C': 866.099816318328, 'gamma': 0.830377712198797}, {'C': 539.1614492475574, 'gamma': 0.9225693725672236}, {'C': 98.14647976501556, 'gamma': 0.10294749316074948}, {'C': 702.5072956958257, 'gamma': 0.8905798691284313}, {'C': 160.56030089820405, 'gamma': 0.2756725448969536}, {'C': 673.4915296568056, 'gamma': 0.1644031240201702}, {'C': 702.3711366090863, 'gamma': 0.48773522220572807}, {'C': 681.6777681763589, 'gamma': 0.5216481923258594}, {'C': 44.39669443408434, 'gamma': 0.22403660350197763}, {'C': 576.2050868680129, 'gamma': 0.1205336601272924}, {'C': 501.11671380079326, 'gamma': 0.13810956825889598}, {'C': 53.80840108926621, 'gamma': 0.17837692253615167}], 'split0_test_score': array([0.76017131, 0.76017131, 0.76017131, 0.76017131, 0.76017131,\n",
      "       0.76017131, 0.76017131, 0.76017131, 0.76017131, 0.76017131,\n",
      "       0.76017131, 0.76017131, 0.76017131, 0.76017131, 0.76017131,\n",
      "       0.76017131, 0.76017131, 0.76017131, 0.76017131, 0.76017131,\n",
      "       0.76017131, 0.76017131, 0.76017131, 0.76017131, 0.76017131,\n",
      "       0.76017131, 0.76017131, 0.76017131, 0.76017131, 0.76017131]), 'split1_test_score': array([0.76017131, 0.76017131, 0.76017131, 0.76017131, 0.76017131,\n",
      "       0.76017131, 0.76017131, 0.76017131, 0.76017131, 0.76017131,\n",
      "       0.76017131, 0.76017131, 0.76017131, 0.76017131, 0.76017131,\n",
      "       0.76017131, 0.76017131, 0.76017131, 0.76017131, 0.76017131,\n",
      "       0.76017131, 0.76017131, 0.76017131, 0.76017131, 0.76017131,\n",
      "       0.76017131, 0.76017131, 0.76017131, 0.76017131, 0.76017131]), 'split2_test_score': array([0.76180258, 0.76180258, 0.76180258, 0.76180258, 0.76180258,\n",
      "       0.76180258, 0.76180258, 0.76180258, 0.76180258, 0.76180258,\n",
      "       0.76180258, 0.76180258, 0.76180258, 0.76180258, 0.76180258,\n",
      "       0.76180258, 0.76180258, 0.76180258, 0.76180258, 0.76180258,\n",
      "       0.76180258, 0.76180258, 0.76180258, 0.76180258, 0.76180258,\n",
      "       0.76180258, 0.76180258, 0.76180258, 0.76180258, 0.76180258]), 'mean_test_score': array([0.76071506, 0.76071506, 0.76071506, 0.76071506, 0.76071506,\n",
      "       0.76071506, 0.76071506, 0.76071506, 0.76071506, 0.76071506,\n",
      "       0.76071506, 0.76071506, 0.76071506, 0.76071506, 0.76071506,\n",
      "       0.76071506, 0.76071506, 0.76071506, 0.76071506, 0.76071506,\n",
      "       0.76071506, 0.76071506, 0.76071506, 0.76071506, 0.76071506,\n",
      "       0.76071506, 0.76071506, 0.76071506, 0.76071506, 0.76071506]), 'std_test_score': array([0.00076899, 0.00076899, 0.00076899, 0.00076899, 0.00076899,\n",
      "       0.00076899, 0.00076899, 0.00076899, 0.00076899, 0.00076899,\n",
      "       0.00076899, 0.00076899, 0.00076899, 0.00076899, 0.00076899,\n",
      "       0.00076899, 0.00076899, 0.00076899, 0.00076899, 0.00076899,\n",
      "       0.00076899, 0.00076899, 0.00076899, 0.00076899, 0.00076899,\n",
      "       0.00076899, 0.00076899, 0.00076899, 0.00076899, 0.00076899]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "Best SVC() Parameters\n",
      "{'C': 517.3986277024461, 'gamma': 0.5707675868681398}\n",
      "Confusion Matrix - Rows = 2,000\n",
      "[[  0 147]\n",
      " [  0 453]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       147\n",
      "           1       0.76      1.00      0.86       453\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.38      0.50      0.43       600\n",
      "weighted avg       0.57      0.76      0.65       600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rand_list2 = {'C': stats.uniform(1,1000), 'gamma':stats.uniform(0.0001,1)}\n",
    "rand_search2 = RandomizedSearchCV(SVC(),param_distributions = rand_list2, n_iter = 30, n_jobs=4, cv = 3, refit = True, random_state = 101, verbose = 1)\n",
    "rand_search2.fit(X_train2,y_train2)\n",
    "\n",
    "print ('Results for SVM with Randomized Search 3-CV, Rows = 2000')\n",
    "print(rand_search2.cv_results_)\n",
    "\n",
    "print('Best SVC() Parameters')\n",
    "print(rand_search2.best_params_)\n",
    "\n",
    "rand_predictions2=rand_search2.predict(X_test2)\n",
    "print('Confusion Matrix - Rows = 2,000')\n",
    "CFM2 = confusion_matrix(y_test2,rand_predictions2,labels =[0,1])\n",
    "print(CFM2)\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test2,rand_predictions2,labels = [0,1]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_H5000 = horizontal_stack.sample(n=5000, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine with Hyperparameter Tuning \n",
    "\n",
    "# Separate target and feature variables into separate data sets\n",
    "\n",
    "Y5000 = df_H5000['target']\n",
    "X5000 = df_H5000.drop(['target'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3798\n",
       "0    1202\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y5000.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "X_train5, X_test5, y_train5, y_test5 = train_test_split( \n",
    "                        X5000, Y5000, test_size = 0.30, random_state = 101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Results for SVM with Randomized Search 3-CV, Rows = 5000\n",
      "{'mean_fit_time': array([0.64541753, 0.61695711, 0.60115623, 0.65089671, 0.6250368 ,\n",
      "       0.57491207, 0.57583777, 0.57583316, 0.54955721, 0.53788471,\n",
      "       0.54789559, 0.55840532, 0.52868573, 0.59578164, 0.57990829,\n",
      "       0.54047251, 0.56389976, 0.56386757, 0.52997557, 0.54892047,\n",
      "       0.52438505, 0.52950406, 0.53278677, 0.53740525, 0.53224683,\n",
      "       0.53708728, 0.55265872, 0.55068723, 0.54975589, 0.53188602]), 'std_fit_time': array([0.02189631, 0.05021263, 0.08327365, 0.03681196, 0.03383056,\n",
      "       0.03758515, 0.00661717, 0.02653858, 0.02151495, 0.01508248,\n",
      "       0.01280763, 0.00736401, 0.00725508, 0.07761367, 0.06784652,\n",
      "       0.01496659, 0.03357045, 0.0260543 , 0.01016148, 0.01411961,\n",
      "       0.01348992, 0.01303788, 0.02173382, 0.00736373, 0.0126821 ,\n",
      "       0.03157872, 0.03859009, 0.01324109, 0.01706529, 0.02500043]), 'mean_score_time': array([0.5006307 , 0.49493178, 0.55725312, 0.51580238, 0.44339617,\n",
      "       0.44331543, 0.43849619, 0.4345293 , 0.45372566, 0.44370929,\n",
      "       0.45414186, 0.43290599, 0.45924695, 0.46382944, 0.45468807,\n",
      "       0.46389119, 0.4903024 , 0.48087064, 0.4619538 , 0.44587811,\n",
      "       0.46698944, 0.46947964, 0.44860617, 0.46468353, 0.44898558,\n",
      "       0.45898787, 0.45621657, 0.44786604, 0.4622949 , 0.40771055]), 'std_score_time': array([3.37317478e-02, 4.44653948e-02, 7.80540504e-02, 5.10304527e-02,\n",
      "       7.55537346e-03, 1.90045897e-02, 2.55692734e-05, 7.35142190e-03,\n",
      "       1.23236609e-02, 7.42515079e-03, 8.58110388e-05, 7.87055869e-03,\n",
      "       1.92614126e-02, 7.64002914e-03, 1.12138017e-02, 2.61350383e-02,\n",
      "       1.44425575e-02, 4.89971775e-02, 1.18439281e-02, 8.26707786e-03,\n",
      "       2.04758989e-02, 3.33113739e-02, 7.94860108e-03, 1.94933665e-02,\n",
      "       1.46497389e-02, 1.89977518e-02, 1.40856095e-02, 6.42243400e-03,\n",
      "       2.35489925e-02, 1.32506244e-02]), 'param_C': masked_array(data=[517.3986277024461, 29.47422647809694,\n",
      "                   686.2769816973125, 307.9662196722378,\n",
      "                   722.5438617683046, 555.2275911247872,\n",
      "                   182.89240266007866, 966.4832224119692,\n",
      "                   84.56143366334368, 729.9927572876178,\n",
      "                   686.3063287801783, 49.48453742640058,\n",
      "                   187.96742613792105, 521.6653966849669,\n",
      "                   735.8190582693819, 914.1535576757685,\n",
      "                   403.99783069378736, 953.8767147108732,\n",
      "                   866.099816318328, 539.1614492475574, 98.14647976501556,\n",
      "                   702.5072956958257, 160.56030089820405,\n",
      "                   673.4915296568056, 702.3711366090863,\n",
      "                   681.6777681763589, 44.39669443408434,\n",
      "                   576.2050868680129, 501.11671380079326,\n",
      "                   53.80840108926621],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.5707675868681398, 0.17162165622510306,\n",
      "                   0.8339968626360765, 0.8937130796833973,\n",
      "                   0.19003895420479677, 0.3522319540266141,\n",
      "                   0.7857017618643588, 0.23245366181476068,\n",
      "                   0.6036484222912185, 0.27633882849726277,\n",
      "                   0.5179674741970474, 0.1379692375621061,\n",
      "                   0.994417901154097, 0.5788895354754169,\n",
      "                   0.5420617722295935, 0.8080201509879171,\n",
      "                   0.35732434282078784, 0.3437315778925598,\n",
      "                   0.830377712198797, 0.9225693725672236,\n",
      "                   0.10294749316074948, 0.8905798691284313,\n",
      "                   0.2756725448969536, 0.1644031240201702,\n",
      "                   0.48773522220572807, 0.5216481923258594,\n",
      "                   0.22403660350197763, 0.1205336601272924,\n",
      "                   0.13810956825889598, 0.17837692253615167],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 517.3986277024461, 'gamma': 0.5707675868681398}, {'C': 29.47422647809694, 'gamma': 0.17162165622510306}, {'C': 686.2769816973125, 'gamma': 0.8339968626360765}, {'C': 307.9662196722378, 'gamma': 0.8937130796833973}, {'C': 722.5438617683046, 'gamma': 0.19003895420479677}, {'C': 555.2275911247872, 'gamma': 0.3522319540266141}, {'C': 182.89240266007866, 'gamma': 0.7857017618643588}, {'C': 966.4832224119692, 'gamma': 0.23245366181476068}, {'C': 84.56143366334368, 'gamma': 0.6036484222912185}, {'C': 729.9927572876178, 'gamma': 0.27633882849726277}, {'C': 686.3063287801783, 'gamma': 0.5179674741970474}, {'C': 49.48453742640058, 'gamma': 0.1379692375621061}, {'C': 187.96742613792105, 'gamma': 0.994417901154097}, {'C': 521.6653966849669, 'gamma': 0.5788895354754169}, {'C': 735.8190582693819, 'gamma': 0.5420617722295935}, {'C': 914.1535576757685, 'gamma': 0.8080201509879171}, {'C': 403.99783069378736, 'gamma': 0.35732434282078784}, {'C': 953.8767147108732, 'gamma': 0.3437315778925598}, {'C': 866.099816318328, 'gamma': 0.830377712198797}, {'C': 539.1614492475574, 'gamma': 0.9225693725672236}, {'C': 98.14647976501556, 'gamma': 0.10294749316074948}, {'C': 702.5072956958257, 'gamma': 0.8905798691284313}, {'C': 160.56030089820405, 'gamma': 0.2756725448969536}, {'C': 673.4915296568056, 'gamma': 0.1644031240201702}, {'C': 702.3711366090863, 'gamma': 0.48773522220572807}, {'C': 681.6777681763589, 'gamma': 0.5216481923258594}, {'C': 44.39669443408434, 'gamma': 0.22403660350197763}, {'C': 576.2050868680129, 'gamma': 0.1205336601272924}, {'C': 501.11671380079326, 'gamma': 0.13810956825889598}, {'C': 53.80840108926621, 'gamma': 0.17837692253615167}], 'split0_test_score': array([0.75835476, 0.75835476, 0.75835476, 0.75835476, 0.75835476,\n",
      "       0.75835476, 0.75835476, 0.75835476, 0.75835476, 0.75835476,\n",
      "       0.75835476, 0.75835476, 0.75835476, 0.75835476, 0.75835476,\n",
      "       0.75835476, 0.75835476, 0.75835476, 0.75835476, 0.75835476,\n",
      "       0.75835476, 0.75835476, 0.75835476, 0.75835476, 0.75835476,\n",
      "       0.75835476, 0.75835476, 0.75835476, 0.75835476, 0.75835476]), 'split1_test_score': array([0.75835476, 0.75835476, 0.75835476, 0.75835476, 0.75835476,\n",
      "       0.75835476, 0.75835476, 0.75835476, 0.75835476, 0.75835476,\n",
      "       0.75835476, 0.75835476, 0.75835476, 0.75835476, 0.75835476,\n",
      "       0.75835476, 0.75835476, 0.75835476, 0.75835476, 0.75835476,\n",
      "       0.75835476, 0.75835476, 0.75835476, 0.75835476, 0.75835476,\n",
      "       0.75835476, 0.75835476, 0.75835476, 0.75835476, 0.75835476]), 'split2_test_score': array([0.75814751, 0.75814751, 0.75814751, 0.75814751, 0.75814751,\n",
      "       0.75814751, 0.75814751, 0.75814751, 0.75814751, 0.75814751,\n",
      "       0.75814751, 0.75814751, 0.75814751, 0.75814751, 0.75814751,\n",
      "       0.75814751, 0.75814751, 0.75814751, 0.75814751, 0.75814751,\n",
      "       0.75814751, 0.75814751, 0.75814751, 0.75814751, 0.75814751,\n",
      "       0.75814751, 0.75814751, 0.75814751, 0.75814751, 0.75814751]), 'mean_test_score': array([0.75828567, 0.75828567, 0.75828567, 0.75828567, 0.75828567,\n",
      "       0.75828567, 0.75828567, 0.75828567, 0.75828567, 0.75828567,\n",
      "       0.75828567, 0.75828567, 0.75828567, 0.75828567, 0.75828567,\n",
      "       0.75828567, 0.75828567, 0.75828567, 0.75828567, 0.75828567,\n",
      "       0.75828567, 0.75828567, 0.75828567, 0.75828567, 0.75828567,\n",
      "       0.75828567, 0.75828567, 0.75828567, 0.75828567, 0.75828567]), 'std_test_score': array([9.76952492e-05, 9.76952492e-05, 9.76952492e-05, 9.76952492e-05,\n",
      "       9.76952492e-05, 9.76952492e-05, 9.76952492e-05, 9.76952492e-05,\n",
      "       9.76952492e-05, 9.76952492e-05, 9.76952492e-05, 9.76952492e-05,\n",
      "       9.76952492e-05, 9.76952492e-05, 9.76952492e-05, 9.76952492e-05,\n",
      "       9.76952492e-05, 9.76952492e-05, 9.76952492e-05, 9.76952492e-05,\n",
      "       9.76952492e-05, 9.76952492e-05, 9.76952492e-05, 9.76952492e-05,\n",
      "       9.76952492e-05, 9.76952492e-05, 9.76952492e-05, 9.76952492e-05,\n",
      "       9.76952492e-05, 9.76952492e-05]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "Best SVC() Parameters\n",
      "{'C': 517.3986277024461, 'gamma': 0.5707675868681398}\n",
      "Confusion Matrix - Rows = 5,000\n",
      "[[   0  356]\n",
      " [   0 1144]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       356\n",
      "           1       0.76      1.00      0.87      1144\n",
      "\n",
      "    accuracy                           0.76      1500\n",
      "   macro avg       0.38      0.50      0.43      1500\n",
      "weighted avg       0.58      0.76      0.66      1500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rand_list5 = {'C': stats.uniform(1,1000), 'gamma':stats.uniform(0.0001,1)}\n",
    "rand_search5 = RandomizedSearchCV(SVC(),param_distributions = rand_list5, n_iter = 30, n_jobs=4, cv = 3, refit = True, random_state = 101, verbose = 1)\n",
    "rand_search5.fit(X_train5,y_train5)\n",
    "\n",
    "print ('Results for SVM with Randomized Search 3-CV, Rows = 5000')\n",
    "print(rand_search5.cv_results_)\n",
    "\n",
    "print('Best SVC() Parameters')\n",
    "print(rand_search5.best_params_)\n",
    "\n",
    "rand_predictions5=rand_search5.predict(X_test5)\n",
    "print('Confusion Matrix - Rows = 5,000')\n",
    "CFM5 = confusion_matrix(y_test5,rand_predictions5,labels =[0,1])\n",
    "print(CFM5)\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test5,rand_predictions5,labels = [0,1]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_H10000 = horizontal_stack.sample(n=10000, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine with Hyperparameter Tuning \n",
    "\n",
    "# Separate target and feature variables into separate data sets\n",
    "\n",
    "Y10000 = df_H10000['target']\n",
    "X10000 = df_H10000.drop(['target'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7593\n",
       "0    2407\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y10000.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "X_train10, X_test10, y_train10, y_test10 = train_test_split( \n",
    "                        X10000, Y10000, test_size = 0.30, random_state = 101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Results for SVM with Randomized Search 3-CV, Rows = 10000\n",
      "{'mean_fit_time': array([3.52038177, 3.57033547, 3.57059924, 3.47048291, 3.48401658,\n",
      "       3.59704002, 3.59278584, 3.34103346, 3.41686932, 3.45519551,\n",
      "       3.2884353 , 3.34823998, 3.24093596, 3.42217811, 3.33653108,\n",
      "       3.24890057, 3.11534039, 3.08588163, 3.06858134, 3.12029966,\n",
      "       2.72695581, 2.75830253, 2.98155165, 2.84462667, 2.74132125,\n",
      "       2.74711593, 2.94504213, 2.86117824, 2.91014187, 2.89900788]), 'std_fit_time': array([0.01845849, 0.08423283, 0.07016793, 0.03508372, 0.02692799,\n",
      "       0.11420797, 0.09727228, 0.02702875, 0.05676155, 0.01591014,\n",
      "       0.0128724 , 0.03364099, 0.06770051, 0.13664532, 0.15242033,\n",
      "       0.03369059, 0.10971061, 0.17319806, 0.23455939, 0.04062039,\n",
      "       0.29726834, 0.16732159, 0.12059417, 0.17635016, 0.1782544 ,\n",
      "       0.19473456, 0.05303346, 0.16310146, 0.07708606, 0.16260545]), 'mean_score_time': array([1.91182836, 1.94845398, 1.96532067, 1.92930365, 1.93821367,\n",
      "       2.01285561, 2.02598174, 1.94975416, 1.95835956, 1.92068458,\n",
      "       1.95052481, 1.94602466, 2.00665212, 1.99001098, 1.99969769,\n",
      "       1.9605484 , 1.96966394, 2.02751573, 2.02778983, 2.26228992,\n",
      "       2.05014698, 2.08485333, 2.03797332, 2.04843219, 2.07444779,\n",
      "       2.07134573, 2.0739785 , 2.07946738, 2.05487728, 1.81770945]), 'std_score_time': array([0.02209248, 0.09221245, 0.10235222, 0.03912045, 0.01814145,\n",
      "       0.01593763, 0.1102362 , 0.02917202, 0.03527374, 0.02094153,\n",
      "       0.03263347, 0.03297312, 0.0351949 , 0.0869092 , 0.02854417,\n",
      "       0.04236475, 0.03813727, 0.08421454, 0.05046264, 0.26246017,\n",
      "       0.05928545, 0.03638657, 0.04005891, 0.03274625, 0.03750042,\n",
      "       0.04022298, 0.02669362, 0.03481593, 0.03175416, 0.12648687]), 'param_C': masked_array(data=[517.3986277024461, 29.47422647809694,\n",
      "                   686.2769816973125, 307.9662196722378,\n",
      "                   722.5438617683046, 555.2275911247872,\n",
      "                   182.89240266007866, 966.4832224119692,\n",
      "                   84.56143366334368, 729.9927572876178,\n",
      "                   686.3063287801783, 49.48453742640058,\n",
      "                   187.96742613792105, 521.6653966849669,\n",
      "                   735.8190582693819, 914.1535576757685,\n",
      "                   403.99783069378736, 953.8767147108732,\n",
      "                   866.099816318328, 539.1614492475574, 98.14647976501556,\n",
      "                   702.5072956958257, 160.56030089820405,\n",
      "                   673.4915296568056, 702.3711366090863,\n",
      "                   681.6777681763589, 44.39669443408434,\n",
      "                   576.2050868680129, 501.11671380079326,\n",
      "                   53.80840108926621],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.5707675868681398, 0.17162165622510306,\n",
      "                   0.8339968626360765, 0.8937130796833973,\n",
      "                   0.19003895420479677, 0.3522319540266141,\n",
      "                   0.7857017618643588, 0.23245366181476068,\n",
      "                   0.6036484222912185, 0.27633882849726277,\n",
      "                   0.5179674741970474, 0.1379692375621061,\n",
      "                   0.994417901154097, 0.5788895354754169,\n",
      "                   0.5420617722295935, 0.8080201509879171,\n",
      "                   0.35732434282078784, 0.3437315778925598,\n",
      "                   0.830377712198797, 0.9225693725672236,\n",
      "                   0.10294749316074948, 0.8905798691284313,\n",
      "                   0.2756725448969536, 0.1644031240201702,\n",
      "                   0.48773522220572807, 0.5216481923258594,\n",
      "                   0.22403660350197763, 0.1205336601272924,\n",
      "                   0.13810956825889598, 0.17837692253615167],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 517.3986277024461, 'gamma': 0.5707675868681398}, {'C': 29.47422647809694, 'gamma': 0.17162165622510306}, {'C': 686.2769816973125, 'gamma': 0.8339968626360765}, {'C': 307.9662196722378, 'gamma': 0.8937130796833973}, {'C': 722.5438617683046, 'gamma': 0.19003895420479677}, {'C': 555.2275911247872, 'gamma': 0.3522319540266141}, {'C': 182.89240266007866, 'gamma': 0.7857017618643588}, {'C': 966.4832224119692, 'gamma': 0.23245366181476068}, {'C': 84.56143366334368, 'gamma': 0.6036484222912185}, {'C': 729.9927572876178, 'gamma': 0.27633882849726277}, {'C': 686.3063287801783, 'gamma': 0.5179674741970474}, {'C': 49.48453742640058, 'gamma': 0.1379692375621061}, {'C': 187.96742613792105, 'gamma': 0.994417901154097}, {'C': 521.6653966849669, 'gamma': 0.5788895354754169}, {'C': 735.8190582693819, 'gamma': 0.5420617722295935}, {'C': 914.1535576757685, 'gamma': 0.8080201509879171}, {'C': 403.99783069378736, 'gamma': 0.35732434282078784}, {'C': 953.8767147108732, 'gamma': 0.3437315778925598}, {'C': 866.099816318328, 'gamma': 0.830377712198797}, {'C': 539.1614492475574, 'gamma': 0.9225693725672236}, {'C': 98.14647976501556, 'gamma': 0.10294749316074948}, {'C': 702.5072956958257, 'gamma': 0.8905798691284313}, {'C': 160.56030089820405, 'gamma': 0.2756725448969536}, {'C': 673.4915296568056, 'gamma': 0.1644031240201702}, {'C': 702.3711366090863, 'gamma': 0.48773522220572807}, {'C': 681.6777681763589, 'gamma': 0.5216481923258594}, {'C': 44.39669443408434, 'gamma': 0.22403660350197763}, {'C': 576.2050868680129, 'gamma': 0.1205336601272924}, {'C': 501.11671380079326, 'gamma': 0.13810956825889598}, {'C': 53.80840108926621, 'gamma': 0.17837692253615167}], 'split0_test_score': array([0.7613539, 0.7613539, 0.7613539, 0.7613539, 0.7613539, 0.7613539,\n",
      "       0.7613539, 0.7613539, 0.7613539, 0.7613539, 0.7613539, 0.7613539,\n",
      "       0.7613539, 0.7613539, 0.7613539, 0.7613539, 0.7613539, 0.7613539,\n",
      "       0.7613539, 0.7613539, 0.7613539, 0.7613539, 0.7613539, 0.7613539,\n",
      "       0.7613539, 0.7613539, 0.7613539, 0.7613539, 0.7613539, 0.7613539]), 'split1_test_score': array([0.76168024, 0.76168024, 0.76168024, 0.76168024, 0.76168024,\n",
      "       0.76168024, 0.76168024, 0.76168024, 0.76168024, 0.76168024,\n",
      "       0.76168024, 0.76168024, 0.76168024, 0.76168024, 0.76168024,\n",
      "       0.76168024, 0.76168024, 0.76168024, 0.76168024, 0.76168024,\n",
      "       0.76168024, 0.76168024, 0.76168024, 0.76168024, 0.76168024,\n",
      "       0.76168024, 0.76168024, 0.76168024, 0.76168024, 0.76168024]), 'split2_test_score': array([0.76168024, 0.76168024, 0.76168024, 0.76168024, 0.76168024,\n",
      "       0.76168024, 0.76168024, 0.76168024, 0.76168024, 0.76168024,\n",
      "       0.76168024, 0.76168024, 0.76168024, 0.76168024, 0.76168024,\n",
      "       0.76168024, 0.76168024, 0.76168024, 0.76168024, 0.76168024,\n",
      "       0.76168024, 0.76168024, 0.76168024, 0.76168024, 0.76168024,\n",
      "       0.76168024, 0.76168024, 0.76168024, 0.76168024, 0.76168024]), 'mean_test_score': array([0.76157146, 0.76157146, 0.76157146, 0.76157146, 0.76157146,\n",
      "       0.76157146, 0.76157146, 0.76157146, 0.76157146, 0.76157146,\n",
      "       0.76157146, 0.76157146, 0.76157146, 0.76157146, 0.76157146,\n",
      "       0.76157146, 0.76157146, 0.76157146, 0.76157146, 0.76157146,\n",
      "       0.76157146, 0.76157146, 0.76157146, 0.76157146, 0.76157146,\n",
      "       0.76157146, 0.76157146, 0.76157146, 0.76157146, 0.76157146]), 'std_test_score': array([0.00015384, 0.00015384, 0.00015384, 0.00015384, 0.00015384,\n",
      "       0.00015384, 0.00015384, 0.00015384, 0.00015384, 0.00015384,\n",
      "       0.00015384, 0.00015384, 0.00015384, 0.00015384, 0.00015384,\n",
      "       0.00015384, 0.00015384, 0.00015384, 0.00015384, 0.00015384,\n",
      "       0.00015384, 0.00015384, 0.00015384, 0.00015384, 0.00015384,\n",
      "       0.00015384, 0.00015384, 0.00015384, 0.00015384, 0.00015384]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "Best SVC() Parameters\n",
      "{'C': 517.3986277024461, 'gamma': 0.5707675868681398}\n",
      "Confusion Matrix - Rows = 10,000\n",
      "[[   0  738]\n",
      " [   0 2262]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       738\n",
      "           1       0.75      1.00      0.86      2262\n",
      "\n",
      "    accuracy                           0.75      3000\n",
      "   macro avg       0.38      0.50      0.43      3000\n",
      "weighted avg       0.57      0.75      0.65      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rand_list10 = {'C': stats.uniform(1,1000), 'gamma':stats.uniform(0.0001,1)}\n",
    "rand_search10 = RandomizedSearchCV(SVC(),param_distributions = rand_list10, n_iter = 30, n_jobs=4, cv = 3, refit = True, random_state = 101, verbose = 1)\n",
    "rand_search10.fit(X_train10,y_train10)\n",
    "\n",
    "print ('Results for SVM with Randomized Search 3-CV, Rows = 10000')\n",
    "print(rand_search10.cv_results_)\n",
    "\n",
    "print('Best SVC() Parameters')\n",
    "print(rand_search10.best_params_)\n",
    "\n",
    "rand_predictions10=rand_search10.predict(X_test10)\n",
    "print('Confusion Matrix - Rows = 10,000')\n",
    "CFM10 = confusion_matrix(y_test10,rand_predictions10,labels =[0,1])\n",
    "print(CFM10)\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test10,rand_predictions10,labels = [0,1]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_H50000 = horizontal_stack.sample(n=50000, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine with Hyperparameter Tuning \n",
    "\n",
    "# Separate target and feature variables into separate data sets\n",
    "\n",
    "Y50000 = df_H50000['target']\n",
    "X50000 = df_H50000.drop(['target'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    38138\n",
       "0    11862\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y50000.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "X_train50, X_test50, y_train50, y_test50 = train_test_split( \n",
    "                        X50000, Y50000, test_size = 0.30, random_state = 101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Results for SVM with Randomized Search 3-CV, Rows = 50000\n",
      "{'mean_fit_time': array([536.84340151, 537.75959651, 538.7595555 , 535.94890054,\n",
      "       503.00869862, 536.77806966, 474.34260909, 464.64144913,\n",
      "       530.48935795, 526.6572543 , 500.02553829, 523.95442629,\n",
      "       542.87410752, 552.64114761, 498.39000901, 528.53167049,\n",
      "       530.76054255, 518.92245928, 555.26290147, 562.55395524,\n",
      "       518.96970606, 564.39830287, 670.67697446, 675.12850722,\n",
      "       585.6218644 , 607.31080063, 611.73490524, 584.10467521,\n",
      "       535.04073159, 467.88434903]), 'std_fit_time': array([ 4.4346196 ,  4.06779751,  6.30595595,  6.40668215,  1.23709831,\n",
      "        2.18822373, 45.51717902, 39.26148411,  4.14974778,  2.61833355,\n",
      "       17.45926095, 29.32564864,  2.98158492,  3.18553589,  0.93110063,\n",
      "       12.95159395, 17.20366378, 20.44193666,  1.28389759,  1.90162868,\n",
      "       30.53752058, 68.07489393, 13.72048319,  1.25741367,  7.96626279,\n",
      "       22.98845845, 13.96520714, 12.39414761,  1.71930924, 32.14592562]), 'mean_score_time': array([ 52.23991934, 101.74142671, 104.71316028, 103.2881345 ,\n",
      "        57.74045714, 100.61588367,  53.10181308, 102.86539944,\n",
      "       105.0351882 ,  58.12878871, 104.06372778, 102.77647797,\n",
      "        54.46290723, 103.24167013,  57.65539869, 105.76851185,\n",
      "       104.6136388 , 104.18484926,  54.44661411,  58.28003502,\n",
      "       105.59934036, 118.58839353, 120.86190518,  69.70762547,\n",
      "       114.66398859,  63.98049506, 115.18351475, 105.39360245,\n",
      "        59.59495862,  95.81041257]), 'std_score_time': array([ 0.30130973, 65.70281757, 67.14860297, 65.31387398,  0.30878456,\n",
      "       67.95355861,  0.40267783, 67.06089849, 67.72986223,  0.21078707,\n",
      "       64.5515341 , 65.88297012,  2.86598184, 66.91679754,  1.19561046,\n",
      "       66.55869466, 65.69793706, 66.26190199,  0.44024504,  0.59203994,\n",
      "       67.30496495, 76.50033563, 74.27331498,  0.3493161 , 72.74198394,\n",
      "        1.7093756 , 75.55264211, 68.44658545,  0.71650927, 66.709197  ]), 'param_C': masked_array(data=[517.3986277024461, 29.47422647809694,\n",
      "                   686.2769816973125, 307.9662196722378,\n",
      "                   722.5438617683046, 555.2275911247872,\n",
      "                   182.89240266007866, 966.4832224119692,\n",
      "                   84.56143366334368, 729.9927572876178,\n",
      "                   686.3063287801783, 49.48453742640058,\n",
      "                   187.96742613792105, 521.6653966849669,\n",
      "                   735.8190582693819, 914.1535576757685,\n",
      "                   403.99783069378736, 953.8767147108732,\n",
      "                   866.099816318328, 539.1614492475574, 98.14647976501556,\n",
      "                   702.5072956958257, 160.56030089820405,\n",
      "                   673.4915296568056, 702.3711366090863,\n",
      "                   681.6777681763589, 44.39669443408434,\n",
      "                   576.2050868680129, 501.11671380079326,\n",
      "                   53.80840108926621],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.5707675868681398, 0.17162165622510306,\n",
      "                   0.8339968626360765, 0.8937130796833973,\n",
      "                   0.19003895420479677, 0.3522319540266141,\n",
      "                   0.7857017618643588, 0.23245366181476068,\n",
      "                   0.6036484222912185, 0.27633882849726277,\n",
      "                   0.5179674741970474, 0.1379692375621061,\n",
      "                   0.994417901154097, 0.5788895354754169,\n",
      "                   0.5420617722295935, 0.8080201509879171,\n",
      "                   0.35732434282078784, 0.3437315778925598,\n",
      "                   0.830377712198797, 0.9225693725672236,\n",
      "                   0.10294749316074948, 0.8905798691284313,\n",
      "                   0.2756725448969536, 0.1644031240201702,\n",
      "                   0.48773522220572807, 0.5216481923258594,\n",
      "                   0.22403660350197763, 0.1205336601272924,\n",
      "                   0.13810956825889598, 0.17837692253615167],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 517.3986277024461, 'gamma': 0.5707675868681398}, {'C': 29.47422647809694, 'gamma': 0.17162165622510306}, {'C': 686.2769816973125, 'gamma': 0.8339968626360765}, {'C': 307.9662196722378, 'gamma': 0.8937130796833973}, {'C': 722.5438617683046, 'gamma': 0.19003895420479677}, {'C': 555.2275911247872, 'gamma': 0.3522319540266141}, {'C': 182.89240266007866, 'gamma': 0.7857017618643588}, {'C': 966.4832224119692, 'gamma': 0.23245366181476068}, {'C': 84.56143366334368, 'gamma': 0.6036484222912185}, {'C': 729.9927572876178, 'gamma': 0.27633882849726277}, {'C': 686.3063287801783, 'gamma': 0.5179674741970474}, {'C': 49.48453742640058, 'gamma': 0.1379692375621061}, {'C': 187.96742613792105, 'gamma': 0.994417901154097}, {'C': 521.6653966849669, 'gamma': 0.5788895354754169}, {'C': 735.8190582693819, 'gamma': 0.5420617722295935}, {'C': 914.1535576757685, 'gamma': 0.8080201509879171}, {'C': 403.99783069378736, 'gamma': 0.35732434282078784}, {'C': 953.8767147108732, 'gamma': 0.3437315778925598}, {'C': 866.099816318328, 'gamma': 0.830377712198797}, {'C': 539.1614492475574, 'gamma': 0.9225693725672236}, {'C': 98.14647976501556, 'gamma': 0.10294749316074948}, {'C': 702.5072956958257, 'gamma': 0.8905798691284313}, {'C': 160.56030089820405, 'gamma': 0.2756725448969536}, {'C': 673.4915296568056, 'gamma': 0.1644031240201702}, {'C': 702.3711366090863, 'gamma': 0.48773522220572807}, {'C': 681.6777681763589, 'gamma': 0.5216481923258594}, {'C': 44.39669443408434, 'gamma': 0.22403660350197763}, {'C': 576.2050868680129, 'gamma': 0.1205336601272924}, {'C': 501.11671380079326, 'gamma': 0.13810956825889598}, {'C': 53.80840108926621, 'gamma': 0.17837692253615167}], 'split0_test_score': array([0.76274964, 0.76274964, 0.76274964, 0.76274964, 0.76274964,\n",
      "       0.76274964, 0.76274964, 0.76274964, 0.76274964, 0.76274964,\n",
      "       0.76274964, 0.76274964, 0.76274964, 0.76274964, 0.76274964,\n",
      "       0.76274964, 0.76274964, 0.76274964, 0.76274964, 0.76274964,\n",
      "       0.76274964, 0.76274964, 0.76274964, 0.76274964, 0.76274964,\n",
      "       0.76274964, 0.76274964, 0.76274964, 0.76274964, 0.76274964]), 'split1_test_score': array([0.76274964, 0.76274964, 0.76274964, 0.76274964, 0.76274964,\n",
      "       0.76274964, 0.76274964, 0.76274964, 0.76274964, 0.76274964,\n",
      "       0.76274964, 0.76274964, 0.76274964, 0.76274964, 0.76274964,\n",
      "       0.76274964, 0.76274964, 0.76274964, 0.76274964, 0.76274964,\n",
      "       0.76274964, 0.76274964, 0.76274964, 0.76274964, 0.76274964,\n",
      "       0.76274964, 0.76274964, 0.76274964, 0.76274964, 0.76274964]), 'split2_test_score': array([0.7627293, 0.7627293, 0.7627293, 0.7627293, 0.7627293, 0.7627293,\n",
      "       0.7627293, 0.7627293, 0.7627293, 0.7627293, 0.7627293, 0.7627293,\n",
      "       0.7627293, 0.7627293, 0.7627293, 0.7627293, 0.7627293, 0.7627293,\n",
      "       0.7627293, 0.7627293, 0.7627293, 0.7627293, 0.7627293, 0.7627293,\n",
      "       0.7627293, 0.7627293, 0.7627293, 0.7627293, 0.7627293, 0.7627293]), 'mean_test_score': array([0.76274286, 0.76274286, 0.76274286, 0.76274286, 0.76274286,\n",
      "       0.76274286, 0.76274286, 0.76274286, 0.76274286, 0.76274286,\n",
      "       0.76274286, 0.76274286, 0.76274286, 0.76274286, 0.76274286,\n",
      "       0.76274286, 0.76274286, 0.76274286, 0.76274286, 0.76274286,\n",
      "       0.76274286, 0.76274286, 0.76274286, 0.76274286, 0.76274286,\n",
      "       0.76274286, 0.76274286, 0.76274286, 0.76274286, 0.76274286]), 'std_test_score': array([9.58691019e-06, 9.58691019e-06, 9.58691019e-06, 9.58691019e-06,\n",
      "       9.58691019e-06, 9.58691019e-06, 9.58691019e-06, 9.58691019e-06,\n",
      "       9.58691019e-06, 9.58691019e-06, 9.58691019e-06, 9.58691019e-06,\n",
      "       9.58691019e-06, 9.58691019e-06, 9.58691019e-06, 9.58691019e-06,\n",
      "       9.58691019e-06, 9.58691019e-06, 9.58691019e-06, 9.58691019e-06,\n",
      "       9.58691019e-06, 9.58691019e-06, 9.58691019e-06, 9.58691019e-06,\n",
      "       9.58691019e-06, 9.58691019e-06, 9.58691019e-06, 9.58691019e-06,\n",
      "       9.58691019e-06, 9.58691019e-06]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "Best SVC() Parameters\n",
      "{'C': 517.3986277024461, 'gamma': 0.5707675868681398}\n",
      "Confusion Matrix - Rows = 50,000\n",
      "[[    0  3558]\n",
      " [    0 11442]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3558\n",
      "           1       0.76      1.00      0.87     11442\n",
      "\n",
      "    accuracy                           0.76     15000\n",
      "   macro avg       0.38      0.50      0.43     15000\n",
      "weighted avg       0.58      0.76      0.66     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rand_list50 = {'C': stats.uniform(1,1000), 'gamma':stats.uniform(0.0001,1)}\n",
    "rand_search50 = RandomizedSearchCV(SVC(),param_distributions = rand_list50, n_iter = 30, n_jobs=4, cv = 3, refit = True, random_state = 101, verbose = 1)\n",
    "rand_search50.fit(X_train50,y_train50)\n",
    "\n",
    "print ('Results for SVM with Randomized Search 3-CV, Rows = 50000')\n",
    "print(rand_search50.cv_results_)\n",
    "\n",
    "print('Best SVC() Parameters')\n",
    "print(rand_search50.best_params_)\n",
    "\n",
    "rand_predictions50=rand_search50.predict(X_test50)\n",
    "print('Confusion Matrix - Rows = 50,000')\n",
    "CFM50 = confusion_matrix(y_test50,rand_predictions50,labels =[0,1])\n",
    "print(CFM50)\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test50,rand_predictions50,labels = [0,1]))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
