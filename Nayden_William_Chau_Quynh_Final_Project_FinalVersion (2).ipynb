{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "William Nayden and Quynh Chau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 INTRODUCTION\n",
    "\n",
    "The purpose of this analysis is to predict Class 1 and Class 0 categories for the data set given with the goal of minimizing\n",
    "dollar losses due to misclassifications.  For each false positive, there is an associated loss of **\\\\$225** and for each false \n",
    "negative, there is an associated loss of **\\\\$35**.\n",
    "\n",
    "For purposes of this classification, positive is class 1 and negative is class 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Data Preparation\n",
    "\n",
    "The data set was downloaded from https://smu.box.com/s/k9x193jxm39enje2wx8ouw2kopx33132 in .csv format. \n",
    "\n",
    "There are 160,000 rows and 51 columns (features). 46 features are numeric and five features are categorical.  Nonnumeric features 'x24', 'x29', 'x30' contained categorical values of continental regions (Europe, Asia, America), calendar month, and calendar day of the week, respectively.  \n",
    "\n",
    "Missing data for these three features was imputed using a new factor level for each feature.  For example, missing values for feature `x24` had the imputed value of `NOregion`.  Similarly, missing values for feature `x29` had the imputed value of `NOmonth`, and lastly, missing values for feature `x30` had the imputed value of `NOday`.  The remaining features, `x32` and `x37` were numerical values containing `$` and `%`.  These two characters were stripped from their respective values and these features were converted to numerical types.\n",
    "\n",
    "For numerical features with missing values, the median of their respective range of values were imputed.  The median was chosen rather than the mean or mode to minimize the impact of outliers and to not create any artificial imbalance within the data set.\n",
    "\n",
    "## B. Model Selection\n",
    "\n",
    "XGBoost Classifier with hypeparameter tuning was used to build the classification model.  Hyperparameter tuning was done for `max_weight` and `min_child_weight` parameters.\n",
    "\n",
    "We chose XGBoost Classifier because for classification problems like this one, we believe the accuracy of tree based algorithms provides better accuracy than linear algorithms because they are better at recognizing non-linear relationships. Additionally, compared to Random Forest, XGBoost provides faster run times for similar accuracies, making the model more scalable.\n",
    "\n",
    "For modeling and evaluation purposes, a baseline XGBoost Classifier model was done using train/test/split with 80/20 for purposes of establishing a point for comparison of model performance.  Evaluation metrics include accuracy and log loss, with calculation for dollar loss impact from misclassifications.  In addition, two models using XGBoost Classifier were ran using imputed data and also excluding all missing data for purposes of comparing model performance.\n",
    "\n",
    "The top 10 important features were plotted using plot_importance and ranked by F-score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for the XGBoost Classifier Models are in the following table:  \n",
    "\n",
    "|Model|Accuracy|Log Loss|Total Rounds|\n",
    "|:-----|--------|--------|----------:|\n",
    "|XGBoost-Excl. Missing Data|93%|2.8953|129|\n",
    "|XGBoost-Imputed Data|95%|1.6261|53|\n",
    "\n",
    "Hyperparameter tuning and cross validation grid search showed that the best values to use for xgBoost Classifier were \n",
    "`max_weight = 9`, `min_child_weight = 6`.  \n",
    "\n",
    "The estimated dollar loss for `XGBoost - Excluding Missing Data` was extrapolated from the results of the confusion matrix\n",
    "generated from 20% of the train/test split data set.  \n",
    "\n",
    "|Model|Estimated \\\\$ Loss|\n",
    "|:---|---:|\n",
    "|XGBoost-Excl. Missing Data|\\\\$1,414,475|\n",
    "|XGBoost-Imputed Data|\\\\$860,825|\n",
    "\n",
    "As seen in the table above, the `XGBoost-Imputed Data` model provides an estimated savings of **\\\\$553,650** over the `XGBoost-Excl. Missing Data` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top ten most important features using F-score ranking are plotted in the following graph.  High F score indicates a relatively higher degree of feature importance in the classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432000x720000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Top 10 Most Important Features based on  F-score\n",
    "from matplotlib import pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "\n",
    "fig= plt.figure(figsize=(6000,10000))\n",
    "plot_importance(model2, max_num_features=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We believe feature importance is crucial for further development of this model, as it will help us create new features by looking at the interactions and covariance of important features. While we did not do this in this version of the model, it represents opportunity for further research, as enumerated by this graph.\n",
    "\n",
    "Additionally, with further context, this can help further elucidate the business case and real world insights for this model. While these features have generic labels now, more descriptive feature labeling can help craft the narrative story for what is important in this classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 CONCLUSION\n",
    "\n",
    "We recommend using our `XGBoost-Imputed Data` model to help classify this data. It provides the highest accuracy, lowest log loss, lowest run time, but most importantly fewest dollars lost of all the models we tested.\n",
    "\n",
    "Additionally, we found both hyperparameter tuning, and imputing missing data served as vehicles for huge improvements in all of our KPIs.\n",
    "\n",
    "For further research, we would recommend exploring further feature creation, using our feature importance graph as a starting point. Additionally, we believe ensembling methods could provide marginal accuracy gains to reduce the number of misclassifications by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX : CODE AND MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\SMU\\\\DS 7333 Quant the World\\\\Case Studies\\\\Case Study wk 14 and Final'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "os. chdir('C:/SMU/DS 7333 Quant the World/Case Studies/Case Study wk 14 and Final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data set has 160000 rows and 51 columns\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"final_project.csv\")\n",
    "print (\"This data set has {} rows and {} columns\".format(df1.shape[0],df1.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0     26\n",
      "x1     25\n",
      "x2     38\n",
      "x3     37\n",
      "x4     26\n",
      "x5     37\n",
      "x6     26\n",
      "x7     27\n",
      "x8     21\n",
      "x9     30\n",
      "x10    43\n",
      "x11    30\n",
      "x12    36\n",
      "x13    31\n",
      "x14    34\n",
      "x15    35\n",
      "x16    26\n",
      "x17    27\n",
      "x18    40\n",
      "x19    35\n",
      "x20    38\n",
      "x21    29\n",
      "x22    27\n",
      "x23    47\n",
      "x24    28\n",
      "x25    22\n",
      "x26    36\n",
      "x27    30\n",
      "x28    35\n",
      "x29    30\n",
      "x30    30\n",
      "x31    39\n",
      "x32    31\n",
      "x33    41\n",
      "x34    41\n",
      "x35    30\n",
      "x36    27\n",
      "x37    23\n",
      "x38    31\n",
      "x39    23\n",
      "x40    36\n",
      "x41    40\n",
      "x42    26\n",
      "x43    37\n",
      "x44    40\n",
      "x45    29\n",
      "x46    31\n",
      "x47    37\n",
      "x48    32\n",
      "x49    32\n",
      "y       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (df1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160000 entries, 0 to 159999\n",
      "Data columns (total 51 columns):\n",
      "x0     159974 non-null float64\n",
      "x1     159975 non-null float64\n",
      "x2     159962 non-null float64\n",
      "x3     159963 non-null float64\n",
      "x4     159974 non-null float64\n",
      "x5     159963 non-null float64\n",
      "x6     159974 non-null float64\n",
      "x7     159973 non-null float64\n",
      "x8     159979 non-null float64\n",
      "x9     159970 non-null float64\n",
      "x10    159957 non-null float64\n",
      "x11    159970 non-null float64\n",
      "x12    159964 non-null float64\n",
      "x13    159969 non-null float64\n",
      "x14    159966 non-null float64\n",
      "x15    159965 non-null float64\n",
      "x16    159974 non-null float64\n",
      "x17    159973 non-null float64\n",
      "x18    159960 non-null float64\n",
      "x19    159965 non-null float64\n",
      "x20    159962 non-null float64\n",
      "x21    159971 non-null float64\n",
      "x22    159973 non-null float64\n",
      "x23    159953 non-null float64\n",
      "x24    159972 non-null object\n",
      "x25    159978 non-null float64\n",
      "x26    159964 non-null float64\n",
      "x27    159970 non-null float64\n",
      "x28    159965 non-null float64\n",
      "x29    159970 non-null object\n",
      "x30    159970 non-null object\n",
      "x31    159961 non-null float64\n",
      "x32    159969 non-null object\n",
      "x33    159959 non-null float64\n",
      "x34    159959 non-null float64\n",
      "x35    159970 non-null float64\n",
      "x36    159973 non-null float64\n",
      "x37    159977 non-null object\n",
      "x38    159969 non-null float64\n",
      "x39    159977 non-null float64\n",
      "x40    159964 non-null float64\n",
      "x41    159960 non-null float64\n",
      "x42    159974 non-null float64\n",
      "x43    159963 non-null float64\n",
      "x44    159960 non-null float64\n",
      "x45    159971 non-null float64\n",
      "x46    159969 non-null float64\n",
      "x47    159963 non-null float64\n",
      "x48    159968 non-null float64\n",
      "x49    159968 non-null float64\n",
      "y      160000 non-null int64\n",
      "dtypes: float64(45), int64(1), object(5)\n",
      "memory usage: 62.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x41</th>\n",
       "      <th>x42</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.166563</td>\n",
       "      <td>-3.961588</td>\n",
       "      <td>4.621113</td>\n",
       "      <td>2.481908</td>\n",
       "      <td>-1.800135</td>\n",
       "      <td>0.804684</td>\n",
       "      <td>6.718751</td>\n",
       "      <td>-14.789997</td>\n",
       "      <td>-1.040673</td>\n",
       "      <td>-4.204950</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.497117</td>\n",
       "      <td>5.414063</td>\n",
       "      <td>-2.325655</td>\n",
       "      <td>1.674827</td>\n",
       "      <td>-0.264332</td>\n",
       "      <td>60.781427</td>\n",
       "      <td>-7.689696</td>\n",
       "      <td>0.151589</td>\n",
       "      <td>-8.040166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.149894</td>\n",
       "      <td>-0.585676</td>\n",
       "      <td>27.839856</td>\n",
       "      <td>4.152333</td>\n",
       "      <td>6.426802</td>\n",
       "      <td>-2.426943</td>\n",
       "      <td>40.477058</td>\n",
       "      <td>-6.725709</td>\n",
       "      <td>0.896421</td>\n",
       "      <td>0.330165</td>\n",
       "      <td>...</td>\n",
       "      <td>36.292790</td>\n",
       "      <td>4.490915</td>\n",
       "      <td>0.762561</td>\n",
       "      <td>6.526662</td>\n",
       "      <td>1.007927</td>\n",
       "      <td>15.805696</td>\n",
       "      <td>-4.896678</td>\n",
       "      <td>-0.320283</td>\n",
       "      <td>16.719974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.321707</td>\n",
       "      <td>-1.429819</td>\n",
       "      <td>12.251561</td>\n",
       "      <td>6.586874</td>\n",
       "      <td>-5.304647</td>\n",
       "      <td>-11.311090</td>\n",
       "      <td>17.812850</td>\n",
       "      <td>11.060572</td>\n",
       "      <td>5.325880</td>\n",
       "      <td>-2.632984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.368491</td>\n",
       "      <td>9.088864</td>\n",
       "      <td>-0.689886</td>\n",
       "      <td>-2.731118</td>\n",
       "      <td>0.754200</td>\n",
       "      <td>30.856417</td>\n",
       "      <td>-7.428573</td>\n",
       "      <td>-2.090804</td>\n",
       "      <td>-7.869421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.245594</td>\n",
       "      <td>5.076677</td>\n",
       "      <td>-24.149632</td>\n",
       "      <td>3.637307</td>\n",
       "      <td>6.505811</td>\n",
       "      <td>2.290224</td>\n",
       "      <td>-35.111751</td>\n",
       "      <td>-18.913592</td>\n",
       "      <td>-0.337041</td>\n",
       "      <td>-5.568076</td>\n",
       "      <td>...</td>\n",
       "      <td>15.691546</td>\n",
       "      <td>-7.467775</td>\n",
       "      <td>2.940789</td>\n",
       "      <td>-6.424112</td>\n",
       "      <td>0.419776</td>\n",
       "      <td>-72.424569</td>\n",
       "      <td>5.361375</td>\n",
       "      <td>1.806070</td>\n",
       "      <td>-7.670847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.273366</td>\n",
       "      <td>0.306326</td>\n",
       "      <td>-11.352593</td>\n",
       "      <td>1.676758</td>\n",
       "      <td>2.928441</td>\n",
       "      <td>-0.616824</td>\n",
       "      <td>-16.505817</td>\n",
       "      <td>27.532281</td>\n",
       "      <td>1.199715</td>\n",
       "      <td>-4.309105</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.911297</td>\n",
       "      <td>-5.229937</td>\n",
       "      <td>1.783928</td>\n",
       "      <td>3.957801</td>\n",
       "      <td>-0.096988</td>\n",
       "      <td>-14.085435</td>\n",
       "      <td>-0.208351</td>\n",
       "      <td>-0.894942</td>\n",
       "      <td>15.724742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1         x2        x3        x4         x5         x6  \\\n",
       "0 -0.166563 -3.961588   4.621113  2.481908 -1.800135   0.804684   6.718751   \n",
       "1 -0.149894 -0.585676  27.839856  4.152333  6.426802  -2.426943  40.477058   \n",
       "2 -0.321707 -1.429819  12.251561  6.586874 -5.304647 -11.311090  17.812850   \n",
       "3 -0.245594  5.076677 -24.149632  3.637307  6.505811   2.290224 -35.111751   \n",
       "4 -0.273366  0.306326 -11.352593  1.676758  2.928441  -0.616824 -16.505817   \n",
       "\n",
       "          x7        x8        x9  ...        x41       x42       x43  \\\n",
       "0 -14.789997 -1.040673 -4.204950  ...  -1.497117  5.414063 -2.325655   \n",
       "1  -6.725709  0.896421  0.330165  ...  36.292790  4.490915  0.762561   \n",
       "2  11.060572  5.325880 -2.632984  ...  -0.368491  9.088864 -0.689886   \n",
       "3 -18.913592 -0.337041 -5.568076  ...  15.691546 -7.467775  2.940789   \n",
       "4  27.532281  1.199715 -4.309105  ... -13.911297 -5.229937  1.783928   \n",
       "\n",
       "        x44       x45        x46       x47       x48        x49  y  \n",
       "0  1.674827 -0.264332  60.781427 -7.689696  0.151589  -8.040166  0  \n",
       "1  6.526662  1.007927  15.805696 -4.896678 -0.320283  16.719974  0  \n",
       "2 -2.731118  0.754200  30.856417 -7.428573 -2.090804  -7.869421  0  \n",
       "3 -6.424112  0.419776 -72.424569  5.361375  1.806070  -7.670847  0  \n",
       "4  3.957801 -0.096988 -14.085435 -0.208351 -0.894942  15.724742  1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Variables:  Create New Factor Level, Detect Missing Data and Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['euorpe', 'asia', 'america', nan], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.x24.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['x24']= df1['x24'].astype(str).str.replace('nan','NOregion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['euorpe', 'asia', 'america', 'NOregion'], dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.x24.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['July', 'Aug', 'Jun', 'May', 'sept.', 'Apr', 'Nov', 'Oct', nan,\n",
       "       'Mar', 'Feb', 'Dev', 'January'], dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.x29.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['July', 'Aug', 'Jun', 'May', 'sept.', 'Apr', 'Nov', 'Oct',\n",
       "       'NOmonth', 'Mar', 'Feb', 'Dev', 'January'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['x29']=df1['x29'].astype(str).str.replace('nan','NOmonth')\n",
    "df1.x29.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tuesday', 'wednesday', 'thurday', 'monday', 'friday', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.x30.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tuesday', 'wednesday', 'thurday', 'monday', 'friday', 'NODay'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['x30']=df1['x30'].astype(str).str.replace('nan','NODay')\n",
    "df1.x30.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0%', '-0.02%', '-0.01%', '0.01%', '-0.03%', '0.02%', '-0.0%',\n",
       "       '-0.04%', nan, '0.03%', '0.04%', '-0.05%', '0.05%'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.x32.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping \"%\"\n",
    "df1['x32'] = df1['x32'].astype(str).str.replace('%', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0', '-0.02', '-0.01', '0.01', '-0.03', '0.02', '-0.0', '-0.04',\n",
       "       'nan', '0.03', '0.04', '-0.05', '0.05'], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.x32.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['x32']= df1['x32'].astype(str).str.replace('nan','0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"x32\"] = pd.to_numeric(df1[\"x32\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.  , -0.02, -0.01,  0.01, -0.03,  0.02, -0.04,  0.03,  0.04,\n",
       "       -0.05,  0.05])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.x32.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['$1313.96', '$1962.78', '$430.47', ..., '$1588.65', '$439.21',\n",
       "       '$-1229.34'], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.x37.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping \"$\"\n",
    "df1['x37'] = df1['x37'].astype(str).str.replace('$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['x37']= df1['x37'].astype(str).str.replace('nan','0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"x37\"] = pd.to_numeric(df1[\"x37\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1313.96,  1962.78,   430.47, ...,  1588.65,   439.21, -1229.34])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.x37.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute Missing Numerical Feature Values with Median Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in each column/feature of numerical data type with the median value for that column feature\n",
    "df1.fillna(df1.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0     0\n",
       "x1     0\n",
       "x2     0\n",
       "x3     0\n",
       "x4     0\n",
       "x5     0\n",
       "x6     0\n",
       "x7     0\n",
       "x8     0\n",
       "x9     0\n",
       "x10    0\n",
       "x11    0\n",
       "x12    0\n",
       "x13    0\n",
       "x14    0\n",
       "x15    0\n",
       "x16    0\n",
       "x17    0\n",
       "x18    0\n",
       "x19    0\n",
       "x20    0\n",
       "x21    0\n",
       "x22    0\n",
       "x23    0\n",
       "x24    0\n",
       "x25    0\n",
       "x26    0\n",
       "x27    0\n",
       "x28    0\n",
       "x29    0\n",
       "x30    0\n",
       "x31    0\n",
       "x32    0\n",
       "x33    0\n",
       "x34    0\n",
       "x35    0\n",
       "x36    0\n",
       "x37    0\n",
       "x38    0\n",
       "x39    0\n",
       "x40    0\n",
       "x41    0\n",
       "x42    0\n",
       "x43    0\n",
       "x44    0\n",
       "x45    0\n",
       "x46    0\n",
       "x47    0\n",
       "x48    0\n",
       "x49    0\n",
       "y      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that all missing data have been imputed\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoostClassifier Model with Imputed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        x24  x29  x30\n",
      "0         3    5    4\n",
      "1         2    1    5\n",
      "2         2    5    5\n",
      "3         2    5    5\n",
      "4         2    5    4\n",
      "...     ...  ...  ...\n",
      "159995    2    1    5\n",
      "159996    2    8    5\n",
      "159997    2    6    5\n",
      "159998    2    8    5\n",
      "159999    2    1    4\n",
      "\n",
      "[160000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#One hot encode categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df1[['x24','x29','x30']] = df1[['x24','x29','x30']].apply(LabelEncoder().fit_transform)\n",
    "print(df1[['x24','x29','x30']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = df1['y']\n",
    "df1.drop(['y'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.2\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(df1, target1, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtrain1 = xgb.DMatrix(X_train1.values, y_train1.values)\n",
    "xgtest1 = xgb.DMatrix(X_test1.values, y_test1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "dtrain1 = xgb.DMatrix(X_train1, label=y_train1)\n",
    "dtest1 = xgb.DMatrix(X_test1, label=y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed Model Baseline Accuracy is 0.40\n",
      "Imputed Baseline Log Loss is 0.67\n"
     ]
    }
   ],
   "source": [
    "# \"Learn\" the mean from the training data\n",
    "mean_train1 = np.mean(y_train1)\n",
    "# Get predictions on the test set\n",
    "baseline_predictions1 = np.ones(y_test1.shape) * mean_train1\n",
    "\n",
    "# Compute Log Loss and Accuracy\n",
    "log_baseline1 = log_loss(y_test1, baseline_predictions1)\n",
    "acc_baseline1 = accuracy_score(y_test1, np.ones(baseline_predictions1.shape))\n",
    "\n",
    "print(\"Imputed Model Baseline Accuracy is {:.2f}\".format(acc_baseline1))\n",
    "print(\"Imputed Baseline Log Loss is {:.2f}\".format(log_baseline1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model1 = xgb.XGBClassifier()\n",
    "model1.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred1 = model1.predict(X_test1)\n",
    "predictions1 = [round(value) for value in y_pred1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.84%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy1 = accuracy_score(y_test1, predictions1)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy1 * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17157  1950]\n",
      " [ 3222  9671]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "cm1 = confusion_matrix(y_test1, predictions1)\n",
    "print(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$551,520.00\n"
     ]
    }
   ],
   "source": [
    "total_loss1 = (1950*225) + (3222*35)\n",
    "formatted = \"${:,.2f}\".format(total_loss1)\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'binary:hinge',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1['eval_metric'] = \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest1-error:0.597094\n",
      "Will train until Test1-error hasn't improved in 10 rounds.\n",
      "[1]\tTest1-error:0.532375\n",
      "[2]\tTest1-error:0.281625\n",
      "[3]\tTest1-error:0.221938\n",
      "[4]\tTest1-error:0.203031\n",
      "[5]\tTest1-error:0.1915\n",
      "[6]\tTest1-error:0.186312\n",
      "[7]\tTest1-error:0.178062\n",
      "[8]\tTest1-error:0.167469\n",
      "[9]\tTest1-error:0.162687\n",
      "[10]\tTest1-error:0.152531\n",
      "[11]\tTest1-error:0.146219\n",
      "[12]\tTest1-error:0.142438\n",
      "[13]\tTest1-error:0.137938\n",
      "[14]\tTest1-error:0.136469\n",
      "[15]\tTest1-error:0.1325\n",
      "[16]\tTest1-error:0.128969\n",
      "[17]\tTest1-error:0.126375\n",
      "[18]\tTest1-error:0.125563\n",
      "[19]\tTest1-error:0.122969\n",
      "[20]\tTest1-error:0.121437\n",
      "[21]\tTest1-error:0.1165\n",
      "[22]\tTest1-error:0.113781\n",
      "[23]\tTest1-error:0.110125\n",
      "[24]\tTest1-error:0.108625\n",
      "[25]\tTest1-error:0.10675\n",
      "[26]\tTest1-error:0.105719\n",
      "[27]\tTest1-error:0.104031\n",
      "[28]\tTest1-error:0.103844\n",
      "[29]\tTest1-error:0.104\n",
      "[30]\tTest1-error:0.103625\n",
      "[31]\tTest1-error:0.102875\n",
      "[32]\tTest1-error:0.10075\n",
      "[33]\tTest1-error:0.098312\n",
      "[34]\tTest1-error:0.095469\n",
      "[35]\tTest1-error:0.093281\n",
      "[36]\tTest1-error:0.091781\n",
      "[37]\tTest1-error:0.090313\n",
      "[38]\tTest1-error:0.089156\n",
      "[39]\tTest1-error:0.087969\n",
      "[40]\tTest1-error:0.086594\n",
      "[41]\tTest1-error:0.085281\n",
      "[42]\tTest1-error:0.08525\n",
      "[43]\tTest1-error:0.084406\n",
      "[44]\tTest1-error:0.083094\n",
      "[45]\tTest1-error:0.082594\n",
      "[46]\tTest1-error:0.082094\n",
      "[47]\tTest1-error:0.082\n",
      "[48]\tTest1-error:0.082156\n",
      "[49]\tTest1-error:0.081688\n",
      "[50]\tTest1-error:0.081969\n",
      "[51]\tTest1-error:0.082094\n",
      "[52]\tTest1-error:0.081531\n",
      "[53]\tTest1-error:0.080781\n",
      "[54]\tTest1-error:0.080187\n",
      "[55]\tTest1-error:0.079938\n",
      "[56]\tTest1-error:0.079906\n",
      "[57]\tTest1-error:0.079875\n",
      "[58]\tTest1-error:0.080094\n",
      "[59]\tTest1-error:0.08025\n",
      "[60]\tTest1-error:0.080063\n",
      "[61]\tTest1-error:0.079969\n",
      "[62]\tTest1-error:0.079844\n",
      "[63]\tTest1-error:0.079875\n",
      "[64]\tTest1-error:0.079313\n",
      "[65]\tTest1-error:0.07925\n",
      "[66]\tTest1-error:0.079281\n",
      "[67]\tTest1-error:0.078375\n",
      "[68]\tTest1-error:0.078437\n",
      "[69]\tTest1-error:0.0785\n",
      "[70]\tTest1-error:0.078531\n",
      "[71]\tTest1-error:0.078156\n",
      "[72]\tTest1-error:0.078219\n",
      "[73]\tTest1-error:0.078219\n",
      "[74]\tTest1-error:0.07825\n",
      "[75]\tTest1-error:0.078031\n",
      "[76]\tTest1-error:0.078094\n",
      "[77]\tTest1-error:0.077969\n",
      "[78]\tTest1-error:0.077344\n",
      "[79]\tTest1-error:0.076438\n",
      "[80]\tTest1-error:0.076594\n",
      "[81]\tTest1-error:0.076375\n",
      "[82]\tTest1-error:0.075938\n",
      "[83]\tTest1-error:0.075969\n",
      "[84]\tTest1-error:0.07575\n",
      "[85]\tTest1-error:0.075625\n",
      "[86]\tTest1-error:0.076063\n",
      "[87]\tTest1-error:0.075875\n",
      "[88]\tTest1-error:0.075938\n",
      "[89]\tTest1-error:0.076187\n",
      "[90]\tTest1-error:0.075969\n",
      "[91]\tTest1-error:0.075375\n",
      "[92]\tTest1-error:0.074562\n",
      "[93]\tTest1-error:0.074031\n",
      "[94]\tTest1-error:0.074\n",
      "[95]\tTest1-error:0.073781\n",
      "[96]\tTest1-error:0.073594\n",
      "[97]\tTest1-error:0.073656\n",
      "[98]\tTest1-error:0.073469\n",
      "[99]\tTest1-error:0.073719\n",
      "[100]\tTest1-error:0.073844\n",
      "[101]\tTest1-error:0.073875\n",
      "[102]\tTest1-error:0.074062\n",
      "[103]\tTest1-error:0.074125\n",
      "[104]\tTest1-error:0.074125\n",
      "[105]\tTest1-error:0.074156\n",
      "[106]\tTest1-error:0.074062\n",
      "[107]\tTest1-error:0.07425\n",
      "[108]\tTest1-error:0.07425\n",
      "Stopping. Best iteration:\n",
      "[98]\tTest1-error:0.073469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = 999\n",
    "\n",
    "model1 = xgb.train(\n",
    "    params1,\n",
    "    dtrain1,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest1, \"Test1\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed Model Best Accuracy: 0.93 with 99 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Imputed Model Best Accuracy: {:.2f} with {} rounds\".format(\n",
    "                 (1-model1.best_score),\n",
    "                 model1.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.599188</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>22.076522</td>\n",
       "      <td>0.022470</td>\n",
       "      <td>0.599188</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>22.074753</td>\n",
       "      <td>0.090034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.535330</td>\n",
       "      <td>0.034381</td>\n",
       "      <td>19.726219</td>\n",
       "      <td>1.266066</td>\n",
       "      <td>0.536312</td>\n",
       "      <td>0.034032</td>\n",
       "      <td>19.759317</td>\n",
       "      <td>1.253452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.272805</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>10.047016</td>\n",
       "      <td>0.253710</td>\n",
       "      <td>0.278969</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>10.278046</td>\n",
       "      <td>0.227589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>8.268337</td>\n",
       "      <td>0.081187</td>\n",
       "      <td>0.229914</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>8.470688</td>\n",
       "      <td>0.108583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.202109</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>7.444442</td>\n",
       "      <td>0.076810</td>\n",
       "      <td>0.207688</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>7.651778</td>\n",
       "      <td>0.070479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.050853</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>1.873582</td>\n",
       "      <td>0.111433</td>\n",
       "      <td>0.079891</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>2.943263</td>\n",
       "      <td>0.097030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.050711</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>1.868329</td>\n",
       "      <td>0.117637</td>\n",
       "      <td>0.079765</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>2.938657</td>\n",
       "      <td>0.101714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>1.865451</td>\n",
       "      <td>0.117702</td>\n",
       "      <td>0.079773</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>2.938945</td>\n",
       "      <td>0.095590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.050508</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>1.860845</td>\n",
       "      <td>0.121555</td>\n",
       "      <td>0.079688</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>2.935779</td>\n",
       "      <td>0.101641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.050332</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>1.854369</td>\n",
       "      <td>0.127960</td>\n",
       "      <td>0.079672</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>2.935203</td>\n",
       "      <td>0.101157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-error-mean  train-error-std  train-logloss-mean  train-logloss-std  \\\n",
       "0            0.599188         0.000612           22.076522           0.022470   \n",
       "1            0.535330         0.034381           19.726219           1.266066   \n",
       "2            0.272805         0.006886           10.047016           0.253710   \n",
       "3            0.224490         0.002205            8.268337           0.081187   \n",
       "4            0.202109         0.002087            7.444442           0.076810   \n",
       "..                ...              ...                 ...                ...   \n",
       "122          0.050853         0.003024            1.873582           0.111433   \n",
       "123          0.050711         0.003193            1.868329           0.117637   \n",
       "124          0.050633         0.003195            1.865451           0.117702   \n",
       "125          0.050508         0.003299            1.860845           0.121555   \n",
       "126          0.050332         0.003473            1.854369           0.127960   \n",
       "\n",
       "     test-error-mean  test-error-std  test-logloss-mean  test-logloss-std  \n",
       "0           0.599188        0.002446          22.074753          0.090034  \n",
       "1           0.536312        0.034032          19.759317          1.253452  \n",
       "2           0.278969        0.006177          10.278046          0.227589  \n",
       "3           0.229914        0.002947           8.470688          0.108583  \n",
       "4           0.207688        0.001913           7.651778          0.070479  \n",
       "..               ...             ...                ...               ...  \n",
       "122         0.079891        0.002634           2.943263          0.097030  \n",
       "123         0.079765        0.002761           2.938657          0.101714  \n",
       "124         0.079773        0.002595           2.938945          0.095590  \n",
       "125         0.079688        0.002759           2.935779          0.101641  \n",
       "126         0.079672        0.002746           2.935203          0.101157  \n",
       "\n",
       "[127 rows x 8 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results1 = xgb.cv(\n",
    "    params1,\n",
    "    dtrain1,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'logloss','error'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed Model Best Accuracy: 0.920328\n",
      "Imputed Model Best Log Loss: 2.9352028\n"
     ]
    }
   ],
   "source": [
    "print('Imputed Model Best Accuracy: {}'.format(1-cv_results1['test-error-mean'].min()))\n",
    "print('Imputed Model Best Log Loss: {}'.format(cv_results1['test-logloss-mean'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params1 = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed Model \\Log Loss 2.8120065999999997 for 53 rounds\n",
      "Imputed Model \\Accuracy 0.9236718 for 53 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "Imputed Model \\Log Loss 2.8341702 for 42 rounds\n",
      "Imputed Model \\Accuracy 0.9230704 for 42 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "Imputed Model \\Log Loss 2.8456842 for 46 rounds\n",
      "Imputed Model \\Accuracy 0.9227578 for 46 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "Imputed Model \\Log Loss 2.8756194 for 39 rounds\n",
      "Imputed Model \\Accuracy 0.9219452 for 39 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "Imputed Model \\Log Loss 2.8546068 for 31 rounds\n",
      "Imputed Model \\Accuracy 0.9225156 for 31 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "Imputed Model \\Log Loss 2.8266864000000003 for 30 rounds\n",
      "Imputed Model \\Accuracy 0.9232734 for 30 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "Imputed Model \\Log Loss 2.8974958 for 24 rounds\n",
      "Imputed Model \\Accuracy 0.9213515999999999 for 24 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "Imputed Model \\Log Loss 2.8957684000000006 for 23 rounds\n",
      "Imputed Model \\Accuracy 0.9213984 for 23 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "Imputed Model \\Log Loss 2.8275498000000003 for 31 rounds\n",
      "Imputed Model \\Accuracy 0.9232498 for 31 rounds\n",
      "Imputed Model Best params: 9, 5, Log Loss: 2.8275498000000003, Accuracy: 0.9236718\n"
     ]
    }
   ],
   "source": [
    "# Define initial best params and accuracy\n",
    "min_error1= float(\"Inf\")\n",
    "best_params1 = None\n",
    "for max_depth, min_child_weight in gridsearch_params1:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params1['max_depth'] = max_depth\n",
    "    params1['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results1 = xgb.cv(\n",
    "        params1,\n",
    "        dtrain1,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'logloss', 'error'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best Log Loss\n",
    "    mean_logloss1 = cv_results1['test-logloss-mean'].min()\n",
    "    mean_error1 = cv_results1['test-error-mean'].min()\n",
    "    boost_rounds = cv_results1['test-error-mean'].argmin()\n",
    "    print(\"Imputed Model \\Log Loss {} for {} rounds\".format(mean_logloss1, boost_rounds))\n",
    "    print(\"Imputed Model \\Accuracy {} for {} rounds\".format((1-mean_error1), boost_rounds))\n",
    "    if mean_error1 < min_error1:\n",
    "        min_error1 = mean_error1\n",
    "        best_params1 = (max_depth,min_child_weight)\n",
    "print(\"Imputed Model Best params: {}, {}, Log Loss: {}, Accuracy: {}\".format(best_params1[0], best_params1[1], mean_logloss1,(1-min_error1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit XGBoostClassifier with Results from CV Grid Search Using max_depth =9, min_child_weight=6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=9,\n",
       "              min_child_weight=6, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model2 = xgb.XGBClassifier(max_depth =9, min_child_weight = 6, random_state = 0, verbosity=1)\n",
    "model2.fit(df1, target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred2 = model2.predict(df1)\n",
    "predictions2 = [round(value) for value in y_pred2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.29%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy2 = accuracy_score(target1, predictions2)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy2 * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92660  3143]\n",
      " [ 4390 59807]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "cm2 = confusion_matrix(target1, predictions2)\n",
    "print(cm2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$860,825.00\n"
     ]
    }
   ],
   "source": [
    "total_loss2 = (3143*225) + (4390*35)\n",
    "formatted = \"${:,.2f}\".format(total_loss1)\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6261444732349086\n"
     ]
    }
   ],
   "source": [
    "model2_log_loss = log_loss(target1, predictions2)\n",
    "print(model2_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432000x720000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Top 10 Most Important Features based on  F-score\n",
    "from matplotlib import pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "\n",
    "fig= plt.figure(figsize=(6000,10000))\n",
    "plot_importance(model2, max_num_features=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Original Data Excluding Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "target = df['y']\n",
    "df.drop(['y'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x24</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "      <th>x32</th>\n",
       "      <th>x37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>euorpe</td>\n",
       "      <td>July</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>$1313.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asia</td>\n",
       "      <td>Aug</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>-0.02%</td>\n",
       "      <td>$1962.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asia</td>\n",
       "      <td>July</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>-0.01%</td>\n",
       "      <td>$430.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asia</td>\n",
       "      <td>July</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>$-2366.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asia</td>\n",
       "      <td>July</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>$-620.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x24   x29        x30     x32        x37\n",
       "0  euorpe  July    tuesday    0.0%   $1313.96\n",
       "1    asia   Aug  wednesday  -0.02%   $1962.78\n",
       "2    asia  July  wednesday  -0.01%    $430.47\n",
       "3    asia  July  wednesday   0.01%  $-2366.29\n",
       "4    asia  July    tuesday   0.01%   $-620.66"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_df = df.select_dtypes(include=['object']).copy()\n",
    "obj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0.00\n",
      "1        -0.02\n",
      "2        -0.01\n",
      "3         0.01\n",
      "4         0.01\n",
      "          ... \n",
      "159995    0.00\n",
      "159996   -0.01\n",
      "159997   -0.00\n",
      "159998   -0.02\n",
      "159999    0.02\n",
      "Name: x32, Length: 158392, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def per(x):\n",
    "    return float(x.strip('%'))\n",
    "\n",
    "df['x32'] = df['x32'].apply(per)\n",
    "print(df['x32'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         1313.96\n",
      "1         1962.78\n",
      "2          430.47\n",
      "3        -2366.29\n",
      "4         -620.66\n",
      "           ...   \n",
      "159995    -891.96\n",
      "159996    1588.65\n",
      "159997     687.46\n",
      "159998     439.21\n",
      "159999   -1229.34\n",
      "Name: x37, Length: 158392, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def dol(x):\n",
    "    return float(x.strip('$'))\n",
    "\n",
    "df['x37'] = df['x37'].apply(dol)\n",
    "print(df['x37'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        x24  x29  x30\n",
      "0         2    5    3\n",
      "1         1    1    4\n",
      "2         1    5    4\n",
      "3         1    5    4\n",
      "4         1    5    3\n",
      "...     ...  ...  ...\n",
      "159995    1    1    4\n",
      "159996    1    8    4\n",
      "159997    1    6    4\n",
      "159998    1    8    4\n",
      "159999    1    1    3\n",
      "\n",
      "[158392 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df[['x24','x29','x30']] = df[['x24','x29','x30']].apply(LabelEncoder().fit_transform)\n",
    "print(df[['x24','x29','x30']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 158392 entries, 0 to 159999\n",
      "Data columns (total 50 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   x0      158392 non-null  float64\n",
      " 1   x1      158392 non-null  float64\n",
      " 2   x2      158392 non-null  float64\n",
      " 3   x3      158392 non-null  float64\n",
      " 4   x4      158392 non-null  float64\n",
      " 5   x5      158392 non-null  float64\n",
      " 6   x6      158392 non-null  float64\n",
      " 7   x7      158392 non-null  float64\n",
      " 8   x8      158392 non-null  float64\n",
      " 9   x9      158392 non-null  float64\n",
      " 10  x10     158392 non-null  float64\n",
      " 11  x11     158392 non-null  float64\n",
      " 12  x12     158392 non-null  float64\n",
      " 13  x13     158392 non-null  float64\n",
      " 14  x14     158392 non-null  float64\n",
      " 15  x15     158392 non-null  float64\n",
      " 16  x16     158392 non-null  float64\n",
      " 17  x17     158392 non-null  float64\n",
      " 18  x18     158392 non-null  float64\n",
      " 19  x19     158392 non-null  float64\n",
      " 20  x20     158392 non-null  float64\n",
      " 21  x21     158392 non-null  float64\n",
      " 22  x22     158392 non-null  float64\n",
      " 23  x23     158392 non-null  float64\n",
      " 24  x24     158392 non-null  int32  \n",
      " 25  x25     158392 non-null  float64\n",
      " 26  x26     158392 non-null  float64\n",
      " 27  x27     158392 non-null  float64\n",
      " 28  x28     158392 non-null  float64\n",
      " 29  x29     158392 non-null  int32  \n",
      " 30  x30     158392 non-null  int32  \n",
      " 31  x31     158392 non-null  float64\n",
      " 32  x32     158392 non-null  float64\n",
      " 33  x33     158392 non-null  float64\n",
      " 34  x34     158392 non-null  float64\n",
      " 35  x35     158392 non-null  float64\n",
      " 36  x36     158392 non-null  float64\n",
      " 37  x37     158392 non-null  float64\n",
      " 38  x38     158392 non-null  float64\n",
      " 39  x39     158392 non-null  float64\n",
      " 40  x40     158392 non-null  float64\n",
      " 41  x41     158392 non-null  float64\n",
      " 42  x42     158392 non-null  float64\n",
      " 43  x43     158392 non-null  float64\n",
      " 44  x44     158392 non-null  float64\n",
      " 45  x45     158392 non-null  float64\n",
      " 46  x46     158392 non-null  float64\n",
      " 47  x47     158392 non-null  float64\n",
      " 48  x48     158392 non-null  float64\n",
      " 49  x49     158392 non-null  float64\n",
      "dtypes: float64(47), int32(3)\n",
      "memory usage: 59.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(X_train.values, y_train.values)\n",
    "xgtest = xgb.DMatrix(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy is 0.40\n",
      "Baseline Log Loss is 0.67\n"
     ]
    }
   ],
   "source": [
    "# \"Learn\" the mean from the training data\n",
    "mean_train = np.mean(y_train)\n",
    "# Get predictions on the test set\n",
    "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
    "\n",
    "# Compute Log Loss and Accuracy\n",
    "log_baseline = log_loss(y_test, baseline_predictions)\n",
    "acc_baseline = accuracy_score(y_test, np.ones(baseline_predictions.shape))\n",
    "\n",
    "print(\"Baseline Accuracy is {:.2f}\".format(acc_baseline))\n",
    "print(\"Baseline Log Loss is {:.2f}\".format(log_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WilliamNayden\\anaconda3\\envs\\DS7331\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:28:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.43%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17821  1047]\n",
      " [ 1352 11459]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$282,895.00\n"
     ]
    }
   ],
   "source": [
    "total_loss = (1047*225) + (1352*35)\n",
    "formatted = \"${:,.2f}\".format(total_loss)\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'binary:hinge',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eval_metric'] = \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-error:0.59560\n",
      "[1]\tTest-error:0.52628\n",
      "[2]\tTest-error:0.26383\n",
      "[3]\tTest-error:0.22052\n",
      "[4]\tTest-error:0.20559\n",
      "[5]\tTest-error:0.19499\n",
      "[6]\tTest-error:0.18549\n",
      "[7]\tTest-error:0.17071\n",
      "[8]\tTest-error:0.16304\n",
      "[9]\tTest-error:0.15717\n",
      "[10]\tTest-error:0.15357\n",
      "[11]\tTest-error:0.14991\n",
      "[12]\tTest-error:0.14262\n",
      "[13]\tTest-error:0.13801\n",
      "[14]\tTest-error:0.13548\n",
      "[15]\tTest-error:0.13372\n",
      "[16]\tTest-error:0.12983\n",
      "[17]\tTest-error:0.12904\n",
      "[18]\tTest-error:0.12545\n",
      "[19]\tTest-error:0.12431\n",
      "[20]\tTest-error:0.12210\n",
      "[21]\tTest-error:0.12011\n",
      "[22]\tTest-error:0.11992\n",
      "[23]\tTest-error:0.11916\n",
      "[24]\tTest-error:0.11784\n",
      "[25]\tTest-error:0.11326\n",
      "[26]\tTest-error:0.10922\n",
      "[27]\tTest-error:0.10673\n",
      "[28]\tTest-error:0.10398\n",
      "[29]\tTest-error:0.10275\n",
      "[30]\tTest-error:0.10127\n",
      "[31]\tTest-error:0.09994\n",
      "[32]\tTest-error:0.09782\n",
      "[33]\tTest-error:0.09754\n",
      "[34]\tTest-error:0.09666\n",
      "[35]\tTest-error:0.09514\n",
      "[36]\tTest-error:0.09454\n",
      "[37]\tTest-error:0.09385\n",
      "[38]\tTest-error:0.09281\n",
      "[39]\tTest-error:0.09211\n",
      "[40]\tTest-error:0.09082\n",
      "[41]\tTest-error:0.09022\n",
      "[42]\tTest-error:0.08876\n",
      "[43]\tTest-error:0.08798\n",
      "[44]\tTest-error:0.08741\n",
      "[45]\tTest-error:0.08690\n",
      "[46]\tTest-error:0.08687\n",
      "[47]\tTest-error:0.08621\n",
      "[48]\tTest-error:0.08460\n",
      "[49]\tTest-error:0.08413\n",
      "[50]\tTest-error:0.08381\n",
      "[51]\tTest-error:0.08387\n",
      "[52]\tTest-error:0.08390\n",
      "[53]\tTest-error:0.08390\n",
      "[54]\tTest-error:0.08324\n",
      "[55]\tTest-error:0.08293\n",
      "[56]\tTest-error:0.08176\n",
      "[57]\tTest-error:0.08103\n",
      "[58]\tTest-error:0.08087\n",
      "[59]\tTest-error:0.08100\n",
      "[60]\tTest-error:0.08068\n",
      "[61]\tTest-error:0.08056\n",
      "[62]\tTest-error:0.08065\n",
      "[63]\tTest-error:0.08021\n",
      "[64]\tTest-error:0.08027\n",
      "[65]\tTest-error:0.08015\n",
      "[66]\tTest-error:0.08027\n",
      "[67]\tTest-error:0.07989\n",
      "[68]\tTest-error:0.08005\n",
      "[69]\tTest-error:0.08009\n",
      "[70]\tTest-error:0.07964\n",
      "[71]\tTest-error:0.07977\n",
      "[72]\tTest-error:0.07980\n",
      "[73]\tTest-error:0.07958\n",
      "[74]\tTest-error:0.07876\n",
      "[75]\tTest-error:0.07844\n",
      "[76]\tTest-error:0.07860\n",
      "[77]\tTest-error:0.07863\n",
      "[78]\tTest-error:0.07866\n",
      "[79]\tTest-error:0.07866\n",
      "[80]\tTest-error:0.07860\n",
      "[81]\tTest-error:0.07844\n",
      "[82]\tTest-error:0.07828\n",
      "[83]\tTest-error:0.07825\n",
      "[84]\tTest-error:0.07816\n",
      "[85]\tTest-error:0.07781\n",
      "[86]\tTest-error:0.07765\n",
      "[87]\tTest-error:0.07753\n",
      "[88]\tTest-error:0.07743\n",
      "[89]\tTest-error:0.07747\n",
      "[90]\tTest-error:0.07750\n",
      "[91]\tTest-error:0.07750\n",
      "[92]\tTest-error:0.07750\n",
      "[93]\tTest-error:0.07753\n",
      "[94]\tTest-error:0.07775\n",
      "[95]\tTest-error:0.07772\n",
      "[96]\tTest-error:0.07769\n",
      "[97]\tTest-error:0.07690\n",
      "[98]\tTest-error:0.07712\n",
      "[99]\tTest-error:0.07699\n",
      "[100]\tTest-error:0.07705\n",
      "[101]\tTest-error:0.07617\n",
      "[102]\tTest-error:0.07554\n",
      "[103]\tTest-error:0.07541\n",
      "[104]\tTest-error:0.07529\n",
      "[105]\tTest-error:0.07535\n",
      "[106]\tTest-error:0.07513\n",
      "[107]\tTest-error:0.07544\n",
      "[108]\tTest-error:0.07532\n",
      "[109]\tTest-error:0.07535\n",
      "[110]\tTest-error:0.07516\n",
      "[111]\tTest-error:0.07475\n",
      "[112]\tTest-error:0.07478\n",
      "[113]\tTest-error:0.07465\n",
      "[114]\tTest-error:0.07475\n",
      "[115]\tTest-error:0.07484\n",
      "[116]\tTest-error:0.07443\n",
      "[117]\tTest-error:0.07462\n",
      "[118]\tTest-error:0.07459\n",
      "[119]\tTest-error:0.07440\n",
      "[120]\tTest-error:0.07443\n",
      "[121]\tTest-error:0.07447\n",
      "[122]\tTest-error:0.07462\n",
      "[123]\tTest-error:0.07456\n",
      "[124]\tTest-error:0.07459\n",
      "[125]\tTest-error:0.07450\n",
      "[126]\tTest-error:0.07415\n",
      "[127]\tTest-error:0.07421\n",
      "[128]\tTest-error:0.07412\n",
      "[129]\tTest-error:0.07437\n",
      "[130]\tTest-error:0.07421\n",
      "[131]\tTest-error:0.07440\n",
      "[132]\tTest-error:0.07434\n",
      "[133]\tTest-error:0.07440\n",
      "[134]\tTest-error:0.07447\n",
      "[135]\tTest-error:0.07469\n",
      "[136]\tTest-error:0.07443\n",
      "[137]\tTest-error:0.07447\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = 999\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.93 with 129 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Accuracy: {:.2f} with {} rounds\".format(\n",
    "                 (1-model.best_score),\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.599607</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>22.091349</td>\n",
       "      <td>0.044683</td>\n",
       "      <td>0.599607</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>22.090093</td>\n",
       "      <td>0.178729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.518818</td>\n",
       "      <td>0.023295</td>\n",
       "      <td>19.114787</td>\n",
       "      <td>0.858270</td>\n",
       "      <td>0.520349</td>\n",
       "      <td>0.019487</td>\n",
       "      <td>19.170089</td>\n",
       "      <td>0.717906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.280171</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>10.322113</td>\n",
       "      <td>0.268003</td>\n",
       "      <td>0.285006</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>10.500096</td>\n",
       "      <td>0.254380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.221025</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>8.142972</td>\n",
       "      <td>0.117538</td>\n",
       "      <td>0.226812</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>8.356120</td>\n",
       "      <td>0.120233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.197040</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>7.259264</td>\n",
       "      <td>0.095221</td>\n",
       "      <td>0.203278</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>7.489102</td>\n",
       "      <td>0.137180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.047523</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>1.750815</td>\n",
       "      <td>0.077569</td>\n",
       "      <td>0.078840</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>2.904559</td>\n",
       "      <td>0.092868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.047454</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>1.748271</td>\n",
       "      <td>0.076946</td>\n",
       "      <td>0.078737</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>2.900779</td>\n",
       "      <td>0.094268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.047397</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>1.746163</td>\n",
       "      <td>0.076751</td>\n",
       "      <td>0.078713</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>2.899907</td>\n",
       "      <td>0.094290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.047343</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>1.744200</td>\n",
       "      <td>0.075099</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>2.897290</td>\n",
       "      <td>0.094432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.047272</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>1.741584</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.078587</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>2.895255</td>\n",
       "      <td>0.088217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-error-mean  train-error-std  train-logloss-mean  train-logloss-std  \\\n",
       "0            0.599607         0.001213           22.091349           0.044683   \n",
       "1            0.518818         0.023295           19.114787           0.858270   \n",
       "2            0.280171         0.007274           10.322113           0.268003   \n",
       "3            0.221025         0.003190            8.142972           0.117538   \n",
       "4            0.197040         0.002584            7.259264           0.095221   \n",
       "..                ...              ...                 ...                ...   \n",
       "141          0.047523         0.002106            1.750815           0.077569   \n",
       "142          0.047454         0.002088            1.748271           0.076946   \n",
       "143          0.047397         0.002083            1.746163           0.076751   \n",
       "144          0.047343         0.002038            1.744200           0.075099   \n",
       "145          0.047272         0.002018            1.741584           0.074351   \n",
       "\n",
       "     test-error-mean  test-error-std  test-logloss-mean  test-logloss-std  \n",
       "0           0.599607        0.004851          22.090093          0.178729  \n",
       "1           0.520349        0.019487          19.170089          0.717906  \n",
       "2           0.285006        0.006905          10.500096          0.254380  \n",
       "3           0.226812        0.003264           8.356120          0.120233  \n",
       "4           0.203278        0.003724           7.489102          0.137180  \n",
       "..               ...             ...                ...               ...  \n",
       "141         0.078840        0.002521           2.904559          0.092868  \n",
       "142         0.078737        0.002559           2.900779          0.094268  \n",
       "143         0.078713        0.002559           2.899907          0.094290  \n",
       "144         0.078642        0.002563           2.897290          0.094432  \n",
       "145         0.078587        0.002394           2.895255          0.088217  \n",
       "\n",
       "[146 rows x 8 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'logloss','error'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9214132\n",
      "Best Log Loss: 2.8952547999999996\n"
     ]
    }
   ],
   "source": [
    "print('Best Accuracy: {}'.format(1-cv_results['test-error-mean'].min()))\n",
    "print('Best Log Loss: {}'.format(cv_results['test-logloss-mean'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial best params and accuracy\n",
    "min_error = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'logloss', 'error'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best Log Loss\n",
    "    mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "    mean_error = cv_results['test-error-mean'].min()\n",
    "    boost_rounds = cv_results['test-error-mean'].argmin()\n",
    "    print(\"\\Log Loss {} for {} rounds\".format(mean_logloss, boost_rounds))\n",
    "    print(\"\\Accuracy {} for {} rounds\".format((1-mean_error), boost_rounds))\n",
    "    if mean_error < min_error:\n",
    "        min_error = mean_error\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, Log Loss: {}, Accuracy: {}\".format(best_params[0], best_params[1], mean_logloss, (1-min_error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
