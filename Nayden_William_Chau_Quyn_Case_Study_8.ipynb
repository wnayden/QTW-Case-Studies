{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C://Users//WilliamNayden//Documents//MSDS//case_8.csv\", index_col=0)\n",
    "target = train['target']\n",
    "train.drop(['target'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              v1        v2        v4         v5        v6        v7        v8  \\\n",
      "ID                                                                              \n",
      "3       1.335739  8.727474  3.921026   7.915266  2.599278  3.176895  0.012941   \n",
      "4       1.630686  7.464411  4.145098   9.191265  2.436402  2.483921  2.301630   \n",
      "5       0.943877  5.310079  4.410969   5.326159  3.979592  3.928571  0.019645   \n",
      "6       0.797415  8.304757  4.225930  11.627438  2.097700  1.987549  0.171947   \n",
      "8       1.630686  7.464411  4.145098   8.742359  2.436402  2.483921  1.496569   \n",
      "...          ...       ...       ...        ...       ...       ...       ...   \n",
      "228708  1.630686  7.464411  4.145098   8.742359  2.436402  2.483921  1.496569   \n",
      "228710  1.630686  7.464411  4.145098   8.742359  2.436402  2.483921  1.496569   \n",
      "228711  1.630686  7.464411  4.145098  10.069277  2.436402  2.483921  0.323324   \n",
      "228712  1.630686  7.464411  4.145098  10.106144  2.436402  2.483921  0.309226   \n",
      "228713  1.619763  7.932978  4.640085   8.473141  2.351470  2.826766  3.479754   \n",
      "\n",
      "               v9       v10        v11  ...      v121      v122      v123  \\\n",
      "ID                                      ...                                 \n",
      "3        9.999999  0.503281  16.434108  ...  0.803572  8.000000  1.989780   \n",
      "4        9.031859  1.312910  15.447413  ...  2.737596  6.822439  3.549938   \n",
      "5       12.666667  0.765864  14.756098  ...  2.238806  9.333333  2.477596   \n",
      "6        8.965516  6.542669  16.347483  ...  1.956521  7.018256  1.812795   \n",
      "8        9.031859  1.050328  15.447413  ...  2.737596  6.822439  3.549938   \n",
      "...           ...       ...        ...  ...       ...       ...       ...   \n",
      "228708   9.031859  1.444201  15.447413  ...  2.737596  6.822439  3.549938   \n",
      "228710   9.031859  6.236324  15.447413  ...  2.737596  6.822439  3.549938   \n",
      "228711   9.031859  2.078775  15.447413  ...  2.737596  6.822439  3.549938   \n",
      "228712   9.031859  1.291029  15.447413  ...  2.737596  6.822439  3.549938   \n",
      "228713   9.629630  0.853391  14.959786  ...  4.016948  7.936508  2.944285   \n",
      "\n",
      "            v124      v126      v127      v128  v129      v130      v131  \n",
      "ID                                                                        \n",
      "3       0.035754  1.804126  3.113719  2.024285     0  0.636365  2.857144  \n",
      "4       0.598896  1.672658  3.239542  1.957825     0  1.925763  1.739389  \n",
      "5       0.013452  1.773709  3.922193  1.120468     2  0.883118  1.176472  \n",
      "6       0.002267  1.415230  2.954381  1.990847     1  1.677108  1.034483  \n",
      "8       0.919812  1.672658  3.239542  2.030373     0  1.925763  1.739389  \n",
      "...          ...       ...       ...       ...   ...       ...       ...  \n",
      "228708  0.919812  1.672658  3.239542  2.030373     0  1.925763  1.739389  \n",
      "228710  0.919812  1.672658  3.239542  2.030373     1  1.925763  1.739389  \n",
      "228711  0.156764  1.672658  3.239542  2.417606     2  1.925763  1.739389  \n",
      "228712  0.490658  1.672658  3.239542  3.526650     0  1.925763  1.739389  \n",
      "228713  3.135205  1.943149  4.385553  1.604493     0  1.787610  1.386138  \n",
      "\n",
      "[114321 rows x 112 columns]\n"
     ]
    }
   ],
   "source": [
    "train = train.select_dtypes(exclude=['object'])\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 114321 entries and 112 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset has {} entries and {} features\".format(*train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(X_train.values, y_train.values)\n",
    "xgtest = xgb.DMatrix(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Log Loss is 0.55\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# \"Learn\" the mean from the training data\n",
    "mean_train = np.mean(y_train)\n",
    "# Get predictions on the test set\n",
    "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
    "# Compute MAE\n",
    "log_baseline = log_loss(y_test, baseline_predictions)\n",
    "print(\"Baseline Log Loss is {:.2f}\".format(log_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:squarederror',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eval_metric'] = \"logloss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-logloss:0.60271\n",
      "[1]\tTest-logloss:0.55470\n",
      "[2]\tTest-logloss:0.52809\n",
      "[3]\tTest-logloss:0.51300\n",
      "[4]\tTest-logloss:0.50408\n",
      "[5]\tTest-logloss:0.49902\n",
      "[6]\tTest-logloss:0.49553\n",
      "[7]\tTest-logloss:0.49395\n",
      "[8]\tTest-logloss:0.49293\n",
      "[9]\tTest-logloss:0.49266\n",
      "[10]\tTest-logloss:0.49232\n",
      "[11]\tTest-logloss:0.49213\n",
      "[12]\tTest-logloss:0.49227\n",
      "[13]\tTest-logloss:0.49397\n",
      "[14]\tTest-logloss:0.49575\n",
      "[15]\tTest-logloss:0.49584\n",
      "[16]\tTest-logloss:0.49865\n",
      "[17]\tTest-logloss:0.49989\n",
      "[18]\tTest-logloss:0.50006\n",
      "[19]\tTest-logloss:0.50086\n",
      "[20]\tTest-logloss:0.50114\n",
      "[21]\tTest-logloss:0.50195\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Log Loss: 0.49 with 12 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Log Loss: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.601669</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.603357</td>\n",
       "      <td>0.000504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552235</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.555576</td>\n",
       "      <td>0.001102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523861</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.528975</td>\n",
       "      <td>0.001601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.506550</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.513799</td>\n",
       "      <td>0.001758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.495889</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.505380</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.488966</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.500393</td>\n",
       "      <td>0.002177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.484194</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.497677</td>\n",
       "      <td>0.002197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.480240</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.495854</td>\n",
       "      <td>0.002344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.477260</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.495028</td>\n",
       "      <td>0.002489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.474736</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.494304</td>\n",
       "      <td>0.002708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.473118</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.494134</td>\n",
       "      <td>0.002701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-logloss-mean  train-logloss-std  test-logloss-mean  test-logloss-std\n",
       "0             0.601669           0.000238           0.603357          0.000504\n",
       "1             0.552235           0.000494           0.555576          0.001102\n",
       "2             0.523861           0.000561           0.528975          0.001601\n",
       "3             0.506550           0.000594           0.513799          0.001758\n",
       "4             0.495889           0.000760           0.505380          0.001802\n",
       "5             0.488966           0.000637           0.500393          0.002177\n",
       "6             0.484194           0.001207           0.497677          0.002197\n",
       "7             0.480240           0.001120           0.495854          0.002344\n",
       "8             0.477260           0.001468           0.495028          0.002489\n",
       "9             0.474736           0.001477           0.494304          0.002708\n",
       "10            0.473118           0.001363           0.494134          0.002701"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'logloss'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.494134"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-logloss-mean'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\\Log Loss 0.5012734 for 7 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\\Log Loss 0.5012898 for 7 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\\Log Loss 0.5009812 for 7 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\\Log Loss 0.5060884 for 6 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\\Log Loss 0.5052176 for 6 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\\Log Loss 0.5037912 for 6 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\\Log Loss 0.509282 for 5 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\\Log Loss 0.5081260000000001 for 5 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\\Log Loss 0.5071288 for 5 rounds\n",
      "Best params: 9, 7, Log Loss: 0.5009812\n"
     ]
    }
   ],
   "source": [
    "# Define initial best params and Log Loss\n",
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'logloss'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best Log Loss\n",
    "    mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "    boost_rounds = cv_results['test-logloss-mean'].argmin()\n",
    "    print(\"\\Log Loss {} for {} rounds\".format(mean_logloss, boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, Log Loss: {}\".format(best_params[0], best_params[1], min_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 9\n",
    "params['min_child_weight'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tLog Loss 0.5009812 for 7 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tLog Loss 0.500625 for 6 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tLog Loss 0.5006725999999999 for 6 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tLog Loss 0.5003356 for 7 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tLog Loss 0.504537 for 6 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tLog Loss 0.5017894 for 6 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tLog Loss 0.5025012 for 6 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tLog Loss 0.5018232 for 6 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tLog Loss 0.5033380000000001 for 6 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tLog Loss 0.5030368000000001 for 6 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tLog Loss 0.5041678 for 5 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tLog Loss 0.5033358000000001 for 6 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tLog Loss 0.5064618000000001 for 6 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tLog Loss 0.5058956 for 6 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tLog Loss 0.5067232 for 6 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tLog Loss 0.5059142 for 5 rounds\n",
      "Best params: 1.0, 0.7, Log Loss: 0.5003356\n"
     ]
    }
   ],
   "source": [
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'logloss'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "    boost_rounds = cv_results['test-logloss-mean'].argmin()\n",
    "    print(\"\\tLog Loss {} for {} rounds\".format(mean_logloss, boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, Log Loss: {}\".format(best_params[0], best_params[1], min_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = 1.0\n",
    "params['colsample_bytree'] = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "CV with eta=0.3\n",
      "Wall time: 24.4 s\n",
      "\tLog Loss 0.5003356 for 7 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "Wall time: 36.4 s\n",
      "\tLog Loss 0.49725080000000005 for 12 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "Wall time: 1min 5s\n",
      "\tLog Loss 0.49282200000000004 for 32 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "Wall time: 2min 4s\n",
      "\tLog Loss 0.4909674 for 71 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "Wall time: 12min 44s\n",
      "\tLog Loss 0.48955399999999993 for 439 rounds\n",
      "\n",
      "CV with eta=0.005\n",
      "Wall time: 24min 45s\n",
      "\tLog Loss 0.489199 for 894 rounds\n",
      "\n",
      "Best params: 0.005, Log Loss: 0.489199\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "# This can take some time…\n",
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    \n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    \n",
    "    # Run and time CV\n",
    "    %time cv_results = xgb.cv(params,dtrain,num_boost_round=num_boost_round,seed=42,nfold=5,metrics=['logloss'],early_stopping_rounds=10)\n",
    "    \n",
    "    # Update best score\n",
    "    mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "    boost_rounds = cv_results['test-logloss-mean'].argmin()\n",
    "    print(\"\\tLog Loss {} for {} rounds\\n\".format(mean_logloss, boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, Log Loss: {}\".format(best_params, min_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1.0,\n",
       " 'eta': 0.01,\n",
       " 'eval_metric': 'logloss',\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 6,\n",
       " 'objective': 'reg:linear',\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params\n",
    "{'colsample_bytree': 1.0,\n",
    " 'eta': 0.01,\n",
    " 'eval_metric': 'logloss',\n",
    " 'max_depth': 10,\n",
    " 'min_child_weight': 6,\n",
    " 'objective': 'reg:linear',\n",
    " 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-logloss:0.68964\n",
      "[1]\tTest-logloss:0.68622\n",
      "[2]\tTest-logloss:0.68283\n",
      "[3]\tTest-logloss:0.67955\n",
      "[4]\tTest-logloss:0.67637\n",
      "[5]\tTest-logloss:0.67319\n",
      "[6]\tTest-logloss:0.67008\n",
      "[7]\tTest-logloss:0.66704\n",
      "[8]\tTest-logloss:0.66429\n",
      "[9]\tTest-logloss:0.66133\n",
      "[10]\tTest-logloss:0.65844\n",
      "[11]\tTest-logloss:0.65563\n",
      "[12]\tTest-logloss:0.65288\n",
      "[13]\tTest-logloss:0.65016\n",
      "[14]\tTest-logloss:0.64750\n",
      "[15]\tTest-logloss:0.64512\n",
      "[16]\tTest-logloss:0.64254\n",
      "[17]\tTest-logloss:0.64001\n",
      "[18]\tTest-logloss:0.63752\n",
      "[19]\tTest-logloss:0.63508\n",
      "[20]\tTest-logloss:0.63268\n",
      "[21]\tTest-logloss:0.63055\n",
      "[22]\tTest-logloss:0.62822\n",
      "[23]\tTest-logloss:0.62593\n",
      "[24]\tTest-logloss:0.62368\n",
      "[25]\tTest-logloss:0.62148\n",
      "[26]\tTest-logloss:0.61950\n",
      "[27]\tTest-logloss:0.61737\n",
      "[28]\tTest-logloss:0.61548\n",
      "[29]\tTest-logloss:0.61342\n",
      "[30]\tTest-logloss:0.61140\n",
      "[31]\tTest-logloss:0.60939\n",
      "[32]\tTest-logloss:0.60764\n",
      "[33]\tTest-logloss:0.60571\n",
      "[34]\tTest-logloss:0.60400\n",
      "[35]\tTest-logloss:0.60213\n",
      "[36]\tTest-logloss:0.60030\n",
      "[37]\tTest-logloss:0.59849\n",
      "[38]\tTest-logloss:0.59688\n",
      "[39]\tTest-logloss:0.59532\n",
      "[40]\tTest-logloss:0.59378\n",
      "[41]\tTest-logloss:0.59210\n",
      "[42]\tTest-logloss:0.59045\n",
      "[43]\tTest-logloss:0.58884\n",
      "[44]\tTest-logloss:0.58723\n",
      "[45]\tTest-logloss:0.58565\n",
      "[46]\tTest-logloss:0.58412\n",
      "[47]\tTest-logloss:0.58260\n",
      "[48]\tTest-logloss:0.58111\n",
      "[49]\tTest-logloss:0.57964\n",
      "[50]\tTest-logloss:0.57819\n",
      "[51]\tTest-logloss:0.57676\n",
      "[52]\tTest-logloss:0.57551\n",
      "[53]\tTest-logloss:0.57414\n",
      "[54]\tTest-logloss:0.57280\n",
      "[55]\tTest-logloss:0.57145\n",
      "[56]\tTest-logloss:0.57016\n",
      "[57]\tTest-logloss:0.56887\n",
      "[58]\tTest-logloss:0.56758\n",
      "[59]\tTest-logloss:0.56633\n",
      "[60]\tTest-logloss:0.56509\n",
      "[61]\tTest-logloss:0.56388\n",
      "[62]\tTest-logloss:0.56269\n",
      "[63]\tTest-logloss:0.56153\n",
      "[64]\tTest-logloss:0.56039\n",
      "[65]\tTest-logloss:0.55939\n",
      "[66]\tTest-logloss:0.55828\n",
      "[67]\tTest-logloss:0.55719\n",
      "[68]\tTest-logloss:0.55611\n",
      "[69]\tTest-logloss:0.55505\n",
      "[70]\tTest-logloss:0.55398\n",
      "[71]\tTest-logloss:0.55295\n",
      "[72]\tTest-logloss:0.55195\n",
      "[73]\tTest-logloss:0.55095\n",
      "[74]\tTest-logloss:0.54997\n",
      "[75]\tTest-logloss:0.54902\n",
      "[76]\tTest-logloss:0.54815\n",
      "[77]\tTest-logloss:0.54722\n",
      "[78]\tTest-logloss:0.54630\n",
      "[79]\tTest-logloss:0.54538\n",
      "[80]\tTest-logloss:0.54461\n",
      "[81]\tTest-logloss:0.54386\n",
      "[82]\tTest-logloss:0.54300\n",
      "[83]\tTest-logloss:0.54215\n",
      "[84]\tTest-logloss:0.54129\n",
      "[85]\tTest-logloss:0.54047\n",
      "[86]\tTest-logloss:0.53965\n",
      "[87]\tTest-logloss:0.53894\n",
      "[88]\tTest-logloss:0.53815\n",
      "[89]\tTest-logloss:0.53746\n",
      "[90]\tTest-logloss:0.53668\n",
      "[91]\tTest-logloss:0.53593\n",
      "[92]\tTest-logloss:0.53526\n",
      "[93]\tTest-logloss:0.53454\n",
      "[94]\tTest-logloss:0.53382\n",
      "[95]\tTest-logloss:0.53313\n",
      "[96]\tTest-logloss:0.53245\n",
      "[97]\tTest-logloss:0.53178\n",
      "[98]\tTest-logloss:0.53118\n",
      "[99]\tTest-logloss:0.53050\n",
      "[100]\tTest-logloss:0.52991\n",
      "[101]\tTest-logloss:0.52927\n",
      "[102]\tTest-logloss:0.52864\n",
      "[103]\tTest-logloss:0.52802\n",
      "[104]\tTest-logloss:0.52750\n",
      "[105]\tTest-logloss:0.52688\n",
      "[106]\tTest-logloss:0.52626\n",
      "[107]\tTest-logloss:0.52567\n",
      "[108]\tTest-logloss:0.52509\n",
      "[109]\tTest-logloss:0.52452\n",
      "[110]\tTest-logloss:0.52394\n",
      "[111]\tTest-logloss:0.52337\n",
      "[112]\tTest-logloss:0.52282\n",
      "[113]\tTest-logloss:0.52233\n",
      "[114]\tTest-logloss:0.52180\n",
      "[115]\tTest-logloss:0.52128\n",
      "[116]\tTest-logloss:0.52077\n",
      "[117]\tTest-logloss:0.52028\n",
      "[118]\tTest-logloss:0.51987\n",
      "[119]\tTest-logloss:0.51937\n",
      "[120]\tTest-logloss:0.51890\n",
      "[121]\tTest-logloss:0.51844\n",
      "[122]\tTest-logloss:0.51797\n",
      "[123]\tTest-logloss:0.51751\n",
      "[124]\tTest-logloss:0.51705\n",
      "[125]\tTest-logloss:0.51660\n",
      "[126]\tTest-logloss:0.51614\n",
      "[127]\tTest-logloss:0.51570\n",
      "[128]\tTest-logloss:0.51526\n",
      "[129]\tTest-logloss:0.51484\n",
      "[130]\tTest-logloss:0.51443\n",
      "[131]\tTest-logloss:0.51404\n",
      "[132]\tTest-logloss:0.51363\n",
      "[133]\tTest-logloss:0.51323\n",
      "[134]\tTest-logloss:0.51282\n",
      "[135]\tTest-logloss:0.51245\n",
      "[136]\tTest-logloss:0.51206\n",
      "[137]\tTest-logloss:0.51167\n",
      "[138]\tTest-logloss:0.51130\n",
      "[139]\tTest-logloss:0.51092\n",
      "[140]\tTest-logloss:0.51055\n",
      "[141]\tTest-logloss:0.51021\n",
      "[142]\tTest-logloss:0.50991\n",
      "[143]\tTest-logloss:0.50957\n",
      "[144]\tTest-logloss:0.50921\n",
      "[145]\tTest-logloss:0.50886\n",
      "[146]\tTest-logloss:0.50854\n",
      "[147]\tTest-logloss:0.50821\n",
      "[148]\tTest-logloss:0.50789\n",
      "[149]\tTest-logloss:0.50756\n",
      "[150]\tTest-logloss:0.50725\n",
      "[151]\tTest-logloss:0.50695\n",
      "[152]\tTest-logloss:0.50665\n",
      "[153]\tTest-logloss:0.50635\n",
      "[154]\tTest-logloss:0.50606\n",
      "[155]\tTest-logloss:0.50580\n",
      "[156]\tTest-logloss:0.50551\n",
      "[157]\tTest-logloss:0.50523\n",
      "[158]\tTest-logloss:0.50497\n",
      "[159]\tTest-logloss:0.50470\n",
      "[160]\tTest-logloss:0.50444\n",
      "[161]\tTest-logloss:0.50419\n",
      "[162]\tTest-logloss:0.50394\n",
      "[163]\tTest-logloss:0.50371\n",
      "[164]\tTest-logloss:0.50348\n",
      "[165]\tTest-logloss:0.50324\n",
      "[166]\tTest-logloss:0.50303\n",
      "[167]\tTest-logloss:0.50280\n",
      "[168]\tTest-logloss:0.50257\n",
      "[169]\tTest-logloss:0.50234\n",
      "[170]\tTest-logloss:0.50214\n",
      "[171]\tTest-logloss:0.50193\n",
      "[172]\tTest-logloss:0.50170\n",
      "[173]\tTest-logloss:0.50149\n",
      "[174]\tTest-logloss:0.50129\n",
      "[175]\tTest-logloss:0.50107\n",
      "[176]\tTest-logloss:0.50086\n",
      "[177]\tTest-logloss:0.50067\n",
      "[178]\tTest-logloss:0.50050\n",
      "[179]\tTest-logloss:0.50031\n",
      "[180]\tTest-logloss:0.50012\n",
      "[181]\tTest-logloss:0.49993\n",
      "[182]\tTest-logloss:0.49976\n",
      "[183]\tTest-logloss:0.49956\n",
      "[184]\tTest-logloss:0.49939\n",
      "[185]\tTest-logloss:0.49922\n",
      "[186]\tTest-logloss:0.49904\n",
      "[187]\tTest-logloss:0.49887\n",
      "[188]\tTest-logloss:0.49869\n",
      "[189]\tTest-logloss:0.49852\n",
      "[190]\tTest-logloss:0.49835\n",
      "[191]\tTest-logloss:0.49820\n",
      "[192]\tTest-logloss:0.49803\n",
      "[193]\tTest-logloss:0.49787\n",
      "[194]\tTest-logloss:0.49769\n",
      "[195]\tTest-logloss:0.49755\n",
      "[196]\tTest-logloss:0.49740\n",
      "[197]\tTest-logloss:0.49725\n",
      "[198]\tTest-logloss:0.49708\n",
      "[199]\tTest-logloss:0.49694\n",
      "[200]\tTest-logloss:0.49682\n",
      "[201]\tTest-logloss:0.49667\n",
      "[202]\tTest-logloss:0.49655\n",
      "[203]\tTest-logloss:0.49640\n",
      "[204]\tTest-logloss:0.49627\n",
      "[205]\tTest-logloss:0.49615\n",
      "[206]\tTest-logloss:0.49604\n",
      "[207]\tTest-logloss:0.49591\n",
      "[208]\tTest-logloss:0.49578\n",
      "[209]\tTest-logloss:0.49565\n",
      "[210]\tTest-logloss:0.49552\n",
      "[211]\tTest-logloss:0.49540\n",
      "[212]\tTest-logloss:0.49527\n",
      "[213]\tTest-logloss:0.49516\n",
      "[214]\tTest-logloss:0.49505\n",
      "[215]\tTest-logloss:0.49494\n",
      "[216]\tTest-logloss:0.49483\n",
      "[217]\tTest-logloss:0.49472\n",
      "[218]\tTest-logloss:0.49461\n",
      "[219]\tTest-logloss:0.49451\n",
      "[220]\tTest-logloss:0.49441\n",
      "[221]\tTest-logloss:0.49432\n",
      "[222]\tTest-logloss:0.49421\n",
      "[223]\tTest-logloss:0.49410\n",
      "[224]\tTest-logloss:0.49401\n",
      "[225]\tTest-logloss:0.49391\n",
      "[226]\tTest-logloss:0.49382\n",
      "[227]\tTest-logloss:0.49373\n",
      "[228]\tTest-logloss:0.49361\n",
      "[229]\tTest-logloss:0.49351\n",
      "[230]\tTest-logloss:0.49342\n",
      "[231]\tTest-logloss:0.49334\n",
      "[232]\tTest-logloss:0.49325\n",
      "[233]\tTest-logloss:0.49316\n",
      "[234]\tTest-logloss:0.49307\n",
      "[235]\tTest-logloss:0.49300\n",
      "[236]\tTest-logloss:0.49291\n",
      "[237]\tTest-logloss:0.49284\n",
      "[238]\tTest-logloss:0.49276\n",
      "[239]\tTest-logloss:0.49267\n",
      "[240]\tTest-logloss:0.49259\n",
      "[241]\tTest-logloss:0.49251\n",
      "[242]\tTest-logloss:0.49243\n",
      "[243]\tTest-logloss:0.49236\n",
      "[244]\tTest-logloss:0.49229\n",
      "[245]\tTest-logloss:0.49222\n",
      "[246]\tTest-logloss:0.49214\n",
      "[247]\tTest-logloss:0.49208\n",
      "[248]\tTest-logloss:0.49200\n",
      "[249]\tTest-logloss:0.49193\n",
      "[250]\tTest-logloss:0.49187\n",
      "[251]\tTest-logloss:0.49180\n",
      "[252]\tTest-logloss:0.49172\n",
      "[253]\tTest-logloss:0.49165\n",
      "[254]\tTest-logloss:0.49158\n",
      "[255]\tTest-logloss:0.49152\n",
      "[256]\tTest-logloss:0.49146\n",
      "[257]\tTest-logloss:0.49140\n",
      "[258]\tTest-logloss:0.49135\n",
      "[259]\tTest-logloss:0.49127\n",
      "[260]\tTest-logloss:0.49119\n",
      "[261]\tTest-logloss:0.49114\n",
      "[262]\tTest-logloss:0.49109\n",
      "[263]\tTest-logloss:0.49103\n",
      "[264]\tTest-logloss:0.49097\n",
      "[265]\tTest-logloss:0.49092\n",
      "[266]\tTest-logloss:0.49086\n",
      "[267]\tTest-logloss:0.49080\n",
      "[268]\tTest-logloss:0.49075\n",
      "[269]\tTest-logloss:0.49070\n",
      "[270]\tTest-logloss:0.49066\n",
      "[271]\tTest-logloss:0.49061\n",
      "[272]\tTest-logloss:0.49057\n",
      "[273]\tTest-logloss:0.49051\n",
      "[274]\tTest-logloss:0.49045\n",
      "[275]\tTest-logloss:0.49042\n",
      "[276]\tTest-logloss:0.49037\n",
      "[277]\tTest-logloss:0.49034\n",
      "[278]\tTest-logloss:0.49029\n",
      "[279]\tTest-logloss:0.49024\n",
      "[280]\tTest-logloss:0.49020\n",
      "[281]\tTest-logloss:0.49016\n",
      "[282]\tTest-logloss:0.49012\n",
      "[283]\tTest-logloss:0.49008\n",
      "[284]\tTest-logloss:0.49005\n",
      "[285]\tTest-logloss:0.49001\n",
      "[286]\tTest-logloss:0.48997\n",
      "[287]\tTest-logloss:0.48993\n",
      "[288]\tTest-logloss:0.48990\n",
      "[289]\tTest-logloss:0.48987\n",
      "[290]\tTest-logloss:0.48981\n",
      "[291]\tTest-logloss:0.48977\n",
      "[292]\tTest-logloss:0.48974\n",
      "[293]\tTest-logloss:0.48970\n",
      "[294]\tTest-logloss:0.48964\n",
      "[295]\tTest-logloss:0.48960\n",
      "[296]\tTest-logloss:0.48957\n",
      "[297]\tTest-logloss:0.48953\n",
      "[298]\tTest-logloss:0.48949\n",
      "[299]\tTest-logloss:0.48943\n",
      "[300]\tTest-logloss:0.48940\n",
      "[301]\tTest-logloss:0.48936\n",
      "[302]\tTest-logloss:0.48933\n",
      "[303]\tTest-logloss:0.48931\n",
      "[304]\tTest-logloss:0.48928\n",
      "[305]\tTest-logloss:0.48925\n",
      "[306]\tTest-logloss:0.48923\n",
      "[307]\tTest-logloss:0.48918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[308]\tTest-logloss:0.48915\n",
      "[309]\tTest-logloss:0.48912\n",
      "[310]\tTest-logloss:0.48909\n",
      "[311]\tTest-logloss:0.48907\n",
      "[312]\tTest-logloss:0.48901\n",
      "[313]\tTest-logloss:0.48895\n",
      "[314]\tTest-logloss:0.48892\n",
      "[315]\tTest-logloss:0.48889\n",
      "[316]\tTest-logloss:0.48886\n",
      "[317]\tTest-logloss:0.48883\n",
      "[318]\tTest-logloss:0.48879\n",
      "[319]\tTest-logloss:0.48875\n",
      "[320]\tTest-logloss:0.48871\n",
      "[321]\tTest-logloss:0.48869\n",
      "[322]\tTest-logloss:0.48867\n",
      "[323]\tTest-logloss:0.48863\n",
      "[324]\tTest-logloss:0.48862\n",
      "[325]\tTest-logloss:0.48860\n",
      "[326]\tTest-logloss:0.48857\n",
      "[327]\tTest-logloss:0.48855\n",
      "[328]\tTest-logloss:0.48853\n",
      "[329]\tTest-logloss:0.48848\n",
      "[330]\tTest-logloss:0.48848\n",
      "[331]\tTest-logloss:0.48846\n",
      "[332]\tTest-logloss:0.48842\n",
      "[333]\tTest-logloss:0.48838\n",
      "[334]\tTest-logloss:0.48836\n",
      "[335]\tTest-logloss:0.48834\n",
      "[336]\tTest-logloss:0.48832\n",
      "[337]\tTest-logloss:0.48830\n",
      "[338]\tTest-logloss:0.48827\n",
      "[339]\tTest-logloss:0.48826\n",
      "[340]\tTest-logloss:0.48824\n",
      "[341]\tTest-logloss:0.48820\n",
      "[342]\tTest-logloss:0.48815\n",
      "[343]\tTest-logloss:0.48813\n",
      "[344]\tTest-logloss:0.48812\n",
      "[345]\tTest-logloss:0.48810\n",
      "[346]\tTest-logloss:0.48809\n",
      "[347]\tTest-logloss:0.48805\n",
      "[348]\tTest-logloss:0.48803\n",
      "[349]\tTest-logloss:0.48802\n",
      "[350]\tTest-logloss:0.48800\n",
      "[351]\tTest-logloss:0.48798\n",
      "[352]\tTest-logloss:0.48795\n",
      "[353]\tTest-logloss:0.48793\n",
      "[354]\tTest-logloss:0.48791\n",
      "[355]\tTest-logloss:0.48788\n",
      "[356]\tTest-logloss:0.48786\n",
      "[357]\tTest-logloss:0.48785\n",
      "[358]\tTest-logloss:0.48783\n",
      "[359]\tTest-logloss:0.48780\n",
      "[360]\tTest-logloss:0.48779\n",
      "[361]\tTest-logloss:0.48778\n",
      "[362]\tTest-logloss:0.48775\n",
      "[363]\tTest-logloss:0.48774\n",
      "[364]\tTest-logloss:0.48771\n",
      "[365]\tTest-logloss:0.48769\n",
      "[366]\tTest-logloss:0.48767\n",
      "[367]\tTest-logloss:0.48766\n",
      "[368]\tTest-logloss:0.48766\n",
      "[369]\tTest-logloss:0.48765\n",
      "[370]\tTest-logloss:0.48764\n",
      "[371]\tTest-logloss:0.48762\n",
      "[372]\tTest-logloss:0.48760\n",
      "[373]\tTest-logloss:0.48760\n",
      "[374]\tTest-logloss:0.48758\n",
      "[375]\tTest-logloss:0.48757\n",
      "[376]\tTest-logloss:0.48755\n",
      "[377]\tTest-logloss:0.48754\n",
      "[378]\tTest-logloss:0.48753\n",
      "[379]\tTest-logloss:0.48751\n",
      "[380]\tTest-logloss:0.48751\n",
      "[381]\tTest-logloss:0.48751\n",
      "[382]\tTest-logloss:0.48749\n",
      "[383]\tTest-logloss:0.48749\n",
      "[384]\tTest-logloss:0.48747\n",
      "[385]\tTest-logloss:0.48746\n",
      "[386]\tTest-logloss:0.48746\n",
      "[387]\tTest-logloss:0.48745\n",
      "[388]\tTest-logloss:0.48744\n",
      "[389]\tTest-logloss:0.48743\n",
      "[390]\tTest-logloss:0.48743\n",
      "[391]\tTest-logloss:0.48741\n",
      "[392]\tTest-logloss:0.48738\n",
      "[393]\tTest-logloss:0.48736\n",
      "[394]\tTest-logloss:0.48735\n",
      "[395]\tTest-logloss:0.48735\n",
      "[396]\tTest-logloss:0.48734\n",
      "[397]\tTest-logloss:0.48732\n",
      "[398]\tTest-logloss:0.48731\n",
      "[399]\tTest-logloss:0.48730\n",
      "[400]\tTest-logloss:0.48729\n",
      "[401]\tTest-logloss:0.48728\n",
      "[402]\tTest-logloss:0.48727\n",
      "[403]\tTest-logloss:0.48727\n",
      "[404]\tTest-logloss:0.48725\n",
      "[405]\tTest-logloss:0.48724\n",
      "[406]\tTest-logloss:0.48723\n",
      "[407]\tTest-logloss:0.48722\n",
      "[408]\tTest-logloss:0.48721\n",
      "[409]\tTest-logloss:0.48720\n",
      "[410]\tTest-logloss:0.48718\n",
      "[411]\tTest-logloss:0.48718\n",
      "[412]\tTest-logloss:0.48717\n",
      "[413]\tTest-logloss:0.48717\n",
      "[414]\tTest-logloss:0.48716\n",
      "[415]\tTest-logloss:0.48715\n",
      "[416]\tTest-logloss:0.48714\n",
      "[417]\tTest-logloss:0.48713\n",
      "[418]\tTest-logloss:0.48711\n",
      "[419]\tTest-logloss:0.48711\n",
      "[420]\tTest-logloss:0.48710\n",
      "[421]\tTest-logloss:0.48710\n",
      "[422]\tTest-logloss:0.48709\n",
      "[423]\tTest-logloss:0.48708\n",
      "[424]\tTest-logloss:0.48706\n",
      "[425]\tTest-logloss:0.48705\n",
      "[426]\tTest-logloss:0.48704\n",
      "[427]\tTest-logloss:0.48703\n",
      "[428]\tTest-logloss:0.48702\n",
      "[429]\tTest-logloss:0.48702\n",
      "[430]\tTest-logloss:0.48703\n",
      "[431]\tTest-logloss:0.48702\n",
      "[432]\tTest-logloss:0.48702\n",
      "[433]\tTest-logloss:0.48700\n",
      "[434]\tTest-logloss:0.48699\n",
      "[435]\tTest-logloss:0.48696\n",
      "[436]\tTest-logloss:0.48696\n",
      "[437]\tTest-logloss:0.48695\n",
      "[438]\tTest-logloss:0.48694\n",
      "[439]\tTest-logloss:0.48693\n",
      "[440]\tTest-logloss:0.48693\n",
      "[441]\tTest-logloss:0.48690\n",
      "[442]\tTest-logloss:0.48690\n",
      "[443]\tTest-logloss:0.48689\n",
      "[444]\tTest-logloss:0.48689\n",
      "[445]\tTest-logloss:0.48688\n",
      "[446]\tTest-logloss:0.48688\n",
      "[447]\tTest-logloss:0.48688\n",
      "[448]\tTest-logloss:0.48688\n",
      "[449]\tTest-logloss:0.48686\n",
      "[450]\tTest-logloss:0.48685\n",
      "[451]\tTest-logloss:0.48685\n",
      "[452]\tTest-logloss:0.48684\n",
      "[453]\tTest-logloss:0.48684\n",
      "[454]\tTest-logloss:0.48684\n",
      "[455]\tTest-logloss:0.48684\n",
      "[456]\tTest-logloss:0.48683\n",
      "[457]\tTest-logloss:0.48683\n",
      "[458]\tTest-logloss:0.48682\n",
      "[459]\tTest-logloss:0.48682\n",
      "[460]\tTest-logloss:0.48682\n",
      "[461]\tTest-logloss:0.48681\n",
      "[462]\tTest-logloss:0.48681\n",
      "[463]\tTest-logloss:0.48680\n",
      "[464]\tTest-logloss:0.48679\n",
      "[465]\tTest-logloss:0.48679\n",
      "[466]\tTest-logloss:0.48679\n",
      "[467]\tTest-logloss:0.48679\n",
      "[468]\tTest-logloss:0.48679\n",
      "[469]\tTest-logloss:0.48679\n",
      "[470]\tTest-logloss:0.48679\n",
      "[471]\tTest-logloss:0.48679\n",
      "[472]\tTest-logloss:0.48679\n",
      "[473]\tTest-logloss:0.48678\n",
      "[474]\tTest-logloss:0.48678\n",
      "[475]\tTest-logloss:0.48677\n",
      "[476]\tTest-logloss:0.48677\n",
      "[477]\tTest-logloss:0.48677\n",
      "[478]\tTest-logloss:0.48677\n",
      "[479]\tTest-logloss:0.48677\n",
      "[480]\tTest-logloss:0.48676\n",
      "[481]\tTest-logloss:0.48676\n",
      "[482]\tTest-logloss:0.48676\n",
      "[483]\tTest-logloss:0.48676\n",
      "[484]\tTest-logloss:0.48677\n",
      "[485]\tTest-logloss:0.48676\n",
      "[486]\tTest-logloss:0.48676\n",
      "[487]\tTest-logloss:0.48676\n",
      "[488]\tTest-logloss:0.48675\n",
      "[489]\tTest-logloss:0.48674\n",
      "[490]\tTest-logloss:0.48674\n",
      "[491]\tTest-logloss:0.48673\n",
      "[492]\tTest-logloss:0.48673\n",
      "[493]\tTest-logloss:0.48673\n",
      "[494]\tTest-logloss:0.48673\n",
      "[495]\tTest-logloss:0.48673\n",
      "[496]\tTest-logloss:0.48672\n",
      "[497]\tTest-logloss:0.48672\n",
      "[498]\tTest-logloss:0.48672\n",
      "[499]\tTest-logloss:0.48671\n",
      "[500]\tTest-logloss:0.48671\n",
      "[501]\tTest-logloss:0.48671\n",
      "[502]\tTest-logloss:0.48670\n",
      "[503]\tTest-logloss:0.48670\n",
      "[504]\tTest-logloss:0.48670\n",
      "[505]\tTest-logloss:0.48668\n",
      "[506]\tTest-logloss:0.48668\n",
      "[507]\tTest-logloss:0.48667\n",
      "[508]\tTest-logloss:0.48666\n",
      "[509]\tTest-logloss:0.48667\n",
      "[510]\tTest-logloss:0.48667\n",
      "[511]\tTest-logloss:0.48665\n",
      "[512]\tTest-logloss:0.48665\n",
      "[513]\tTest-logloss:0.48664\n",
      "[514]\tTest-logloss:0.48664\n",
      "[515]\tTest-logloss:0.48663\n",
      "[516]\tTest-logloss:0.48662\n",
      "[517]\tTest-logloss:0.48662\n",
      "[518]\tTest-logloss:0.48661\n",
      "[519]\tTest-logloss:0.48661\n",
      "[520]\tTest-logloss:0.48661\n",
      "[521]\tTest-logloss:0.48661\n",
      "[522]\tTest-logloss:0.48660\n",
      "[523]\tTest-logloss:0.48660\n",
      "[524]\tTest-logloss:0.48660\n",
      "[525]\tTest-logloss:0.48660\n",
      "[526]\tTest-logloss:0.48661\n",
      "[527]\tTest-logloss:0.48661\n",
      "[528]\tTest-logloss:0.48661\n",
      "[529]\tTest-logloss:0.48661\n",
      "[530]\tTest-logloss:0.48661\n",
      "[531]\tTest-logloss:0.48661\n",
      "[532]\tTest-logloss:0.48660\n",
      "[533]\tTest-logloss:0.48659\n",
      "[534]\tTest-logloss:0.48658\n",
      "[535]\tTest-logloss:0.48658\n",
      "[536]\tTest-logloss:0.48657\n",
      "[537]\tTest-logloss:0.48657\n",
      "[538]\tTest-logloss:0.48657\n",
      "[539]\tTest-logloss:0.48657\n",
      "[540]\tTest-logloss:0.48657\n",
      "[541]\tTest-logloss:0.48658\n",
      "[542]\tTest-logloss:0.48658\n",
      "[543]\tTest-logloss:0.48658\n",
      "[544]\tTest-logloss:0.48657\n",
      "[545]\tTest-logloss:0.48658\n",
      "[546]\tTest-logloss:0.48658\n",
      "[547]\tTest-logloss:0.48658\n",
      "[548]\tTest-logloss:0.48657\n",
      "[549]\tTest-logloss:0.48657\n",
      "[550]\tTest-logloss:0.48657\n",
      "[551]\tTest-logloss:0.48657\n",
      "[552]\tTest-logloss:0.48656\n",
      "[553]\tTest-logloss:0.48656\n",
      "[554]\tTest-logloss:0.48734\n",
      "[555]\tTest-logloss:0.48735\n",
      "[556]\tTest-logloss:0.48736\n",
      "[557]\tTest-logloss:0.48735\n",
      "[558]\tTest-logloss:0.48736\n",
      "[559]\tTest-logloss:0.48735\n",
      "[560]\tTest-logloss:0.48735\n",
      "[561]\tTest-logloss:0.48735\n",
      "Best Log Loss: 0.49 in 553 rounds\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "print(\"Best Log Loss: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
