{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 12\n",
    "\n",
    "William Nayden and Quynh Chau\n",
    "March 29, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 INTRODUCTION\n",
    "\n",
    "The purpose of this case study is to duplicate the Baldi et al. study titled \"Searching for Exotic Particles in High-Energy\n",
    "Physics using Deep Learning\" by implementing neural network model via TensorFlow in Python. Data can be downloaded from the\n",
    "following site:  'https://archive.ics.uci.edu/ml/datasets/HIGGS'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 METHOD\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "This data has 10,999,999 rows and 29 columns, including the target variable.  Descriptive column names were added based on the data description found on the source site.  The first column contains the target variable, 'class', which is a categorical variable of value 1 or 0 (1= signal, 0 = background).  The remaining 28 columns represent various features related to whether the particle is an exotic particle with a unique signal or just noise.  Feature values were numeric.\n",
    "\n",
    "We scaled the data between 0 and 100 fore easier model training and decided on an 80/20 train/test split with random seed equal to 7.\n",
    "\n",
    "### Neural Network (NN) Model\n",
    "\n",
    "Our neural network (NN) model was built via sequential layering. Our input layer uses the 28 features related to our particles. The first hidden layer has 100 neurons, the second has 50 neurons, and our output layer has one neuron. Both of our hidden layers use `tanh` activation. We used the `stochastic gradient descent` optimizer, seeking the lowest `mean absolute error` for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 RESULTS\n",
    "\n",
    "We trained our NN model over 10 epochs and got the following results:\n",
    "\n",
    "|Metric|Value|\n",
    "|:---: |:---:|\n",
    "|Loss|0.2068|\n",
    "|MSE|0.2068|\n",
    "|MAE|0.4171|\n",
    "|Accuracy|0.6769|\n",
    "|AUC|0.7401|\n",
    "\n",
    "Our result was within range but decidedly not as good as the best performing accuracy and AUC metrics from the best performing models described in Baldi et al. The neural network in Baldi et al. ranged from 0.733-0.816 for different feature levels using 300 hidden layers whereas ours was 0.7401 for 100 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 CONCLUSION\n",
    "\n",
    "Our neural network used just two hidden layers, while the network in Baldi et al used five layers. Additionally, Baldi et al used 300 neurons for each layer, while we used 100 neurons for our first hidden layer and 50 neurons for our second. At its most dense iteration with 10,000 neurons, the Baldi study resulted in AUC ranging from 0.790 to 0.841.  One improvement we could make was to make our NN model more dense with 10,000 neurons.  Furthermore, we could have added more layers as in the Baldi et al paper.  \n",
    "\n",
    "In addition, a possible improvement we could make is using a more modern optimizer for our model. While we chose `sgd` because is is most familiar, we could have easily chosen `adam` or `RMSprop`, which were available when Baldi et al was written.  Current optimizers could improve model performance.\n",
    "\n",
    "Additionally, we wanted to go with a model that was computationally inexpensive by 2021 standards because of the limitations of our local machines, but it would likely be considered computationally expensive by 1986 standards. We could probably build a more complex model that better takes advantage of advances in computers.\n",
    "\n",
    "Ultimately, our model reported performance based on mean square error (MSE = 0.2068)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPENDIX : CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "os.getcwd()\n",
    "os.chdir('C:/SMU/DS 7333 Quant the World/Case Studies\\Case Study week 12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data and Data Prepping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv(\"HIGGS.csv\",nrows = 1000000, header = None, dtype=np.float32)\n",
    "df.to_csv(\"HIGGSSubset.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Lepton_pT</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_mag</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet_1_pt</th>\n",
       "      <th>jet_1_eta</th>\n",
       "      <th>jet_1_phi</th>\n",
       "      <th>jet_1_btag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet_4_eta</th>\n",
       "      <th>jet_4_phi</th>\n",
       "      <th>jet_4_btag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869293</td>\n",
       "      <td>-0.635082</td>\n",
       "      <td>0.225690</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>-0.689993</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>-0.248573</td>\n",
       "      <td>-1.092064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>-0.045767</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.353760</td>\n",
       "      <td>0.979563</td>\n",
       "      <td>0.978076</td>\n",
       "      <td>0.920005</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.876678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907542</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.359412</td>\n",
       "      <td>1.497970</td>\n",
       "      <td>-0.313010</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>-1.588230</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138930</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.833048</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.798343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798835</td>\n",
       "      <td>1.470639</td>\n",
       "      <td>-1.635975</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>1.282322</td>\n",
       "      <td>1.381664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128848</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>0.985692</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.803252</td>\n",
       "      <td>0.865924</td>\n",
       "      <td>0.780118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344385</td>\n",
       "      <td>-0.876626</td>\n",
       "      <td>0.935913</td>\n",
       "      <td>1.992050</td>\n",
       "      <td>0.882454</td>\n",
       "      <td>1.786066</td>\n",
       "      <td>-1.646778</td>\n",
       "      <td>-0.942383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.360356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>1.028704</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.957904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.105009</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>1.522401</td>\n",
       "      <td>0.882808</td>\n",
       "      <td>-1.205349</td>\n",
       "      <td>0.681466</td>\n",
       "      <td>-1.070464</td>\n",
       "      <td>-0.921871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373566</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755856</td>\n",
       "      <td>1.361057</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>1.133295</td>\n",
       "      <td>0.872245</td>\n",
       "      <td>0.808487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  Lepton_pT  lepton_eta  lepton_phi  missing_energy_mag  \\\n",
       "0    1.0   0.869293   -0.635082    0.225690            0.327470   \n",
       "1    1.0   0.907542    0.329147    0.359412            1.497970   \n",
       "2    1.0   0.798835    1.470639   -1.635975            0.453773   \n",
       "3    0.0   1.344385   -0.876626    0.935913            1.992050   \n",
       "4    1.0   1.105009    0.321356    1.522401            0.882808   \n",
       "\n",
       "   missing_energy_phi  jet_1_pt  jet_1_eta  jet_1_phi  jet_1_btag  ...  \\\n",
       "0           -0.689993  0.754202  -0.248573  -1.092064    0.000000  ...   \n",
       "1           -0.313010  1.095531  -0.557525  -1.588230    2.173076  ...   \n",
       "2            0.425629  1.104875   1.282322   1.381664    0.000000  ...   \n",
       "3            0.882454  1.786066  -1.646778  -0.942383    0.000000  ...   \n",
       "4           -1.205349  0.681466  -1.070464  -0.921871    0.000000  ...   \n",
       "\n",
       "   jet_4_eta  jet_4_phi  jet_4_btag      m_jj     m_jjj      m_lv     m_jlv  \\\n",
       "0  -0.010455  -0.045767    3.101961  1.353760  0.979563  0.978076  0.920005   \n",
       "1  -1.138930  -0.000819    0.000000  0.302220  0.833048  0.985700  0.978098   \n",
       "2   1.128848   0.900461    0.000000  0.909753  1.108330  0.985692  0.951331   \n",
       "3  -0.678379  -1.360356    0.000000  0.946652  1.028704  0.998656  0.728281   \n",
       "4  -0.373566   0.113041    0.000000  0.755856  1.361057  0.986610  0.838085   \n",
       "\n",
       "       m_bb     m_wbb    m_wwbb  \n",
       "0  0.721657  0.988751  0.876678  \n",
       "1  0.779732  0.992356  0.798343  \n",
       "2  0.803252  0.865924  0.780118  \n",
       "3  0.869200  1.026736  0.957904  \n",
       "4  1.133295  0.872245  0.808487  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns for descriptive feature identification\n",
    "df.columns = ['class', 'Lepton_pT', 'lepton_eta', 'lepton_phi', 'missing_energy_mag', 'missing_energy_phi',\n",
    "                   'jet_1_pt','jet_1_eta','jet_1_phi','jet_1_btag','jet_2_pt','jet_2_eta', 'jet_2_phi','jet_2_btag',\n",
    "                   'jet_3_pt','jet_3_eta', 'jet_3_phi','jet_3_btag','jet_4_pt','jet_4_eta','jet_4_phi','jet_4_btag',\n",
    "                   'm_jj','m_jjj','m_lv','m_jlv','m_bb','m_wbb','m_wwbb']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set has 1000000 rows and 29 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Lepton_pT</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_mag</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet_1_pt</th>\n",
       "      <th>jet_1_eta</th>\n",
       "      <th>jet_1_phi</th>\n",
       "      <th>jet_1_btag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet_4_eta</th>\n",
       "      <th>jet_4_phi</th>\n",
       "      <th>jet_4_btag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.529673</td>\n",
       "      <td>0.991636</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>0.998163</td>\n",
       "      <td>-0.000573</td>\n",
       "      <td>0.990576</td>\n",
       "      <td>-0.000824</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>1.003582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>-0.001724</td>\n",
       "      <td>1.001547</td>\n",
       "      <td>1.034308</td>\n",
       "      <td>1.024927</td>\n",
       "      <td>1.055578</td>\n",
       "      <td>1.009864</td>\n",
       "      <td>0.973244</td>\n",
       "      <td>1.033359</td>\n",
       "      <td>0.959868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.498550</td>\n",
       "      <td>0.564946</td>\n",
       "      <td>1.008089</td>\n",
       "      <td>1.005646</td>\n",
       "      <td>0.598998</td>\n",
       "      <td>1.006654</td>\n",
       "      <td>0.474941</td>\n",
       "      <td>1.010140</td>\n",
       "      <td>1.006106</td>\n",
       "      <td>1.027217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007577</td>\n",
       "      <td>1.005506</td>\n",
       "      <td>1.397190</td>\n",
       "      <td>0.671789</td>\n",
       "      <td>0.379662</td>\n",
       "      <td>0.164348</td>\n",
       "      <td>0.397682</td>\n",
       "      <td>0.525081</td>\n",
       "      <td>0.364940</td>\n",
       "      <td>0.313111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274697</td>\n",
       "      <td>-2.434976</td>\n",
       "      <td>-1.742508</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>-1.743944</td>\n",
       "      <td>0.138602</td>\n",
       "      <td>-2.969725</td>\n",
       "      <td>-1.741237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.497265</td>\n",
       "      <td>-1.742691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101168</td>\n",
       "      <td>0.234753</td>\n",
       "      <td>0.092202</td>\n",
       "      <td>0.157473</td>\n",
       "      <td>0.048125</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>0.350939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590753</td>\n",
       "      <td>-0.737349</td>\n",
       "      <td>-0.871931</td>\n",
       "      <td>0.576455</td>\n",
       "      <td>-0.871791</td>\n",
       "      <td>0.678535</td>\n",
       "      <td>-0.689225</td>\n",
       "      <td>-0.867542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714190</td>\n",
       "      <td>-0.872034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790729</td>\n",
       "      <td>0.846332</td>\n",
       "      <td>0.985750</td>\n",
       "      <td>0.767338</td>\n",
       "      <td>0.673858</td>\n",
       "      <td>0.819379</td>\n",
       "      <td>0.770333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853737</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.891644</td>\n",
       "      <td>-0.000800</td>\n",
       "      <td>0.894178</td>\n",
       "      <td>-0.001016</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>1.086538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>-0.005259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.894967</td>\n",
       "      <td>0.950568</td>\n",
       "      <td>0.989771</td>\n",
       "      <td>0.916455</td>\n",
       "      <td>0.873490</td>\n",
       "      <td>0.947443</td>\n",
       "      <td>0.871788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.236958</td>\n",
       "      <td>0.738214</td>\n",
       "      <td>0.868775</td>\n",
       "      <td>1.293112</td>\n",
       "      <td>0.871773</td>\n",
       "      <td>1.170649</td>\n",
       "      <td>0.687194</td>\n",
       "      <td>0.869976</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714934</td>\n",
       "      <td>0.868831</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.024375</td>\n",
       "      <td>1.083443</td>\n",
       "      <td>1.020216</td>\n",
       "      <td>1.142236</td>\n",
       "      <td>1.139482</td>\n",
       "      <td>1.140750</td>\n",
       "      <td>1.059245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.711782</td>\n",
       "      <td>2.434868</td>\n",
       "      <td>1.743236</td>\n",
       "      <td>9.900929</td>\n",
       "      <td>1.743257</td>\n",
       "      <td>8.382610</td>\n",
       "      <td>2.969674</td>\n",
       "      <td>1.741454</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>2.498009</td>\n",
       "      <td>1.743372</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>31.076191</td>\n",
       "      <td>15.637859</td>\n",
       "      <td>5.921233</td>\n",
       "      <td>10.794087</td>\n",
       "      <td>13.735691</td>\n",
       "      <td>8.779915</td>\n",
       "      <td>6.259156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                class       Lepton_pT      lepton_eta      lepton_phi  \\\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean         0.529673        0.991636        0.000489       -0.000953   \n",
       "std          0.498550        0.564946        1.008089        1.005646   \n",
       "min          0.000000        0.274697       -2.434976       -1.742508   \n",
       "25%          0.000000        0.590753       -0.737349       -0.871931   \n",
       "50%          1.000000        0.853737        0.000920        0.000417   \n",
       "75%          1.000000        1.236958        0.738214        0.868775   \n",
       "max          1.000000        8.711782        2.434868        1.743236   \n",
       "\n",
       "       missing_energy_mag  missing_energy_phi        jet_1_pt       jet_1_eta  \\\n",
       "count      1000000.000000      1000000.000000  1000000.000000  1000000.000000   \n",
       "mean             0.998163           -0.000573        0.990576       -0.000824   \n",
       "std              0.598998            1.006654        0.474941        1.010140   \n",
       "min              0.000626           -1.743944        0.138602       -2.969725   \n",
       "25%              0.576455           -0.871791        0.678535       -0.689225   \n",
       "50%              0.891644           -0.000800        0.894178       -0.001016   \n",
       "75%              1.293112            0.871773        1.170649        0.687194   \n",
       "max              9.900929            1.743257        8.382610        2.969674   \n",
       "\n",
       "            jet_1_phi      jet_1_btag  ...       jet_4_eta       jet_4_phi  \\\n",
       "count  1000000.000000  1000000.000000  ...  1000000.000000  1000000.000000   \n",
       "mean         0.000549        1.003582  ...       -0.000375       -0.001724   \n",
       "std          1.006106        1.027217  ...        1.007577        1.005506   \n",
       "min         -1.741237        0.000000  ...       -2.497265       -1.742691   \n",
       "25%         -0.867542        0.000000  ...       -0.714190       -0.872034   \n",
       "50%          0.000715        1.086538  ...        0.000372       -0.005259   \n",
       "75%          0.869976        2.173076  ...        0.714934        0.868831   \n",
       "max          1.741454        2.173076  ...        2.498009        1.743372   \n",
       "\n",
       "           jet_4_btag            m_jj           m_jjj            m_lv  \\\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean         1.001547        1.034308        1.024927        1.055578   \n",
       "std          1.397190        0.671789        0.379662        0.164348   \n",
       "min          0.000000        0.101168        0.234753        0.092202   \n",
       "25%          0.000000        0.790729        0.846332        0.985750   \n",
       "50%          0.000000        0.894967        0.950568        0.989771   \n",
       "75%          3.101961        1.024375        1.083443        1.020216   \n",
       "max          3.101961       31.076191       15.637859        5.921233   \n",
       "\n",
       "                m_jlv            m_bb           m_wbb          m_wwbb  \n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000  \n",
       "mean         1.009864        0.973244        1.033359        0.959868  \n",
       "std          0.397682        0.525081        0.364940        0.313111  \n",
       "min          0.157473        0.048125        0.303350        0.350939  \n",
       "25%          0.767338        0.673858        0.819379        0.770333  \n",
       "50%          0.916455        0.873490        0.947443        0.871788  \n",
       "75%          1.142236        1.139482        1.140750        1.059245  \n",
       "max         10.794087       13.735691        8.779915        6.259156  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Lepton_pT</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_mag</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet_1_pt</th>\n",
       "      <th>jet_1_eta</th>\n",
       "      <th>jet_1_phi</th>\n",
       "      <th>jet_1_btag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet_4_eta</th>\n",
       "      <th>jet_4_phi</th>\n",
       "      <th>jet_4_btag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869293</td>\n",
       "      <td>-0.635082</td>\n",
       "      <td>0.225690</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>-0.689993</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>-0.248573</td>\n",
       "      <td>-1.092064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>-0.045767</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.353760</td>\n",
       "      <td>0.979563</td>\n",
       "      <td>0.978076</td>\n",
       "      <td>0.920005</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.876678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907542</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.359412</td>\n",
       "      <td>1.497970</td>\n",
       "      <td>-0.313010</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>-1.588230</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138930</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.833048</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.798343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798835</td>\n",
       "      <td>1.470639</td>\n",
       "      <td>-1.635975</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>1.282322</td>\n",
       "      <td>1.381664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128848</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>0.985692</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.803252</td>\n",
       "      <td>0.865924</td>\n",
       "      <td>0.780118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344385</td>\n",
       "      <td>-0.876626</td>\n",
       "      <td>0.935913</td>\n",
       "      <td>1.992050</td>\n",
       "      <td>0.882454</td>\n",
       "      <td>1.786066</td>\n",
       "      <td>-1.646778</td>\n",
       "      <td>-0.942383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.360356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>1.028704</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.957904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.105009</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>1.522401</td>\n",
       "      <td>0.882808</td>\n",
       "      <td>-1.205349</td>\n",
       "      <td>0.681466</td>\n",
       "      <td>-1.070464</td>\n",
       "      <td>-0.921871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373566</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755856</td>\n",
       "      <td>1.361057</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>1.133295</td>\n",
       "      <td>0.872245</td>\n",
       "      <td>0.808487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  Lepton_pT  lepton_eta  lepton_phi  missing_energy_mag  \\\n",
       "0    1.0   0.869293   -0.635082    0.225690            0.327470   \n",
       "1    1.0   0.907542    0.329147    0.359412            1.497970   \n",
       "2    1.0   0.798835    1.470639   -1.635975            0.453773   \n",
       "3    0.0   1.344385   -0.876626    0.935913            1.992050   \n",
       "4    1.0   1.105009    0.321356    1.522401            0.882808   \n",
       "\n",
       "   missing_energy_phi  jet_1_pt  jet_1_eta  jet_1_phi  jet_1_btag  ...  \\\n",
       "0           -0.689993  0.754202  -0.248573  -1.092064    0.000000  ...   \n",
       "1           -0.313010  1.095531  -0.557525  -1.588230    2.173076  ...   \n",
       "2            0.425629  1.104875   1.282322   1.381664    0.000000  ...   \n",
       "3            0.882454  1.786066  -1.646778  -0.942383    0.000000  ...   \n",
       "4           -1.205349  0.681466  -1.070464  -0.921871    0.000000  ...   \n",
       "\n",
       "   jet_4_eta  jet_4_phi  jet_4_btag      m_jj     m_jjj      m_lv     m_jlv  \\\n",
       "0  -0.010455  -0.045767    3.101961  1.353760  0.979563  0.978076  0.920005   \n",
       "1  -1.138930  -0.000819    0.000000  0.302220  0.833048  0.985700  0.978098   \n",
       "2   1.128848   0.900461    0.000000  0.909753  1.108330  0.985692  0.951331   \n",
       "3  -0.678379  -1.360356    0.000000  0.946652  1.028704  0.998656  0.728281   \n",
       "4  -0.373566   0.113041    0.000000  0.755856  1.361057  0.986610  0.838085   \n",
       "\n",
       "       m_bb     m_wbb    m_wwbb  \n",
       "0  0.721657  0.988751  0.876678  \n",
       "1  0.779732  0.992356  0.798343  \n",
       "2  0.803252  0.865924  0.780118  \n",
       "3  0.869200  1.026736  0.957904  \n",
       "4  1.133295  0.872245  0.808487  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "float32    29\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The data set has {} rows and {} columns\".format(df.shape[0], df.shape[1]))\n",
    "display(df.describe())\n",
    "display(df.head())\n",
    "display(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing input features and target output variable ('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.0\n",
       "1         1.0\n",
       "2         1.0\n",
       "3         0.0\n",
       "4         1.0\n",
       "         ... \n",
       "999995    1.0\n",
       "999996    1.0\n",
       "999997    0.0\n",
       "999998    0.0\n",
       "999999    0.0\n",
       "Name: class, Length: 1000000, dtype: float32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df['class']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the target variable, 'class', into an numpy array\n",
    "y=np.array(df['class'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: median values were scaled by multiplying by 0.2871342739 and adding 0.499969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train = scaler.fit_transform(x)\n",
    "\n",
    "# Print out the adjustment that the scaler applied to the total_earnings column of data\n",
    "print(\"Note: median values were scaled by multiplying by {:.10f} and adding {:.6f}\".format(scaler.scale_[7], scaler.min_[7]))\n",
    "multiplied_by = scaler.scale_[7]\n",
    "added = scaler.min_[7]\n",
    "\n",
    "scaled_train_df = pd.DataFrame(scaled_train, columns=x.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test (validation) subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled_train_df, y, test_size=0.20, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 28)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(28,)))\n",
    "model.add(layers.Dense(100,activation='relu'))  # adds a layer with 100 neurons, tanh activation\n",
    "model.add(layers.Dense(50, activation='relu'))   # adds a layer with 50 neurons, tanh activation\n",
    "model.add(layers.Dense(1, activation='linear'))  # adds a layer with 1 neurons, linear (aka NO) activation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error','mean_absolute_error','accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/10\n",
      "800000/800000 [==============================] - 53s 67us/sample - loss: 0.2366 - mean_squared_error: 0.2366 - mean_absolute_error: 0.4748 - accuracy: 0.5897 - val_loss: 0.2287 - val_mean_squared_error: 0.2287 - val_mean_absolute_error: 0.4554 - val_accuracy: 0.6189\n",
      "Epoch 2/10\n",
      "800000/800000 [==============================] - 54s 67us/sample - loss: 0.2265 - mean_squared_error: 0.2265 - mean_absolute_error: 0.4540 - accuracy: 0.6258 - val_loss: 0.2288 - val_mean_squared_error: 0.2288 - val_mean_absolute_error: 0.4563 - val_accuracy: 0.6124\n",
      "Epoch 3/10\n",
      "800000/800000 [==============================] - 56s 70us/sample - loss: 0.2236 - mean_squared_error: 0.2236 - mean_absolute_error: 0.4484 - accuracy: 0.6362 - val_loss: 0.2217 - val_mean_squared_error: 0.2217 - val_mean_absolute_error: 0.4421 - val_accuracy: 0.6412\n",
      "Epoch 4/10\n",
      "800000/800000 [==============================] - 55s 68us/sample - loss: 0.2211 - mean_squared_error: 0.2211 - mean_absolute_error: 0.4443 - accuracy: 0.6431 - val_loss: 0.2191 - val_mean_squared_error: 0.2191 - val_mean_absolute_error: 0.4423 - val_accuracy: 0.6504\n",
      "Epoch 5/10\n",
      "800000/800000 [==============================] - 56s 70us/sample - loss: 0.2188 - mean_squared_error: 0.2188 - mean_absolute_error: 0.4399 - accuracy: 0.6502 - val_loss: 0.2204 - val_mean_squared_error: 0.2204 - val_mean_absolute_error: 0.4419 - val_accuracy: 0.6454\n",
      "Epoch 6/10\n",
      "800000/800000 [==============================] - 60s 75us/sample - loss: 0.2167 - mean_squared_error: 0.2167 - mean_absolute_error: 0.4358 - accuracy: 0.6551 - val_loss: 0.2148 - val_mean_squared_error: 0.2148 - val_mean_absolute_error: 0.4319 - val_accuracy: 0.6579\n",
      "Epoch 7/10\n",
      "800000/800000 [==============================] - 55s 68us/sample - loss: 0.2143 - mean_squared_error: 0.2143 - mean_absolute_error: 0.4315 - accuracy: 0.6604 - val_loss: 0.2211 - val_mean_squared_error: 0.2211 - val_mean_absolute_error: 0.4243 - val_accuracy: 0.6391\n",
      "Epoch 8/10\n",
      "800000/800000 [==============================] - 61s 76us/sample - loss: 0.2118 - mean_squared_error: 0.2118 - mean_absolute_error: 0.4269 - accuracy: 0.6663 - val_loss: 0.2116 - val_mean_squared_error: 0.2116 - val_mean_absolute_error: 0.4216 - val_accuracy: 0.6602\n",
      "Epoch 9/10\n",
      "800000/800000 [==============================] - 55s 69us/sample - loss: 0.2091 - mean_squared_error: 0.2091 - mean_absolute_error: 0.4219 - accuracy: 0.6715 - val_loss: 0.2072 - val_mean_squared_error: 0.2072 - val_mean_absolute_error: 0.4200 - val_accuracy: 0.6720\n",
      "Epoch 10/10\n",
      "800000/800000 [==============================] - 55s 69us/sample - loss: 0.2068 - mean_squared_error: 0.2068 - mean_absolute_error: 0.4172 - accuracy: 0.6768 - val_loss: 0.2090 - val_mean_squared_error: 0.2090 - val_mean_absolute_error: 0.4185 - val_accuracy: 0.6769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23cb3af0208>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test), batch_size=34)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Review Model History and Comparative Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.2366141768554598,\n",
       "  0.2265159061010927,\n",
       "  0.22355535491537304,\n",
       "  0.22110678348779678,\n",
       "  0.21878414987515657,\n",
       "  0.21665914227759467,\n",
       "  0.21429911603838206,\n",
       "  0.21176092233454807,\n",
       "  0.20912767866445706,\n",
       "  0.20682945714594797],\n",
       " 'mean_squared_error': [0.23661458,\n",
       "  0.22651647,\n",
       "  0.223555,\n",
       "  0.22110687,\n",
       "  0.21878482,\n",
       "  0.21665943,\n",
       "  0.21429831,\n",
       "  0.21176215,\n",
       "  0.2091275,\n",
       "  0.20683005],\n",
       " 'mean_absolute_error': [0.47479177,\n",
       "  0.4540359,\n",
       "  0.44843525,\n",
       "  0.44426444,\n",
       "  0.43990642,\n",
       "  0.43581548,\n",
       "  0.43146,\n",
       "  0.4268657,\n",
       "  0.4218828,\n",
       "  0.41716695],\n",
       " 'accuracy': [0.589745,\n",
       "  0.625825,\n",
       "  0.63623625,\n",
       "  0.6430675,\n",
       "  0.6501925,\n",
       "  0.6551238,\n",
       "  0.66042125,\n",
       "  0.66626126,\n",
       "  0.6714587,\n",
       "  0.6767975],\n",
       " 'val_loss': [0.22868566791594028,\n",
       "  0.22878000627711415,\n",
       "  0.22173909616798163,\n",
       "  0.2190503909663856,\n",
       "  0.2204366422738135,\n",
       "  0.21479878485485912,\n",
       "  0.22113717370696365,\n",
       "  0.2116478346760571,\n",
       "  0.20723794947639107,\n",
       "  0.2090008020016551],\n",
       " 'val_mean_squared_error': [0.22868574,\n",
       "  0.22878015,\n",
       "  0.2217394,\n",
       "  0.21905006,\n",
       "  0.22043635,\n",
       "  0.21479894,\n",
       "  0.22113705,\n",
       "  0.21164843,\n",
       "  0.20723787,\n",
       "  0.20900074],\n",
       " 'val_mean_absolute_error': [0.4553968,\n",
       "  0.4562908,\n",
       "  0.4420816,\n",
       "  0.44233814,\n",
       "  0.44190574,\n",
       "  0.43193114,\n",
       "  0.42427793,\n",
       "  0.42161942,\n",
       "  0.41997063,\n",
       "  0.41851574],\n",
       " 'val_accuracy': [0.61888,\n",
       "  0.61237,\n",
       "  0.641175,\n",
       "  0.65044,\n",
       "  0.6454,\n",
       "  0.657855,\n",
       "  0.63909,\n",
       "  0.66021,\n",
       "  0.672015,\n",
       "  0.676905]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: [0.20900080184936523, 0.20900051, 0.4185159, 0.676905]\n",
      "Test accuracy: [0.20900080184936523, 0.20900051, 0.4185159, 0.676905]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose = 0) \n",
    "\n",
    "print('Test loss:', score) \n",
    "print('Test accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7400840687926283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# auc scores\n",
    "auc_score = roc_auc_score(y_test, pred)\n",
    "\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = model.history.history['loss']\n",
    "val_loss = model.history.history['val_loss']\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 100)               2900      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 8,001\n",
      "Trainable params: 8,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
